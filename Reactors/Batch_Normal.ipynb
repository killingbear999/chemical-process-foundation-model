{"cells":[{"cell_type":"code","execution_count":1,"id":"cc986002","metadata":{"id":"cc986002","executionInfo":{"status":"ok","timestamp":1710227017238,"user_tz":-480,"elapsed":4822,"user":{"displayName":"Wang Zihao","userId":"13688795653924779981"}}},"outputs":[],"source":["# import libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from sklearn import preprocessing\n","from keras.models import Sequential\n","from keras.layers import Dense, SimpleRNN, Input, Activation, Dropout, Add, LSTM, GRU, RNN, LayerNormalization, BatchNormalization, Conv1D, MaxPooling1D, Flatten\n","from keras.optimizers import Adam,SGD\n","import tensorflow as tf\n","from keras import Model, regularizers, activations\n","import pickle\n","from copy import deepcopy\n","\n","# disable warnings to ignore overflow error\n","import warnings\n","warnings.filterwarnings('ignore')\n","warnings.simplefilter('ignore')"]},{"cell_type":"code","execution_count":2,"id":"6a09c682","metadata":{"id":"6a09c682","executionInfo":{"status":"ok","timestamp":1710227017238,"user_tz":-480,"elapsed":2,"user":{"displayName":"Wang Zihao","userId":"13688795653924779981"}}},"outputs":[],"source":["# parameters for Batch\n","V = 1\n","k_0 = 8.46*(np.power(10,7))\n","C_p = 0.231\n","rho_L = 1000\n","Q_s = 0.0\n","E = 5*(np.power(10,4))\n","delta_H = -1.15*(np.power(10,4))\n","R = 8.314\n","\n","t_final = 0.05\n","t_step = 1e-4\n","num_step = 10\n","num_dims = 4\n","\n","# parameters for Reptile\n","seed = 0\n","plot = True\n","rng = np.random.RandomState(seed)\n","innerepochs = 50 # number of epochs of each inner SGD\n","niterations = 1000 # number of outer updates; each iteration we sample one task and update on it\n","ntrain = 32 # Size of training minibatches (K)\n","eval_step = 50 # evaluation step\n","threshold = 10 # threshold to check data correctness"]},{"cell_type":"code","execution_count":4,"id":"PBKEZLBI5Ty9","metadata":{"id":"PBKEZLBI5Ty9","executionInfo":{"status":"ok","timestamp":1710227036609,"user_tz":-480,"elapsed":493,"user":{"displayName":"Wang Zihao","userId":"13688795653924779981"}}},"outputs":[],"source":["def Batch_simulation(V, k_0, E, R, delta_H, rho_L, C_p, Q, t_final, t_step, C_A_initial, T_initial):\n","    \"\"\"\n","        simulating Batch using forward Euler method\n","    \"\"\"\n","\n","    C_A_list = list()  # evolution of CA over time\n","    T_list = list()  # evolution of T over time\n","\n","    C_A = C_A_initial\n","    T = T_initial\n","\n","    for i in range(int(t_final / t_step)):\n","        dCAdt = -k_0 * np.exp(-E / (R * T)) * C_A\n","        dTdt = - delta_H / (rho_L * C_p) * k_0 * np.exp(-E / (R * T)) * C_A + Q / (rho_L * C_p * V)\n","\n","        T += dTdt * t_step\n","        C_A += dCAdt * t_step\n","\n","        if i % 50 == 0:\n","            C_A_list.append(C_A)\n","            T_list.append(T)\n","\n","    return C_A_list, T_list\n","\n","def to_tensor(x):\n","    return tf.convert_to_tensor(x, dtype=tf.float32)\n","\n","def train_on_batch(x, y, model, optimizer):\n","    x = to_tensor(x)\n","    y = to_tensor(y)\n","\n","    with tf.GradientTape() as tape:\n","        YHat = model(x)\n","        loss = mse_loss_fn(y, YHat)\n","        grads = tape.gradient(loss, model.trainable_weights)\n","    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n","    return loss\n","\n","def predict(x, model):\n","    x = to_tensor(x)\n","    return model(x).numpy()\n","\n","def compute_loss(x, y, model):\n","    return np.square(predict(x, model) - y).mean()"]},{"cell_type":"code","execution_count":15,"id":"FyP7p8e5POqy","metadata":{"id":"FyP7p8e5POqy","executionInfo":{"status":"ok","timestamp":1710228605854,"user_tz":-480,"elapsed":3,"user":{"displayName":"Wang Zihao","userId":"13688795653924779981"}}},"outputs":[],"source":["def gen_batch(V, k_0, E, R, delta_H, rho_L, C_p, Q_s, t_final, t_step, num_step):\n","    isCorrect = False\n","    while isCorrect == False:\n","        V_new = V\n","        Q_s_new = Q_s\n","        rho_L_new = rho_L\n","        C_p_new = C_p\n","        k_0_new = k_0\n","        E_new = E\n","        delta_H_new = delta_H\n","\n","        # generating inputs and initial states for Batch\n","        u_list = np.linspace(-5e5, 5e5, 4, endpoint=True)\n","        T_initial = np.linspace(300, 600, 40, endpoint=True)\n","        CA_initial = np.linspace(0, 6, 40, endpoint=True)\n","\n","        # restruture the data\n","        T_start = list()\n","        CA_start = list()\n","\n","        for T in T_initial:\n","            for CA in CA_initial:\n","                CA_start.append(CA)\n","                T_start.append(T)\n","\n","        CA_start = np.array([CA_start])\n","        T_start = np.array([T_start])\n","        x_deviation = np.concatenate((CA_start.T, T_start.T), axis=1)\n","\n","        # get X and y data for training and testing\n","        CA_output = list()\n","        T_output = list()\n","        CA_input = list()\n","        T_input = list()\n","        CA0_input = list()\n","        Q_input = list()\n","\n","        for u1 in u_list:\n","            Q = u1 + Q_s_new\n","            for C_A_initial, T_initial in x_deviation:\n","\n","                C_A_list, T_list = Batch_simulation(V_new, k_0_new, E_new, R, delta_H_new, rho_L_new, C_p_new, Q, t_final, t_step, C_A_initial, T_initial)\n","                if any(abs(i) < 0.001 for i in T_list) == False and any(abs(i) < 0.001 for i in C_A_list) == False and any(abs(i) > 10000 for i in T_list) == False and any(abs(i) > 10000 for i in C_A_list) == False and any(abs(i) == 0 for i in T_list) == False and any(abs(i) == 0 for i in C_A_list) == False and np.isnan(C_A_list).any() == False and np.isnan(T_list).any() == False and np.isinf(C_A_list).any() == False and np.isinf(T_list).any() == False:\n","                    CA0_input.append(0)\n","                    Q_input.append(u1)\n","                    CA_input.append(C_A_initial)\n","                    T_input.append(T_initial)\n","\n","                    CA_output.append(C_A_list)\n","                    T_output.append(T_list)\n","\n","        # regenerate data if requirement is not met\n","        if len(CA_output) > 500:\n","\n","            # collate input for RNN\n","            CA0_input = np.array(CA0_input)\n","            CA0_input = CA0_input.reshape(-1,1,1)\n","\n","            Q_input = np.array(Q_input)\n","            Q_input = Q_input.reshape(-1,1,1)\n","\n","            CA_input = np.array(CA_input)\n","            CA_input = CA_input.reshape(-1,1,1)\n","\n","            T_input = np.array(T_input)\n","            T_input = T_input.reshape(-1,1,1)\n","\n","            RNN_input = np.concatenate((T_input, CA_input, Q_input, CA0_input), axis=2)\n","            RNN_input = RNN_input.repeat(num_step, axis=1)\n","\n","            # collate output for RNN\n","            CA_output = np.array(CA_output)\n","            CA_output = CA_output.reshape(-1, num_step, 1)\n","\n","            T_output = np.array(T_output)\n","            T_output = T_output.reshape(-1, num_step, 1)\n","\n","            RNN_output = np.concatenate((T_output, CA_output), axis=2)\n","\n","            # scale the data\n","            scaler_X = preprocessing.StandardScaler().fit(RNN_input.reshape(-1, num_dims))\n","            scaler_y = preprocessing.StandardScaler().fit(RNN_output.reshape(-1, 2))\n","\n","            X = scaler_X.transform(RNN_input.reshape(-1, num_dims))\n","            y = scaler_y.transform(RNN_output.reshape(-1,2))\n","\n","            if np.isnan(X).any() == False and np.isnan(y).any() == False and np.isinf(X).any() == False and np.isinf(y).any() == False and any(abs(i) > threshold for i in y.reshape(-1)) == False:\n","                isCorrect = True\n","\n","    print(\"Number of training samples of Batch: \", int(len(X)/num_step))\n","    return X.reshape(-1,num_step,num_dims), y.reshape(-1,num_step,2)"]},{"cell_type":"code","execution_count":16,"id":"hItV5pfJUx-k","metadata":{"id":"hItV5pfJUx-k","executionInfo":{"status":"ok","timestamp":1710228607748,"user_tz":-480,"elapsed":1,"user":{"displayName":"Wang Zihao","userId":"13688795653924779981"}}},"outputs":[],"source":["class Model(tf.keras.layers.Layer):\n","\n","    def __init__(self):\n","        super(Model, self).__init__()\n","\n","        self.layer_1 = SimpleRNN(64, activation='relu', return_sequences=True)\n","        self.layer_2 = SimpleRNN(64, activation='relu', return_sequences=True)\n","        self.layer_3 = Dense(2, activation='linear')\n","\n","    def call(self, inputs):\n","        x = self.layer_1(inputs)\n","        x = self.layer_2(x)\n","        x = self.layer_3(x)\n","        return x\n","\n","model = Model()\n","\n","# Necessary to create the model's state.\n","# The model doesn't have a state until it's called at least once.\n","_ = model(tf.zeros((ntrain, num_step, num_dims)))\n","\n","optimizer = tf.keras.optimizers.Adam()\n","mse_loss_fn = tf.keras.losses.MeanSquaredError()"]},{"cell_type":"code","execution_count":17,"id":"g8cH2iKAVmq7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g8cH2iKAVmq7","outputId":"f1c71690-2e21-4f29-ea4e-f26f7dbe49e6","executionInfo":{"status":"ok","timestamp":1710228826443,"user_tz":-480,"elapsed":217388,"user":{"displayName":"Wang Zihao","userId":"13688795653924779981"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of training samples of Batch:  2080\n","Test loss:  0.2276694810228859\n"]}],"source":["# generate task\n","isOverflow = True\n","while isOverflow == True:\n","    try:\n","        x_all, y_all = gen_batch(V, k_0, E, R, delta_H, rho_L, C_p, Q_s, t_final, t_step, num_step)\n","        isOverflow = False\n","    except ValueError:\n","        pass\n","\n","# begin training\n","inds = rng.permutation(len(x_all))\n","\n","for i in range(innerepochs):\n","    for start in range(0, len(x_all)-ntrain*13, ntrain):\n","        mbinds = inds[start:start+ntrain]\n","        train_on_batch(x_all[mbinds], y_all[mbinds], model, optimizer)\n","\n","test_loss = compute_loss(x_all[len(x_all)-ntrain*13:], y_all[len(x_all)-ntrain*13:], model)\n","print(\"Test loss: \", test_loss)"]},{"cell_type":"code","source":["# Number of training samples:  6400\n","# Test loss original:  0.0002799301997144804\n","# Test loss with zero padding:  0.00036578343812920404"],"metadata":{"id":"_5KRUf4XqeH-"},"id":"_5KRUf4XqeH-","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1Okv370rN4h3t4O5u_4klSBCafTLOo2ZK","timestamp":1709614437441},{"file_id":"1e_-X-o388wo1SE3aD29Cje3smefG12em","timestamp":1708937435667},{"file_id":"1qw_LOTDfL_q158TqkqGE7TpzHEDhuS58","timestamp":1708920500182},{"file_id":"1j2FxdwUojH6lWx8sfrNnzQgH6i6B4-4T","timestamp":1704714779628}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":5}