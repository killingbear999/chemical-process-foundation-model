{"cells":[{"cell_type":"code","execution_count":2,"id":"832feb51","metadata":{"id":"832feb51","executionInfo":{"status":"ok","timestamp":1712112472961,"user_tz":-480,"elapsed":535,"user":{"displayName":"Wang Zihao","userId":"13688795653924779981"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy.integrate import solve_ivp\n","import torch\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import DataLoader, TensorDataset\n","import math\n","# import optuna"]},{"cell_type":"markdown","id":"551708c1","metadata":{"id":"551708c1"},"source":["# EarlyStopping function"]},{"cell_type":"code","execution_count":17,"id":"7d0fd46f","metadata":{"id":"7d0fd46f","executionInfo":{"status":"ok","timestamp":1712114007529,"user_tz":-480,"elapsed":444,"user":{"displayName":"Wang Zihao","userId":"13688795653924779981"}}},"outputs":[],"source":["class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","\n","    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement.\n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.pt'\n","            trace_func (function): trace print function.\n","                            Default: print\n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","        self.trace_func = trace_func\n","\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss"]},{"cell_type":"code","execution_count":4,"id":"23b1aa92","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"23b1aa92","executionInfo":{"status":"ok","timestamp":1712112479431,"user_tz":-480,"elapsed":5,"user":{"displayName":"Wang Zihao","userId":"13688795653924779981"}},"outputId":"e9a283de-3fed-4479-c36f-53173836f2f4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'using cpu'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}],"source":["# Tells whether the model is running on CPU or GPU\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print('using GPU:', torch.cuda.get_device_name()) if torch.cuda.is_available() else 'using cpu'"]},{"cell_type":"markdown","id":"424399e1","metadata":{"id":"424399e1"},"source":["# Specifying parameters for CSTR and other constants"]},{"cell_type":"code","execution_count":27,"id":"53772680","metadata":{"id":"53772680","executionInfo":{"status":"ok","timestamp":1712114138269,"user_tz":-480,"elapsed":311,"user":{"displayName":"Wang Zihao","userId":"13688795653924779981"}}},"outputs":[],"source":["# Parameter values for a second-order reaction taking place in a CSTR\n","\n","T_0 = 300 # inlet temperature\n","\n","V = 1 # volume of reacting liquid in the reactor\n","\n","k_0 = 8.46 * (np.power(10,6)) # pre-exponential constant\n","\n","C_p = 0.231 # heat capacity of reacting liquid\n","\n","rho_L = 1000 # density of reacting liquid\n","\n","Q_s = 0.0 # steady-state heat input rate\n","\n","T_s = 0 # steady-state reactor temperature\n","\n","F = 5 # volumetric flow rate\n","\n","E = 5 * (np.power(10,4)) # activation energy\n","\n","delta_H = -1.15 * (np.power(10,4)) # enthalpy of reaction\n","\n","R = 8.314 # ideal gas constant\n","\n","C_A0s = 4 #  steady-state inlet concentration of A\n","\n","C_As = 0 # steady-state reactor concentration of A\n","\n","t_final = 0.05 #0.01 # end time for numerical simulation\n","\n","t_step = 0.01 #1e-3 # integration time step h_c\n","\n","P = np.array([[1060, 22], [22, 0.52]]) # a positive definite matrix"]},{"cell_type":"markdown","id":"cfbebe71","metadata":{"id":"cfbebe71"},"source":["# Euler method RK45 (use Scipy or this)"]},{"cell_type":"code","execution_count":28,"id":"1c8b034c","metadata":{"id":"1c8b034c","executionInfo":{"status":"ok","timestamp":1712114140342,"user_tz":-480,"elapsed":397,"user":{"displayName":"Wang Zihao","userId":"13688795653924779981"}}},"outputs":[],"source":["# Function that uses Euler method to return the values of concentration and temperature of the next time-step\n","\n","def CSTR_simulation_Euler(F, V, C_A0, k_0, E, R, T_0, delta_H, rho_L, C_p, Q, C_As, T_s, t_final, t_step, C_A_initial, T_initial):\n","\n","    def dCAdt(C_A, T):\n","        return F / V * (C_A0 - C_A) - k_0 * np.exp(-E / (R * T)) * C_A**2\n","    def dTdt(C_A, T):\n","        return F / V * (T_0 - T) - delta_H / (rho_L * C_p) * k_0 * np.exp(-E / (R * T)) * C_A**2 + Q / (rho_L * C_p * V)\n","\n","    C_A = C_A_initial + C_As\n","    T = T_initial + T_s\n","    dCAdt1 = dCAdt(C_A, T)\n","    dTdt1 = dTdt(C_A, T)\n","\n","    C_A_2_1 = C_A + dCAdt1 * t_step / 2\n","    T_2_1 = T + dTdt1 * t_step / 2\n","    dCAdt2_1 = dCAdt(C_A_2_1, T_2_1)\n","    dTdt2_1 = dTdt(C_A_2_1, T_2_1)\n","\n","    C_A_2_2 = C_A + dCAdt2_1 * t_step / 2\n","    T_2_2 = T + dTdt2_1 * t_step / 2\n","    dCAdt2_2 = dCAdt(C_A_2_2, T_2_2)\n","    dTdt2_2 = dTdt(C_A_2_2, T_2_2)\n","\n","    C_A_3 = C_A + dCAdt2_2 * t_step\n","    T_3 = T + dTdt2_2 * t_step\n","    dCAdt3 = dCAdt(C_A_3, T_3)\n","    dTdt3 =  dTdt(C_A_3, T_3)\n","\n","    dCAdt2 = (dCAdt2_1 + dCAdt2_2) / 2\n","    dTdt2 = (dTdt2_1 + dTdt2_2) / 2\n","\n","    C_A_3 = C_A + t_step / 6 * (dCAdt1 + 4*dCAdt2 + dCAdt3)\n","    T_3 = T + t_step / 6 * (dTdt1 + 4*dTdt2 + dTdt3)\n","\n","    return C_A_3 - C_As, T_3 - T_s  # in deviation form"]},{"cell_type":"markdown","id":"22ee7570","metadata":{"id":"22ee7570"},"source":["# Data generation (PI-RNN) collocation points"]},{"cell_type":"code","execution_count":29,"id":"7a002e31","metadata":{"id":"7a002e31","executionInfo":{"status":"ok","timestamp":1712114141758,"user_tz":-480,"elapsed":2,"user":{"displayName":"Wang Zihao","userId":"13688795653924779981"}}},"outputs":[],"source":["# generating inputs and initial states for CSTR, all expressed in deviation form\n","\n","u1_physics_list = np.linspace(-3.5, 3.5, 10) # u1 is the inlet concentration of species A\n","u2_physics_list = np.linspace(-5e5, 5e5, 10) # u2 is the heat input rate\n","T_physics_initial = np.linspace(300, 500, 10) - T_s # inlet temperature\n","CA_physics_initial = np.linspace(0, 5, 10) - C_As # inlet concentration"]},{"cell_type":"code","execution_count":31,"id":"5db1f3e1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5db1f3e1","executionInfo":{"status":"ok","timestamp":1712114150371,"user_tz":-480,"elapsed":504,"user":{"displayName":"Wang Zihao","userId":"13688795653924779981"}},"outputId":"59370fe1-226d-406e-f2c5-6276c7eb818c"},"outputs":[{"output_type":"stream","name":"stdout","text":["number of initial conditions: 100\n","shape of x_physics_original is (100, 2)\n"]}],"source":["# sieve out initial states that lie outside of stability region\n","\n","T_physics_start = list()\n","CA_physics_start = list()\n","\n","for T in T_physics_initial:\n","    for CA in CA_physics_initial:\n","        x = np.array([CA, T])\n","        # if x @ P @ x < 1000:\n","        CA_physics_start.append(CA)\n","        T_physics_start.append(T)\n","\n","print(\"number of initial conditions: {}\".format(len(CA_physics_start)))\n","\n","# convert to np.arrays\n","CA_physics_start = np.array([CA_physics_start])\n","T_physics_start = np.array([T_physics_start])\n","x_physics_original = np.concatenate((CA_physics_start.T, T_physics_start.T), axis=1)  # every row is a pair of initial states within stability region\n","print(\"shape of x_physics_original is {}\".format(x_physics_original.shape))"]},{"cell_type":"code","execution_count":32,"id":"608f72a6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"608f72a6","executionInfo":{"status":"ok","timestamp":1712114154578,"user_tz":-480,"elapsed":1437,"user":{"displayName":"Wang Zihao","userId":"13688795653924779981"}},"outputId":"fbcfcbe2-d2f2-42b1-f4e1-5165a89dd6e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["1 out of 10\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-28-50459b598c9b>:6: RuntimeWarning: overflow encountered in scalar power\n","  return F / V * (C_A0 - C_A) - k_0 * np.exp(-E / (R * T)) * C_A**2\n","<ipython-input-28-50459b598c9b>:8: RuntimeWarning: overflow encountered in scalar power\n","  return F / V * (T_0 - T) - delta_H / (rho_L * C_p) * k_0 * np.exp(-E / (R * T)) * C_A**2 + Q / (rho_L * C_p * V)\n","<ipython-input-28-50459b598c9b>:6: RuntimeWarning: invalid value encountered in scalar subtract\n","  return F / V * (C_A0 - C_A) - k_0 * np.exp(-E / (R * T)) * C_A**2\n","<ipython-input-28-50459b598c9b>:8: RuntimeWarning: invalid value encountered in scalar subtract\n","  return F / V * (T_0 - T) - delta_H / (rho_L * C_p) * k_0 * np.exp(-E / (R * T)) * C_A**2 + Q / (rho_L * C_p * V)\n","<ipython-input-28-50459b598c9b>:6: RuntimeWarning: overflow encountered in scalar multiply\n","  return F / V * (C_A0 - C_A) - k_0 * np.exp(-E / (R * T)) * C_A**2\n","<ipython-input-28-50459b598c9b>:8: RuntimeWarning: overflow encountered in scalar multiply\n","  return F / V * (T_0 - T) - delta_H / (rho_L * C_p) * k_0 * np.exp(-E / (R * T)) * C_A**2 + Q / (rho_L * C_p * V)\n"]},{"output_type":"stream","name":"stdout","text":["2 out of 10\n","3 out of 10\n","4 out of 10\n","5 out of 10\n","6 out of 10\n","7 out of 10\n","8 out of 10\n","9 out of 10\n","10 out of 10\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-28-50459b598c9b>:34: RuntimeWarning: overflow encountered in scalar multiply\n","  T_3 = T + t_step / 6 * (dTdt1 + 4*dTdt2 + dTdt3)\n"]}],"source":["# get X and y data for physics-informed loss\n","\n","CA_physics_output = list()\n","T_physics_output = list()\n","CA_physics_input = list()\n","T_physics_input = list()\n","CA0_physics_input = list()\n","Q_physics_input = list()\n","\n","for num_id, u1 in enumerate(u1_physics_list):\n","    print(f\"{num_id + 1} out of {u1_physics_list.shape[0]}\")    #just to count and keep track\n","    C_A0 = u1 + C_A0s\n","\n","    for u2 in u2_physics_list:\n","        Q = u2 + Q_s\n","\n","        for C_A_initial, T_initial in x_physics_original:\n","            CA0_physics_input.append(u1)\n","            Q_physics_input.append(u2)\n","            CA_physics_input.append(C_A_initial)\n","            T_physics_input.append(T_initial)\n","            C_A_list = [C_A_initial]\n","            T_list = [T_initial]\n","\n","\n","            for _ in range(int(t_final / t_step)):\n","                CA_next, T_next = CSTR_simulation_Euler(F, V, C_A0, k_0, E, R, T_0, delta_H, rho_L, C_p, Q, C_As, T_s, t_final, t_step, C_A_initial, T_initial)\n","                C_A_list.append(CA_next)\n","                T_list.append(T_next)\n","                C_A_initial = CA_next\n","                T_initial = T_next\n","\n","            CA_physics_output.append(C_A_list)\n","            T_physics_output.append(T_list)"]},{"cell_type":"code","execution_count":33,"id":"36fe5111","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"36fe5111","executionInfo":{"status":"ok","timestamp":1712114166965,"user_tz":-480,"elapsed":416,"user":{"displayName":"Wang Zihao","userId":"13688795653924779981"}},"outputId":"7bed9ae2-52f9-4659-f1fc-eaccdab62f1c"},"outputs":[{"output_type":"stream","name":"stdout","text":["RNN_physics_input_temp shape is (10000, 6, 4)\n","RNN_physics_output shape is (10000, 6, 2)\n","X_train shape is (6000, 6, 4), X_val shape is (2000, 6, 4), X_test shape is (2000, 6, 4)\n","y_train shape is (6000, 6, 2), y_val shape is (2000, 6, 2), y_test shape is (2000, 6, 2)\n"]}],"source":["# collate input for RNN for physics loss\n","\n","CA0_physics_input = np.array(CA0_physics_input)\n","CA0_physics_input = CA0_physics_input.reshape(-1,1,1)\n","\n","\n","Q_physics_input = np.array(Q_physics_input)\n","Q_physics_input = Q_physics_input.reshape(-1,1,1)\n","\n","\n","CA_physics_input = np.array(CA_physics_input)\n","CA_physics_input = CA_physics_input.reshape(-1,1,1)\n","\n","\n","T_physics_input = np.array(T_physics_input)\n","T_physics_input = T_physics_input.reshape(-1,1,1)\n","\n","\n","RNN_physics_input_temp = np.concatenate((CA0_physics_input, Q_physics_input, CA_physics_input, T_physics_input), axis=2)\n","\n","\"\"\"\n","    the input to RNN is in the shape [number of samples x timestep x variables], and the input variables are same for every\n","    time step\n","\"\"\"\n","\n","RNN_physics_input_temp = RNN_physics_input_temp.repeat(6, axis=1)\n","print(\"RNN_physics_input_temp shape is {}\".format(RNN_physics_input_temp.shape))\n","\n","############################## collate output for RNN ####################################################\n","\n","CA_physics_output = np.array(CA_physics_output)\n","CA_physics_output = CA_physics_output.reshape(-1, 6, 1)\n","\n","T_physics_output = np.array(T_physics_output)\n","T_physics_output = T_physics_output.reshape(-1, 6, 1)\n","\n","RNN_physics_output = np.concatenate((CA_physics_output, T_physics_output), axis=2)\n","print(\"RNN_physics_output shape is {}\".format(RNN_physics_output.shape))  # output shape: number of samples x timestep x variables\n","\n","############################# Split Train, Test, and Validation dataset ##################################\n","\n","X_train, X_test, y_train, y_test = train_test_split(RNN_physics_input_temp, RNN_physics_output, test_size=0.2, random_state=123)\n","\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=123) # 0.25 x 0.8 = 0.2\n","\n","print(f\"X_train shape is {X_train.shape}, X_val shape is {X_val.shape}, X_test shape is {X_test.shape}\")\n","print(f\"y_train shape is {y_train.shape}, y_val shape is {y_val.shape}, y_test shape is {y_test.shape}\")"]},{"cell_type":"code","execution_count":34,"id":"32825d59","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"32825d59","executionInfo":{"status":"ok","timestamp":1712114174752,"user_tz":-480,"elapsed":450,"user":{"displayName":"Wang Zihao","userId":"13688795653924779981"}},"outputId":"99eacb30-f90b-4c2d-9036-82e9d035904c"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([  2.5039, 399.6630])\n"]}],"source":["# Extract mean and standard deviation to standardize both the input and output data\n","\n","mean_CA0 = np.mean(X_train[:, 0, 0].reshape(-1))\n","std_CA0 = np.std(X_train[:, 0, 0].reshape(-1))\n","\n","mean_Q = np.mean(X_train[:, 0, 1].reshape(-1))\n","std_Q = np.std(X_train[:, 0, 1].reshape(-1))\n","\n","mean_CA_input = np.mean(X_train[:, 0, -2].reshape(-1))\n","std_CA_input = np.std(X_train[:, 0, -2].reshape(-1))\n","\n","mean_T_input = np.mean(X_train[:, 0, -1].reshape(-1))\n","std_T_input = np.std(X_train[:, 0, -1].reshape(-1))\n","\n","# mean and standard deviation of the input data is used to scale the output data\n","\n","mean_y = np.concatenate((mean_CA_input.reshape(-1), mean_T_input.reshape(-1)))\n","std_y = np.concatenate((std_CA_input.reshape(-1), std_T_input.reshape(-1)))\n","\n","mean_y = torch.from_numpy(mean_y).float()\n","std_y = torch.from_numpy(std_y).float()\n","\n","print(mean_y)"]},{"cell_type":"code","execution_count":35,"id":"82fe45e7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"82fe45e7","executionInfo":{"status":"ok","timestamp":1712114178336,"user_tz":-480,"elapsed":368,"user":{"displayName":"Wang Zihao","userId":"13688795653924779981"}},"outputId":"3b2ee1e8-bf33-4ccd-ee0c-db4de02a70fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["X_physics shape is: torch.Size([6000, 6, 4])\n"]}],"source":["# scale the input of the Traininng, Testing, and Validation dataset\n","\n","X_physics_train = (X_train - [mean_CA0, mean_Q, mean_CA_input, mean_T_input]) / [std_CA0, std_Q, std_CA_input, std_T_input]\n","X_physics_train = torch.from_numpy(X_physics_train).float()\n","\n","X_physics_val = (X_val - [mean_CA0, mean_Q, mean_CA_input, mean_T_input]) / [std_CA0, std_Q, std_CA_input, std_T_input]\n","X_physics_val = torch.from_numpy(X_physics_val).float()\n","\n","X_physics_test = (X_test - [mean_CA0, mean_Q, mean_CA_input, mean_T_input]) / [std_CA0, std_Q, std_CA_input, std_T_input]\n","X_physics_test = torch.from_numpy(X_physics_test).float()\n","\n","y_physics_test = torch.from_numpy(y_test).float().view(-1, 6, 2)\n","# y_physics = (y_physics - mean_y) / (std_y)\n","\n","print(f'X_physics shape is: {X_physics_train.shape}')"]},{"cell_type":"markdown","id":"b954379a","metadata":{"id":"b954379a"},"source":["# Preparing dataset for PyTorch"]},{"cell_type":"code","execution_count":36,"id":"0704ff58","metadata":{"id":"0704ff58","executionInfo":{"status":"ok","timestamp":1712114181380,"user_tz":-480,"elapsed":425,"user":{"displayName":"Wang Zihao","userId":"13688795653924779981"}}},"outputs":[],"source":["dataset_physics_train = TensorDataset(X_physics_train)\n","dataloader_physics_train = DataLoader(dataset_physics_train, batch_size=2048, shuffle=True)\n","\n","dataset_physics_val = TensorDataset(X_physics_val)\n","dataloader_physics_val = DataLoader(dataset_physics_val, batch_size=2048, shuffle=True)\n","\n","dataset_physics_test = TensorDataset(X_physics_test)\n","dataloader_physics_test = DataLoader(dataset_physics_test, batch_size=1, shuffle=False)"]},{"cell_type":"markdown","id":"9897beae","metadata":{"id":"9897beae"},"source":["# Defining RNN"]},{"cell_type":"code","execution_count":37,"id":"6fc02715","metadata":{"id":"6fc02715","executionInfo":{"status":"ok","timestamp":1712114184362,"user_tz":-480,"elapsed":362,"user":{"displayName":"Wang Zihao","userId":"13688795653924779981"}}},"outputs":[],"source":["class RNN(nn.Module):\n","    \"Defines a RNN network\"\n","\n","    def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS):\n","        super(RNN, self).__init__()\n","        self.layers = N_LAYERS\n","\n","        if isinstance(N_HIDDEN, list):\n","            self.rnn = nn.LSTM(N_INPUT,\n","                                N_HIDDEN[0],\n","                                batch_first=True)\n","\n","            self.rnn1 = nn.ModuleList(\n","                [nn.LSTM(N_HIDDEN[i],\n","                        N_HIDDEN[i+1],\n","                       batch_first=True) for i in range(N_LAYERS - 1)]\n","            )\n","\n","            self.output_layer = nn.Linear(N_HIDDEN[-1], N_OUTPUT)\n","\n","            self.list_flag = True\n","\n","        else:\n","            self.rnn = nn.LSTM(N_INPUT,\n","                                N_HIDDEN,\n","                                N_LAYERS,\n","                                batch_first=True,\n","                                dropout=0.1)\n","\n","            self.output_layer = nn.Linear(N_HIDDEN, N_OUTPUT)\n","\n","            self.list_flag = False\n","\n","\n","\n","\n","\n","\n","    def forward(self, x):\n","        x, _ = self.rnn(x)\n","\n","        if self.list_flag:\n","            for i in range(self.layers - 1):\n","                x, _ = self.rnn1[i](x)\n","\n","        x = self.output_layer(x)\n","        return x"]},{"cell_type":"markdown","id":"4463dcc5","metadata":{"id":"4463dcc5"},"source":["# Physics-informed RNN"]},{"cell_type":"code","execution_count":38,"id":"17ffc6a8","metadata":{"id":"17ffc6a8","executionInfo":{"status":"ok","timestamp":1712114186657,"user_tz":-480,"elapsed":3,"user":{"displayName":"Wang Zihao","userId":"13688795653924779981"}}},"outputs":[],"source":["def train_model(model, patience, n_epochs):\n","\n","    # to track the training loss as the model trains\n","    train_losses = []\n","    # to track the validation loss as the model trains\n","    valid_losses = []\n","    # to track the average training loss per epoch as the model trains\n","    avg_train_losses = []\n","    # to track the average validation loss per epoch as the model trains\n","    avg_valid_losses = []\n","\n","    # initialize the early_stopping object\n","    early_stopping = EarlyStopping(patience=patience, verbose=True)\n","\n","    for epoch in range(1, n_epochs + 1):\n","\n","        ###################\n","        # train the model #\n","        ###################\n","        model.train() # prep model for training\n","        for batch, x_batch in enumerate(dataloader_physics_train, 1):\n","            # clear the gradients of all optimized variables\n","            x_batch = x_batch[0].to(device)\n","            optimizer.zero_grad()\n","\n","            NN_output = model_PINN(x_batch)\n","\n","            loss1 = torch.mean((NN_output[:, 0, :] - x_batch[:, 0, -2:])**2)  # use mean squared error\n","\n","            # compute the \"physics loss\"\n","\n","            C_A0 = x_batch[:, :, 0] * std_CA0 + mean_CA0 + C_A0s\n","            Q = x_batch[:, :, 1] * std_Q + mean_Q + Q_s\n","\n","            NN_output = NN_output * std_y.to(device) + mean_y.to(device) + torch.from_numpy(np.array([C_As, T_s])).float().to(device)\n","\n","            dCA_first = (NN_output[:, 1:2, 0] - NN_output[:, 0:1, 0]) / (t_step)\n","            dT_first = (NN_output[:, 1:2, 1] - NN_output[:, 0:1, 1]) / (t_step)\n","\n","            dCA_center = (NN_output[:, 2:, 0] - NN_output[:, :-2, 0]) / (2 * t_step)\n","            dT_center = (NN_output[:, 2:, 1] - NN_output[:, :-2, 1]) / (2 * t_step)\n","\n","            dCA_last = (NN_output[:, -1:, 0] - NN_output[:, -2:-1, 0]) / (t_step)\n","            dT_last = (NN_output[:, -1:, 1] - NN_output[:, -2:-1, 1]) / (t_step)\n","\n","\n","            dCA = torch.cat((dCA_first, dCA_center, dCA_last), 1)\n","            dT = torch.cat((dT_first, dT_center, dT_last), 1)\n","\n","\n","            # Physics-based Concentration loss\n","            loss3 = dCA - F / V * (C_A0 - NN_output[:, :, 0]) + k_0 * torch.exp(-E / (R * NN_output[:, :, 1])) * NN_output[:, :, 0]**2\n","            loss3 = torch.mean(loss3**2)\n","\n","            # Physics-based Temperature loss\n","            loss4 = dT - F / V * (T_0 - NN_output[:, :, 1]) + delta_H / (rho_L * C_p) * k_0 * torch.exp(-E / (R * NN_output[:, :, 1])) * NN_output[:, :, 0]**2 - Q / (rho_L * C_p * V)\n","            loss4 = torch.mean(loss4**2)\n","\n","            # backpropagate joint loss using appropriate scaling factors\n","            loss = 1e3 * loss1 + 1e-1 * loss3 + 1e-5 * loss4 # add all loss terms together\n","\n","            print(loss3)\n","            print(loss4)\n","\n","            # backward pass: compute gradient of the loss with respect to model parameters\n","            loss.backward()\n","            # perform a single optimization step (parameter update)\n","            optimizer.step()\n","            # record training loss\n","            train_losses.append(loss.item())\n","\n","        ######################\n","        # validate the model #\n","        ######################\n","        model.eval() # prep model for evaluation\n","        for val_batch in dataloader_physics_val:\n","            # forward pass: compute predicted outputs by passing inputs to the model\n","            val_batch = val_batch[0].to(device)\n","            NN_output = model(val_batch)\n","\n","            loss1 = torch.mean((NN_output[:, 0, :] - val_batch[:, 0, -2:])**2)  # use mean squared error\n","\n","            # compute the \"physics loss\"\n","\n","            C_A0 = val_batch[:, :, 0] * std_CA0 + mean_CA0 + C_A0s\n","            Q = val_batch[:, :, 1] * std_Q + mean_Q + Q_s\n","\n","            NN_output = NN_output * std_y.to(device) + mean_y.to(device) + torch.from_numpy(np.array([C_As, T_s])).float().to(device)\n","\n","            dCA_first = (NN_output[:, 1:2, 0] - NN_output[:, 0:1, 0]) / (t_step)\n","            dT_first = (NN_output[:, 1:2, 1] - NN_output[:, 0:1, 1]) / (t_step)\n","\n","            dCA_center = (NN_output[:, 2:, 0] - NN_output[:, :-2, 0]) / (2 * t_step)\n","            dT_center = (NN_output[:, 2:, 1] - NN_output[:, :-2, 1]) / (2 * t_step)\n","\n","            dCA_last = (NN_output[:, -1:, 0] - NN_output[:, -2:-1, 0]) / (t_step)\n","            dT_last = (NN_output[:, -1:, 1] - NN_output[:, -2:-1, 1]) / (t_step)\n","\n","\n","            dCA = torch.cat((dCA_first, dCA_center, dCA_last), 1)\n","            dT = torch.cat((dT_first, dT_center, dT_last), 1)\n","\n","\n","            # Physics-based Concentration loss\n","            loss3 = dCA - F / V * (C_A0 - NN_output[:, :, 0]) + k_0 * torch.exp(-E / (R * NN_output[:, :, 1])) * NN_output[:, :, 0]**2\n","            loss3 = torch.mean(loss3**2)\n","\n","            # Physics-based Temperature loss\n","            loss4 = dT - F / V * (T_0 - NN_output[:, :, 1]) + delta_H / (rho_L * C_p) * k_0 * torch.exp(-E / (R * NN_output[:, :, 1])) * NN_output[:, :, 0]**2 - Q / (rho_L * C_p * V)\n","            loss4 = torch.mean(loss4**2)\n","\n","            # backpropagate joint loss using appropriate scaling factors\n","            loss = 1e3 * loss1 + 1e-1 * loss3 + 1e-5 * loss4 # add all loss terms together\n","\n","            # record validation loss\n","            valid_losses.append(loss.item())\n","\n","        # print training/validation statistics\n","        # calculate average loss over an epoch\n","        train_loss = np.average(train_losses)\n","        valid_loss = np.average(valid_losses)\n","        avg_train_losses.append(train_loss)\n","        avg_valid_losses.append(valid_loss)\n","\n","        epoch_len = len(str(n_epochs))\n","\n","        print_msg = (f'[{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +\n","                     f'train_loss: {train_loss:.5f} ' +\n","                     f'valid_loss: {valid_loss:.5f}')\n","\n","        print(print_msg)\n","\n","        # clear lists to track next epoch\n","        train_losses = []\n","        valid_losses = []\n","\n","        # early_stopping needs the validation loss to check if it has decresed,\n","        # and if it has, it will make a checkpoint of the current model\n","        early_stopping(valid_loss, model)\n","\n","        if early_stopping.early_stop:\n","            print(\"Early stopping\")\n","            break\n","\n","    # load the last checkpoint with the best model\n","    model.load_state_dict(torch.load('checkpoint.pt'))\n","\n","    return  model, avg_train_losses, avg_valid_losses"]},{"cell_type":"code","execution_count":39,"id":"6ee48f4a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ee48f4a","executionInfo":{"status":"ok","timestamp":1712114867193,"user_tz":-480,"elapsed":677851,"user":{"displayName":"Wang Zihao","userId":"13688795653924779981"}},"outputId":"9aaa42e4-0075-4192-a8ec-a81bb7571ac6"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","tensor(37.8721, grad_fn=<MeanBackward0>)\n","tensor(431291.7188, grad_fn=<MeanBackward0>)\n","tensor(39.8494, grad_fn=<MeanBackward0>)\n","tensor(407117.8438, grad_fn=<MeanBackward0>)\n","tensor(39.2692, grad_fn=<MeanBackward0>)\n","tensor(421124.1250, grad_fn=<MeanBackward0>)\n","[ 376/1000] train_loss: 25.94855 valid_loss: 12.49706\n","Validation loss decreased (12.504342 --> 12.497058).  Saving model ...\n","tensor(38.2126, grad_fn=<MeanBackward0>)\n","tensor(398072.7188, grad_fn=<MeanBackward0>)\n","tensor(40.9707, grad_fn=<MeanBackward0>)\n","tensor(403226.3750, grad_fn=<MeanBackward0>)\n","tensor(39.1702, grad_fn=<MeanBackward0>)\n","tensor(418242.0625, grad_fn=<MeanBackward0>)\n","[ 377/1000] train_loss: 25.81022 valid_loss: 12.48049\n","Validation loss decreased (12.497058 --> 12.480488).  Saving model ...\n","tensor(38.8997, grad_fn=<MeanBackward0>)\n","tensor(360814.7812, grad_fn=<MeanBackward0>)\n","tensor(38.2271, grad_fn=<MeanBackward0>)\n","tensor(379032.0312, grad_fn=<MeanBackward0>)\n","tensor(44.7485, grad_fn=<MeanBackward0>)\n","tensor(398458.0938, grad_fn=<MeanBackward0>)\n","[ 378/1000] train_loss: 25.65479 valid_loss: 12.44077\n","Validation loss decreased (12.480488 --> 12.440773).  Saving model ...\n","tensor(41.1967, grad_fn=<MeanBackward0>)\n","tensor(420731.7812, grad_fn=<MeanBackward0>)\n","tensor(40.6924, grad_fn=<MeanBackward0>)\n","tensor(385087.1562, grad_fn=<MeanBackward0>)\n","tensor(39.6247, grad_fn=<MeanBackward0>)\n","tensor(376427.0312, grad_fn=<MeanBackward0>)\n","[ 379/1000] train_loss: 25.86888 valid_loss: 12.45609\n","EarlyStopping counter: 1 out of 20\n","tensor(39.8023, grad_fn=<MeanBackward0>)\n","tensor(422520.9688, grad_fn=<MeanBackward0>)\n","tensor(41.9068, grad_fn=<MeanBackward0>)\n","tensor(424594.2500, grad_fn=<MeanBackward0>)\n","tensor(36.4894, grad_fn=<MeanBackward0>)\n","tensor(378708.1250, grad_fn=<MeanBackward0>)\n","[ 380/1000] train_loss: 25.73192 valid_loss: 12.42971\n","Validation loss decreased (12.440773 --> 12.429708).  Saving model ...\n","tensor(39.6429, grad_fn=<MeanBackward0>)\n","tensor(419976.5000, grad_fn=<MeanBackward0>)\n","tensor(37.9345, grad_fn=<MeanBackward0>)\n","tensor(403719.7188, grad_fn=<MeanBackward0>)\n","tensor(41.0118, grad_fn=<MeanBackward0>)\n","tensor(356461.6562, grad_fn=<MeanBackward0>)\n","[ 381/1000] train_loss: 25.62534 valid_loss: 12.44177\n","EarlyStopping counter: 1 out of 20\n","tensor(40.8223, grad_fn=<MeanBackward0>)\n","tensor(365362.7812, grad_fn=<MeanBackward0>)\n","tensor(41.1133, grad_fn=<MeanBackward0>)\n","tensor(399158.4688, grad_fn=<MeanBackward0>)\n","tensor(38.4737, grad_fn=<MeanBackward0>)\n","tensor(380017.2188, grad_fn=<MeanBackward0>)\n","[ 382/1000] train_loss: 25.42130 valid_loss: 12.40838\n","Validation loss decreased (12.429708 --> 12.408379).  Saving model ...\n","tensor(41.1003, grad_fn=<MeanBackward0>)\n","tensor(436903.4688, grad_fn=<MeanBackward0>)\n","tensor(40.5112, grad_fn=<MeanBackward0>)\n","tensor(391450.2188, grad_fn=<MeanBackward0>)\n","tensor(36.3065, grad_fn=<MeanBackward0>)\n","tensor(394573.5000, grad_fn=<MeanBackward0>)\n","[ 383/1000] train_loss: 25.26775 valid_loss: 12.41462\n","EarlyStopping counter: 1 out of 20\n","tensor(39.3722, grad_fn=<MeanBackward0>)\n","tensor(377904.7500, grad_fn=<MeanBackward0>)\n","tensor(39.0650, grad_fn=<MeanBackward0>)\n","tensor(426562.5312, grad_fn=<MeanBackward0>)\n","tensor(39.2638, grad_fn=<MeanBackward0>)\n","tensor(399711.6875, grad_fn=<MeanBackward0>)\n","[ 384/1000] train_loss: 25.96185 valid_loss: 12.50809\n","EarlyStopping counter: 2 out of 20\n","tensor(43.2938, grad_fn=<MeanBackward0>)\n","tensor(382701.8750, grad_fn=<MeanBackward0>)\n","tensor(39.3351, grad_fn=<MeanBackward0>)\n","tensor(397763.7812, grad_fn=<MeanBackward0>)\n","tensor(37.6487, grad_fn=<MeanBackward0>)\n","tensor(382809.5000, grad_fn=<MeanBackward0>)\n","[ 385/1000] train_loss: 25.23111 valid_loss: 12.39296\n","Validation loss decreased (12.408379 --> 12.392957).  Saving model ...\n","tensor(40.9301, grad_fn=<MeanBackward0>)\n","tensor(374913.2812, grad_fn=<MeanBackward0>)\n","tensor(38.4512, grad_fn=<MeanBackward0>)\n","tensor(403178.5000, grad_fn=<MeanBackward0>)\n","tensor(38.5147, grad_fn=<MeanBackward0>)\n","tensor(441061.7812, grad_fn=<MeanBackward0>)\n","[ 386/1000] train_loss: 25.45454 valid_loss: 12.37534\n","Validation loss decreased (12.392957 --> 12.375340).  Saving model ...\n","tensor(37.5782, grad_fn=<MeanBackward0>)\n","tensor(407520.9688, grad_fn=<MeanBackward0>)\n","tensor(40.9038, grad_fn=<MeanBackward0>)\n","tensor(374609.2500, grad_fn=<MeanBackward0>)\n","tensor(40.0324, grad_fn=<MeanBackward0>)\n","tensor(421919.4062, grad_fn=<MeanBackward0>)\n","[ 387/1000] train_loss: 25.60721 valid_loss: 12.37006\n","Validation loss decreased (12.375340 --> 12.370056).  Saving model ...\n","tensor(38.5845, grad_fn=<MeanBackward0>)\n","tensor(363303.1562, grad_fn=<MeanBackward0>)\n","tensor(39.6595, grad_fn=<MeanBackward0>)\n","tensor(427524., grad_fn=<MeanBackward0>)\n","tensor(41.3052, grad_fn=<MeanBackward0>)\n","tensor(407023.5625, grad_fn=<MeanBackward0>)\n","[ 388/1000] train_loss: 25.20320 valid_loss: 12.37623\n","EarlyStopping counter: 1 out of 20\n","tensor(42.3278, grad_fn=<MeanBackward0>)\n","tensor(411180.7500, grad_fn=<MeanBackward0>)\n","tensor(37.0930, grad_fn=<MeanBackward0>)\n","tensor(398564., grad_fn=<MeanBackward0>)\n","tensor(35.0321, grad_fn=<MeanBackward0>)\n","tensor(398635.2812, grad_fn=<MeanBackward0>)\n","[ 389/1000] train_loss: 25.26148 valid_loss: 12.36416\n","Validation loss decreased (12.370056 --> 12.364161).  Saving model ...\n","tensor(38.1240, grad_fn=<MeanBackward0>)\n","tensor(400609.1562, grad_fn=<MeanBackward0>)\n","tensor(38.8649, grad_fn=<MeanBackward0>)\n","tensor(380460.1562, grad_fn=<MeanBackward0>)\n","tensor(40.2217, grad_fn=<MeanBackward0>)\n","tensor(381936.8125, grad_fn=<MeanBackward0>)\n","[ 390/1000] train_loss: 25.41999 valid_loss: 12.32857\n","Validation loss decreased (12.364161 --> 12.328569).  Saving model ...\n","tensor(37.2373, grad_fn=<MeanBackward0>)\n","tensor(391460., grad_fn=<MeanBackward0>)\n","tensor(38.6352, grad_fn=<MeanBackward0>)\n","tensor(377426.9688, grad_fn=<MeanBackward0>)\n","tensor(42.3043, grad_fn=<MeanBackward0>)\n","tensor(407790.8438, grad_fn=<MeanBackward0>)\n","[ 391/1000] train_loss: 25.14971 valid_loss: 12.31743\n","Validation loss decreased (12.328569 --> 12.317434).  Saving model ...\n","tensor(40.8665, grad_fn=<MeanBackward0>)\n","tensor(383731.4062, grad_fn=<MeanBackward0>)\n","tensor(38.9855, grad_fn=<MeanBackward0>)\n","tensor(407707.9688, grad_fn=<MeanBackward0>)\n","tensor(40.0251, grad_fn=<MeanBackward0>)\n","tensor(347475.2812, grad_fn=<MeanBackward0>)\n","[ 392/1000] train_loss: 25.21047 valid_loss: 12.31821\n","EarlyStopping counter: 1 out of 20\n","tensor(36.1824, grad_fn=<MeanBackward0>)\n","tensor(346640., grad_fn=<MeanBackward0>)\n","tensor(39.4531, grad_fn=<MeanBackward0>)\n","tensor(414665.0312, grad_fn=<MeanBackward0>)\n","tensor(39.9702, grad_fn=<MeanBackward0>)\n","tensor(437386.9375, grad_fn=<MeanBackward0>)\n","[ 393/1000] train_loss: 25.08455 valid_loss: 12.31210\n","Validation loss decreased (12.317434 --> 12.312098).  Saving model ...\n","tensor(36.8539, grad_fn=<MeanBackward0>)\n","tensor(385390.7500, grad_fn=<MeanBackward0>)\n","tensor(41.6743, grad_fn=<MeanBackward0>)\n","tensor(408352.4062, grad_fn=<MeanBackward0>)\n","tensor(39.1147, grad_fn=<MeanBackward0>)\n","tensor(363823.7500, grad_fn=<MeanBackward0>)\n","[ 394/1000] train_loss: 25.30848 valid_loss: 12.28817\n","Validation loss decreased (12.312098 --> 12.288170).  Saving model ...\n","tensor(36.4284, grad_fn=<MeanBackward0>)\n","tensor(398310.0938, grad_fn=<MeanBackward0>)\n","tensor(36.4366, grad_fn=<MeanBackward0>)\n","tensor(362316.2500, grad_fn=<MeanBackward0>)\n","tensor(40.1672, grad_fn=<MeanBackward0>)\n","tensor(409132.1875, grad_fn=<MeanBackward0>)\n","[ 395/1000] train_loss: 24.84630 valid_loss: 12.28487\n","Validation loss decreased (12.288170 --> 12.284870).  Saving model ...\n","tensor(39.0038, grad_fn=<MeanBackward0>)\n","tensor(390272.1562, grad_fn=<MeanBackward0>)\n","tensor(39.3239, grad_fn=<MeanBackward0>)\n","tensor(396626.9688, grad_fn=<MeanBackward0>)\n","tensor(40.6741, grad_fn=<MeanBackward0>)\n","tensor(415162.5000, grad_fn=<MeanBackward0>)\n","[ 396/1000] train_loss: 25.25732 valid_loss: 12.25750\n","Validation loss decreased (12.284870 --> 12.257500).  Saving model ...\n","tensor(38.8248, grad_fn=<MeanBackward0>)\n","tensor(399046.0312, grad_fn=<MeanBackward0>)\n","tensor(40.2635, grad_fn=<MeanBackward0>)\n","tensor(376177.5312, grad_fn=<MeanBackward0>)\n","tensor(39.6500, grad_fn=<MeanBackward0>)\n","tensor(388721.1562, grad_fn=<MeanBackward0>)\n","[ 397/1000] train_loss: 25.51790 valid_loss: 12.23849\n","Validation loss decreased (12.257500 --> 12.238490).  Saving model ...\n","tensor(38.2148, grad_fn=<MeanBackward0>)\n","tensor(385816.2500, grad_fn=<MeanBackward0>)\n","tensor(38.6849, grad_fn=<MeanBackward0>)\n","tensor(386295.2500, grad_fn=<MeanBackward0>)\n","tensor(38.6542, grad_fn=<MeanBackward0>)\n","tensor(384993.0312, grad_fn=<MeanBackward0>)\n","[ 398/1000] train_loss: 25.07606 valid_loss: 12.25615\n","EarlyStopping counter: 1 out of 20\n","tensor(42.1454, grad_fn=<MeanBackward0>)\n","tensor(422622.1562, grad_fn=<MeanBackward0>)\n","tensor(38.1999, grad_fn=<MeanBackward0>)\n","tensor(397938.7188, grad_fn=<MeanBackward0>)\n","tensor(33.3044, grad_fn=<MeanBackward0>)\n","tensor(391169.6562, grad_fn=<MeanBackward0>)\n","[ 399/1000] train_loss: 25.45433 valid_loss: 12.31361\n","EarlyStopping counter: 2 out of 20\n","tensor(37.8423, grad_fn=<MeanBackward0>)\n","tensor(394509.2812, grad_fn=<MeanBackward0>)\n","tensor(42.5832, grad_fn=<MeanBackward0>)\n","tensor(415205.3750, grad_fn=<MeanBackward0>)\n","tensor(34.7458, grad_fn=<MeanBackward0>)\n","tensor(365543.2500, grad_fn=<MeanBackward0>)\n","[ 400/1000] train_loss: 25.01810 valid_loss: 12.32354\n","EarlyStopping counter: 3 out of 20\n","tensor(39.3758, grad_fn=<MeanBackward0>)\n","tensor(376540.7500, grad_fn=<MeanBackward0>)\n","tensor(37.8287, grad_fn=<MeanBackward0>)\n","tensor(393365.9062, grad_fn=<MeanBackward0>)\n","tensor(37.8739, grad_fn=<MeanBackward0>)\n","tensor(382347.7500, grad_fn=<MeanBackward0>)\n","[ 401/1000] train_loss: 25.19908 valid_loss: 12.26218\n","EarlyStopping counter: 4 out of 20\n","tensor(40.1001, grad_fn=<MeanBackward0>)\n","tensor(396430.0938, grad_fn=<MeanBackward0>)\n","tensor(39.0668, grad_fn=<MeanBackward0>)\n","tensor(376042.8750, grad_fn=<MeanBackward0>)\n","tensor(40.3925, grad_fn=<MeanBackward0>)\n","tensor(396893.3125, grad_fn=<MeanBackward0>)\n","[ 402/1000] train_loss: 25.04175 valid_loss: 12.20828\n","Validation loss decreased (12.238490 --> 12.208284).  Saving model ...\n","tensor(35.0379, grad_fn=<MeanBackward0>)\n","tensor(371821.1250, grad_fn=<MeanBackward0>)\n","tensor(40.1202, grad_fn=<MeanBackward0>)\n","tensor(394209.7188, grad_fn=<MeanBackward0>)\n","tensor(40.1146, grad_fn=<MeanBackward0>)\n","tensor(404856.1250, grad_fn=<MeanBackward0>)\n","[ 403/1000] train_loss: 24.93736 valid_loss: 12.19079\n","Validation loss decreased (12.208284 --> 12.190786).  Saving model ...\n","tensor(35.4250, grad_fn=<MeanBackward0>)\n","tensor(362096.0938, grad_fn=<MeanBackward0>)\n","tensor(39.0360, grad_fn=<MeanBackward0>)\n","tensor(373523.6250, grad_fn=<MeanBackward0>)\n","tensor(43.1790, grad_fn=<MeanBackward0>)\n","tensor(414920.9062, grad_fn=<MeanBackward0>)\n","[ 404/1000] train_loss: 24.72605 valid_loss: 12.19272\n","EarlyStopping counter: 1 out of 20\n","tensor(38.3594, grad_fn=<MeanBackward0>)\n","tensor(360887.2812, grad_fn=<MeanBackward0>)\n","tensor(38.6376, grad_fn=<MeanBackward0>)\n","tensor(386481.2812, grad_fn=<MeanBackward0>)\n","tensor(39.7475, grad_fn=<MeanBackward0>)\n","tensor(399253.6875, grad_fn=<MeanBackward0>)\n","[ 405/1000] train_loss: 24.92705 valid_loss: 12.19735\n","EarlyStopping counter: 2 out of 20\n","tensor(39.8926, grad_fn=<MeanBackward0>)\n","tensor(410530.2812, grad_fn=<MeanBackward0>)\n","tensor(36.3211, grad_fn=<MeanBackward0>)\n","tensor(361697.7500, grad_fn=<MeanBackward0>)\n","tensor(37.4140, grad_fn=<MeanBackward0>)\n","tensor(378521.9375, grad_fn=<MeanBackward0>)\n","[ 406/1000] train_loss: 24.88122 valid_loss: 12.19630\n","EarlyStopping counter: 3 out of 20\n","tensor(36.1585, grad_fn=<MeanBackward0>)\n","tensor(396392.8438, grad_fn=<MeanBackward0>)\n","tensor(39.2031, grad_fn=<MeanBackward0>)\n","tensor(400409., grad_fn=<MeanBackward0>)\n","tensor(36.8487, grad_fn=<MeanBackward0>)\n","tensor(387577.8125, grad_fn=<MeanBackward0>)\n","[ 407/1000] train_loss: 24.74039 valid_loss: 12.19169\n","EarlyStopping counter: 4 out of 20\n","tensor(39.8074, grad_fn=<MeanBackward0>)\n","tensor(425576.3750, grad_fn=<MeanBackward0>)\n","tensor(35.4136, grad_fn=<MeanBackward0>)\n","tensor(372322.5000, grad_fn=<MeanBackward0>)\n","tensor(36.8347, grad_fn=<MeanBackward0>)\n","tensor(365099.5625, grad_fn=<MeanBackward0>)\n","[ 408/1000] train_loss: 25.11033 valid_loss: 12.23860\n","EarlyStopping counter: 5 out of 20\n","tensor(36.0826, grad_fn=<MeanBackward0>)\n","tensor(336446.0938, grad_fn=<MeanBackward0>)\n","tensor(39.1146, grad_fn=<MeanBackward0>)\n","tensor(409136.7188, grad_fn=<MeanBackward0>)\n","tensor(38.2912, grad_fn=<MeanBackward0>)\n","tensor(382687.5625, grad_fn=<MeanBackward0>)\n","[ 409/1000] train_loss: 24.43052 valid_loss: 12.16845\n","Validation loss decreased (12.190786 --> 12.168453).  Saving model ...\n","tensor(39.9166, grad_fn=<MeanBackward0>)\n","tensor(367408.3438, grad_fn=<MeanBackward0>)\n","tensor(40.9072, grad_fn=<MeanBackward0>)\n","tensor(395725.5312, grad_fn=<MeanBackward0>)\n","tensor(37.1338, grad_fn=<MeanBackward0>)\n","tensor(373520.2812, grad_fn=<MeanBackward0>)\n","[ 410/1000] train_loss: 24.78772 valid_loss: 12.15281\n","Validation loss decreased (12.168453 --> 12.152810).  Saving model ...\n","tensor(40.0346, grad_fn=<MeanBackward0>)\n","tensor(393977.4688, grad_fn=<MeanBackward0>)\n","tensor(37.0437, grad_fn=<MeanBackward0>)\n","tensor(375824.5000, grad_fn=<MeanBackward0>)\n","tensor(37.4010, grad_fn=<MeanBackward0>)\n","tensor(385492.9688, grad_fn=<MeanBackward0>)\n","[ 411/1000] train_loss: 24.98676 valid_loss: 12.18412\n","EarlyStopping counter: 1 out of 20\n","tensor(38.2988, grad_fn=<MeanBackward0>)\n","tensor(364429.7500, grad_fn=<MeanBackward0>)\n","tensor(38.1801, grad_fn=<MeanBackward0>)\n","tensor(389960.3750, grad_fn=<MeanBackward0>)\n","tensor(34.6410, grad_fn=<MeanBackward0>)\n","tensor(388582.7812, grad_fn=<MeanBackward0>)\n","[ 412/1000] train_loss: 24.88443 valid_loss: 12.18640\n","EarlyStopping counter: 2 out of 20\n","tensor(38.3981, grad_fn=<MeanBackward0>)\n","tensor(436754.7188, grad_fn=<MeanBackward0>)\n","tensor(38.6625, grad_fn=<MeanBackward0>)\n","tensor(378082.7500, grad_fn=<MeanBackward0>)\n","tensor(35.5334, grad_fn=<MeanBackward0>)\n","tensor(361096., grad_fn=<MeanBackward0>)\n","[ 413/1000] train_loss: 24.88193 valid_loss: 12.12641\n","Validation loss decreased (12.152810 --> 12.126414).  Saving model ...\n","tensor(40.7102, grad_fn=<MeanBackward0>)\n","tensor(365353.9688, grad_fn=<MeanBackward0>)\n","tensor(38.1624, grad_fn=<MeanBackward0>)\n","tensor(379915.2188, grad_fn=<MeanBackward0>)\n","tensor(38.9446, grad_fn=<MeanBackward0>)\n","tensor(362339.2188, grad_fn=<MeanBackward0>)\n","[ 414/1000] train_loss: 24.93899 valid_loss: 12.14395\n","EarlyStopping counter: 1 out of 20\n","tensor(39.6941, grad_fn=<MeanBackward0>)\n","tensor(380749.5312, grad_fn=<MeanBackward0>)\n","tensor(38.7469, grad_fn=<MeanBackward0>)\n","tensor(373889.5938, grad_fn=<MeanBackward0>)\n","tensor(36.5685, grad_fn=<MeanBackward0>)\n","tensor(388653.1875, grad_fn=<MeanBackward0>)\n","[ 415/1000] train_loss: 24.83452 valid_loss: 12.13459\n","EarlyStopping counter: 2 out of 20\n","tensor(39.2204, grad_fn=<MeanBackward0>)\n","tensor(397221.5312, grad_fn=<MeanBackward0>)\n","tensor(38.0119, grad_fn=<MeanBackward0>)\n","tensor(363137.9688, grad_fn=<MeanBackward0>)\n","tensor(39.4077, grad_fn=<MeanBackward0>)\n","tensor(376982.4688, grad_fn=<MeanBackward0>)\n","[ 416/1000] train_loss: 24.89135 valid_loss: 12.10973\n","Validation loss decreased (12.126414 --> 12.109733).  Saving model ...\n","tensor(38.3531, grad_fn=<MeanBackward0>)\n","tensor(375046.8750, grad_fn=<MeanBackward0>)\n","tensor(41.6546, grad_fn=<MeanBackward0>)\n","tensor(400142.2188, grad_fn=<MeanBackward0>)\n","tensor(35.0312, grad_fn=<MeanBackward0>)\n","tensor(376169.0625, grad_fn=<MeanBackward0>)\n","[ 417/1000] train_loss: 24.52455 valid_loss: 12.09369\n","Validation loss decreased (12.109733 --> 12.093691).  Saving model ...\n","tensor(38.7823, grad_fn=<MeanBackward0>)\n","tensor(406971.4688, grad_fn=<MeanBackward0>)\n","tensor(36.7347, grad_fn=<MeanBackward0>)\n","tensor(366834.4062, grad_fn=<MeanBackward0>)\n","tensor(36.0457, grad_fn=<MeanBackward0>)\n","tensor(373259.3750, grad_fn=<MeanBackward0>)\n","[ 418/1000] train_loss: 24.70755 valid_loss: 12.08877\n","Validation loss decreased (12.093691 --> 12.088767).  Saving model ...\n","tensor(33.9486, grad_fn=<MeanBackward0>)\n","tensor(368431.6562, grad_fn=<MeanBackward0>)\n","tensor(34.6039, grad_fn=<MeanBackward0>)\n","tensor(379850.7812, grad_fn=<MeanBackward0>)\n","tensor(39.9628, grad_fn=<MeanBackward0>)\n","tensor(398859.2188, grad_fn=<MeanBackward0>)\n","[ 419/1000] train_loss: 24.68918 valid_loss: 12.06236\n","Validation loss decreased (12.088767 --> 12.062364).  Saving model ...\n","tensor(37.8997, grad_fn=<MeanBackward0>)\n","tensor(366193.8750, grad_fn=<MeanBackward0>)\n","tensor(37.8341, grad_fn=<MeanBackward0>)\n","tensor(372179.5312, grad_fn=<MeanBackward0>)\n","tensor(39.1246, grad_fn=<MeanBackward0>)\n","tensor(429607.8750, grad_fn=<MeanBackward0>)\n","[ 420/1000] train_loss: 24.44555 valid_loss: 12.06008\n","Validation loss decreased (12.062364 --> 12.060080).  Saving model ...\n","tensor(39.6833, grad_fn=<MeanBackward0>)\n","tensor(364163.2812, grad_fn=<MeanBackward0>)\n","tensor(37.4188, grad_fn=<MeanBackward0>)\n","tensor(398171.2500, grad_fn=<MeanBackward0>)\n","tensor(39.9237, grad_fn=<MeanBackward0>)\n","tensor(369355.5938, grad_fn=<MeanBackward0>)\n","[ 421/1000] train_loss: 24.71811 valid_loss: 12.09091\n","EarlyStopping counter: 1 out of 20\n","tensor(39.0676, grad_fn=<MeanBackward0>)\n","tensor(371706.8438, grad_fn=<MeanBackward0>)\n","tensor(35.8554, grad_fn=<MeanBackward0>)\n","tensor(362059.7188, grad_fn=<MeanBackward0>)\n","tensor(39.5031, grad_fn=<MeanBackward0>)\n","tensor(379152.5938, grad_fn=<MeanBackward0>)\n","[ 422/1000] train_loss: 24.56683 valid_loss: 12.13222\n","EarlyStopping counter: 2 out of 20\n","tensor(36.6277, grad_fn=<MeanBackward0>)\n","tensor(344550.5000, grad_fn=<MeanBackward0>)\n","tensor(33.7935, grad_fn=<MeanBackward0>)\n","tensor(366390., grad_fn=<MeanBackward0>)\n","tensor(40.8030, grad_fn=<MeanBackward0>)\n","tensor(409654.9062, grad_fn=<MeanBackward0>)\n","[ 423/1000] train_loss: 24.51615 valid_loss: 12.15153\n","EarlyStopping counter: 3 out of 20\n","tensor(36.8752, grad_fn=<MeanBackward0>)\n","tensor(395475.7188, grad_fn=<MeanBackward0>)\n","tensor(36.4118, grad_fn=<MeanBackward0>)\n","tensor(362154.2500, grad_fn=<MeanBackward0>)\n","tensor(37.0933, grad_fn=<MeanBackward0>)\n","tensor(408051.9062, grad_fn=<MeanBackward0>)\n","[ 424/1000] train_loss: 24.53962 valid_loss: 12.12364\n","EarlyStopping counter: 4 out of 20\n","tensor(38.7409, grad_fn=<MeanBackward0>)\n","tensor(377939.7188, grad_fn=<MeanBackward0>)\n","tensor(39.4176, grad_fn=<MeanBackward0>)\n","tensor(360325.7812, grad_fn=<MeanBackward0>)\n","tensor(36.7442, grad_fn=<MeanBackward0>)\n","tensor(384797.1250, grad_fn=<MeanBackward0>)\n","[ 425/1000] train_loss: 24.63906 valid_loss: 12.05635\n","Validation loss decreased (12.060080 --> 12.056353).  Saving model ...\n","tensor(38.5963, grad_fn=<MeanBackward0>)\n","tensor(370645.6562, grad_fn=<MeanBackward0>)\n","tensor(37.8762, grad_fn=<MeanBackward0>)\n","tensor(390140.3438, grad_fn=<MeanBackward0>)\n","tensor(36.2160, grad_fn=<MeanBackward0>)\n","tensor(360372.6250, grad_fn=<MeanBackward0>)\n","[ 426/1000] train_loss: 24.13566 valid_loss: 12.04586\n","Validation loss decreased (12.056353 --> 12.045863).  Saving model ...\n","tensor(34.9530, grad_fn=<MeanBackward0>)\n","tensor(379675.5938, grad_fn=<MeanBackward0>)\n","tensor(37.4697, grad_fn=<MeanBackward0>)\n","tensor(407812.2188, grad_fn=<MeanBackward0>)\n","tensor(37.1423, grad_fn=<MeanBackward0>)\n","tensor(370343.9688, grad_fn=<MeanBackward0>)\n","[ 427/1000] train_loss: 24.59170 valid_loss: 12.03821\n","Validation loss decreased (12.045863 --> 12.038215).  Saving model ...\n","tensor(36.4234, grad_fn=<MeanBackward0>)\n","tensor(390762.8750, grad_fn=<MeanBackward0>)\n","tensor(37.7487, grad_fn=<MeanBackward0>)\n","tensor(377541.4062, grad_fn=<MeanBackward0>)\n","tensor(38.3926, grad_fn=<MeanBackward0>)\n","tensor(384380.1562, grad_fn=<MeanBackward0>)\n","[ 428/1000] train_loss: 24.52889 valid_loss: 12.02440\n","Validation loss decreased (12.038215 --> 12.024401).  Saving model ...\n","tensor(37.3552, grad_fn=<MeanBackward0>)\n","tensor(366333.2188, grad_fn=<MeanBackward0>)\n","tensor(39.8970, grad_fn=<MeanBackward0>)\n","tensor(385268.1562, grad_fn=<MeanBackward0>)\n","tensor(35.8709, grad_fn=<MeanBackward0>)\n","tensor(358452.9688, grad_fn=<MeanBackward0>)\n","[ 429/1000] train_loss: 24.72368 valid_loss: 12.00539\n","Validation loss decreased (12.024401 --> 12.005393).  Saving model ...\n","tensor(39.0136, grad_fn=<MeanBackward0>)\n","tensor(367805.1562, grad_fn=<MeanBackward0>)\n","tensor(37.4471, grad_fn=<MeanBackward0>)\n","tensor(375720.0938, grad_fn=<MeanBackward0>)\n","tensor(37.4497, grad_fn=<MeanBackward0>)\n","tensor(373263.9062, grad_fn=<MeanBackward0>)\n","[ 430/1000] train_loss: 24.28675 valid_loss: 12.01273\n","EarlyStopping counter: 1 out of 20\n","tensor(37.4327, grad_fn=<MeanBackward0>)\n","tensor(383569.1562, grad_fn=<MeanBackward0>)\n","tensor(35.9019, grad_fn=<MeanBackward0>)\n","tensor(374226.0938, grad_fn=<MeanBackward0>)\n","tensor(35.8936, grad_fn=<MeanBackward0>)\n","tensor(362345.6250, grad_fn=<MeanBackward0>)\n","[ 431/1000] train_loss: 24.18785 valid_loss: 12.02448\n","EarlyStopping counter: 2 out of 20\n","tensor(37.0290, grad_fn=<MeanBackward0>)\n","tensor(384782.5312, grad_fn=<MeanBackward0>)\n","tensor(36.4947, grad_fn=<MeanBackward0>)\n","tensor(372155.7188, grad_fn=<MeanBackward0>)\n","tensor(40.4802, grad_fn=<MeanBackward0>)\n","tensor(362901.1562, grad_fn=<MeanBackward0>)\n","[ 432/1000] train_loss: 24.12408 valid_loss: 11.98910\n","Validation loss decreased (12.005393 --> 11.989099).  Saving model ...\n","tensor(39.0355, grad_fn=<MeanBackward0>)\n","tensor(370446.5312, grad_fn=<MeanBackward0>)\n","tensor(35.5870, grad_fn=<MeanBackward0>)\n","tensor(359127.9688, grad_fn=<MeanBackward0>)\n","tensor(40.3214, grad_fn=<MeanBackward0>)\n","tensor(408857.4688, grad_fn=<MeanBackward0>)\n","[ 433/1000] train_loss: 24.50558 valid_loss: 11.95790\n","Validation loss decreased (11.989099 --> 11.957905).  Saving model ...\n","tensor(36.9556, grad_fn=<MeanBackward0>)\n","tensor(379834.5938, grad_fn=<MeanBackward0>)\n","tensor(36.4940, grad_fn=<MeanBackward0>)\n","tensor(365810.7500, grad_fn=<MeanBackward0>)\n","tensor(36.5898, grad_fn=<MeanBackward0>)\n","tensor(361826.5000, grad_fn=<MeanBackward0>)\n","[ 434/1000] train_loss: 23.88917 valid_loss: 11.93210\n","Validation loss decreased (11.957905 --> 11.932098).  Saving model ...\n","tensor(37.8282, grad_fn=<MeanBackward0>)\n","tensor(356460.7500, grad_fn=<MeanBackward0>)\n","tensor(34.3208, grad_fn=<MeanBackward0>)\n","tensor(393574.5000, grad_fn=<MeanBackward0>)\n","tensor(37.7965, grad_fn=<MeanBackward0>)\n","tensor(393423.1562, grad_fn=<MeanBackward0>)\n","[ 435/1000] train_loss: 23.94599 valid_loss: 11.95277\n","EarlyStopping counter: 1 out of 20\n","tensor(37.0311, grad_fn=<MeanBackward0>)\n","tensor(366980.7812, grad_fn=<MeanBackward0>)\n","tensor(36.2881, grad_fn=<MeanBackward0>)\n","tensor(388810.0938, grad_fn=<MeanBackward0>)\n","tensor(36.5287, grad_fn=<MeanBackward0>)\n","tensor(364766.3750, grad_fn=<MeanBackward0>)\n","[ 436/1000] train_loss: 23.87532 valid_loss: 11.94449\n","EarlyStopping counter: 2 out of 20\n","tensor(38.5421, grad_fn=<MeanBackward0>)\n","tensor(377261.6562, grad_fn=<MeanBackward0>)\n","tensor(37.2425, grad_fn=<MeanBackward0>)\n","tensor(363763.5938, grad_fn=<MeanBackward0>)\n","tensor(37.1464, grad_fn=<MeanBackward0>)\n","tensor(381293.2812, grad_fn=<MeanBackward0>)\n","[ 437/1000] train_loss: 24.60688 valid_loss: 11.97019\n","EarlyStopping counter: 3 out of 20\n","tensor(36.4941, grad_fn=<MeanBackward0>)\n","tensor(421843.5312, grad_fn=<MeanBackward0>)\n","tensor(37.5375, grad_fn=<MeanBackward0>)\n","tensor(384888.6562, grad_fn=<MeanBackward0>)\n","tensor(36.5836, grad_fn=<MeanBackward0>)\n","tensor(352271.2188, grad_fn=<MeanBackward0>)\n","[ 438/1000] train_loss: 24.08718 valid_loss: 11.91877\n","Validation loss decreased (11.932098 --> 11.918774).  Saving model ...\n","tensor(35.1313, grad_fn=<MeanBackward0>)\n","tensor(332446.9062, grad_fn=<MeanBackward0>)\n","tensor(37.4253, grad_fn=<MeanBackward0>)\n","tensor(382266.8750, grad_fn=<MeanBackward0>)\n","tensor(35.0589, grad_fn=<MeanBackward0>)\n","tensor(370554.7188, grad_fn=<MeanBackward0>)\n","[ 439/1000] train_loss: 24.06179 valid_loss: 11.91305\n","Validation loss decreased (11.918774 --> 11.913050).  Saving model ...\n","tensor(37.9389, grad_fn=<MeanBackward0>)\n","tensor(348490.1562, grad_fn=<MeanBackward0>)\n","tensor(35.2729, grad_fn=<MeanBackward0>)\n","tensor(366019.5000, grad_fn=<MeanBackward0>)\n","tensor(38.6900, grad_fn=<MeanBackward0>)\n","tensor(352902.1250, grad_fn=<MeanBackward0>)\n","[ 440/1000] train_loss: 23.82162 valid_loss: 11.92745\n","EarlyStopping counter: 1 out of 20\n","tensor(37.3751, grad_fn=<MeanBackward0>)\n","tensor(370309.3438, grad_fn=<MeanBackward0>)\n","tensor(37.5339, grad_fn=<MeanBackward0>)\n","tensor(371847.3438, grad_fn=<MeanBackward0>)\n","tensor(36.5112, grad_fn=<MeanBackward0>)\n","tensor(356352.9375, grad_fn=<MeanBackward0>)\n","[ 441/1000] train_loss: 23.97993 valid_loss: 11.89632\n","Validation loss decreased (11.913050 --> 11.896316).  Saving model ...\n","tensor(38.2869, grad_fn=<MeanBackward0>)\n","tensor(364459.2500, grad_fn=<MeanBackward0>)\n","tensor(36.3639, grad_fn=<MeanBackward0>)\n","tensor(376143.6250, grad_fn=<MeanBackward0>)\n","tensor(36.4620, grad_fn=<MeanBackward0>)\n","tensor(371957.2812, grad_fn=<MeanBackward0>)\n","[ 442/1000] train_loss: 24.12583 valid_loss: 11.88251\n","Validation loss decreased (11.896316 --> 11.882513).  Saving model ...\n","tensor(34.5738, grad_fn=<MeanBackward0>)\n","tensor(373483.2812, grad_fn=<MeanBackward0>)\n","tensor(38.3268, grad_fn=<MeanBackward0>)\n","tensor(346995.8438, grad_fn=<MeanBackward0>)\n","tensor(35.7780, grad_fn=<MeanBackward0>)\n","tensor(355053.5312, grad_fn=<MeanBackward0>)\n","[ 443/1000] train_loss: 24.08415 valid_loss: 11.86555\n","Validation loss decreased (11.882513 --> 11.865545).  Saving model ...\n","tensor(35.0172, grad_fn=<MeanBackward0>)\n","tensor(350349.9688, grad_fn=<MeanBackward0>)\n","tensor(35.9834, grad_fn=<MeanBackward0>)\n","tensor(358773.8438, grad_fn=<MeanBackward0>)\n","tensor(36.7979, grad_fn=<MeanBackward0>)\n","tensor(365806.7188, grad_fn=<MeanBackward0>)\n","[ 444/1000] train_loss: 23.71257 valid_loss: 11.93756\n","EarlyStopping counter: 1 out of 20\n","tensor(36.1573, grad_fn=<MeanBackward0>)\n","tensor(371727.3438, grad_fn=<MeanBackward0>)\n","tensor(37.1628, grad_fn=<MeanBackward0>)\n","tensor(357775.1250, grad_fn=<MeanBackward0>)\n","tensor(37.3059, grad_fn=<MeanBackward0>)\n","tensor(383045.0312, grad_fn=<MeanBackward0>)\n","[ 445/1000] train_loss: 23.98337 valid_loss: 11.89453\n","EarlyStopping counter: 2 out of 20\n","tensor(37.4066, grad_fn=<MeanBackward0>)\n","tensor(347141.7188, grad_fn=<MeanBackward0>)\n","tensor(35.5070, grad_fn=<MeanBackward0>)\n","tensor(405779.4688, grad_fn=<MeanBackward0>)\n","tensor(36.2955, grad_fn=<MeanBackward0>)\n","tensor(357329.5312, grad_fn=<MeanBackward0>)\n","[ 446/1000] train_loss: 23.89824 valid_loss: 11.88868\n","EarlyStopping counter: 3 out of 20\n","tensor(39.3084, grad_fn=<MeanBackward0>)\n","tensor(358321.5000, grad_fn=<MeanBackward0>)\n","tensor(34.4714, grad_fn=<MeanBackward0>)\n","tensor(385121.6562, grad_fn=<MeanBackward0>)\n","tensor(33.3404, grad_fn=<MeanBackward0>)\n","tensor(355870.0625, grad_fn=<MeanBackward0>)\n","[ 447/1000] train_loss: 23.86096 valid_loss: 11.89329\n","EarlyStopping counter: 4 out of 20\n","tensor(35.4861, grad_fn=<MeanBackward0>)\n","tensor(381589.9062, grad_fn=<MeanBackward0>)\n","tensor(34.2736, grad_fn=<MeanBackward0>)\n","tensor(341564.4688, grad_fn=<MeanBackward0>)\n","tensor(38.7743, grad_fn=<MeanBackward0>)\n","tensor(385864.6562, grad_fn=<MeanBackward0>)\n","[ 448/1000] train_loss: 23.70591 valid_loss: 11.90112\n","EarlyStopping counter: 5 out of 20\n","tensor(34.4323, grad_fn=<MeanBackward0>)\n","tensor(355725.4688, grad_fn=<MeanBackward0>)\n","tensor(39.1360, grad_fn=<MeanBackward0>)\n","tensor(360083.7500, grad_fn=<MeanBackward0>)\n","tensor(38.5771, grad_fn=<MeanBackward0>)\n","tensor(366049.2188, grad_fn=<MeanBackward0>)\n","[ 449/1000] train_loss: 24.07658 valid_loss: 11.87289\n","EarlyStopping counter: 6 out of 20\n","tensor(38.1015, grad_fn=<MeanBackward0>)\n","tensor(351770.6562, grad_fn=<MeanBackward0>)\n","tensor(36.2606, grad_fn=<MeanBackward0>)\n","tensor(365800.2500, grad_fn=<MeanBackward0>)\n","tensor(39.9317, grad_fn=<MeanBackward0>)\n","tensor(347114.3438, grad_fn=<MeanBackward0>)\n","[ 450/1000] train_loss: 23.89674 valid_loss: 11.85694\n","Validation loss decreased (11.865545 --> 11.856936).  Saving model ...\n","tensor(37.6270, grad_fn=<MeanBackward0>)\n","tensor(349522.8750, grad_fn=<MeanBackward0>)\n","tensor(37.0185, grad_fn=<MeanBackward0>)\n","tensor(358325.6562, grad_fn=<MeanBackward0>)\n","tensor(38.7557, grad_fn=<MeanBackward0>)\n","tensor(371824.9062, grad_fn=<MeanBackward0>)\n","[ 451/1000] train_loss: 23.80518 valid_loss: 11.85757\n","EarlyStopping counter: 1 out of 20\n","tensor(36.1341, grad_fn=<MeanBackward0>)\n","tensor(371013., grad_fn=<MeanBackward0>)\n","tensor(36.3099, grad_fn=<MeanBackward0>)\n","tensor(379527.7188, grad_fn=<MeanBackward0>)\n","tensor(38.7666, grad_fn=<MeanBackward0>)\n","tensor(367402.0312, grad_fn=<MeanBackward0>)\n","[ 452/1000] train_loss: 23.86210 valid_loss: 11.85416\n","Validation loss decreased (11.856936 --> 11.854160).  Saving model ...\n","tensor(36.5629, grad_fn=<MeanBackward0>)\n","tensor(377766.1562, grad_fn=<MeanBackward0>)\n","tensor(35.6601, grad_fn=<MeanBackward0>)\n","tensor(361673.4062, grad_fn=<MeanBackward0>)\n","tensor(36.0447, grad_fn=<MeanBackward0>)\n","tensor(381058.5000, grad_fn=<MeanBackward0>)\n","[ 453/1000] train_loss: 24.14654 valid_loss: 11.80747\n","Validation loss decreased (11.854160 --> 11.807467).  Saving model ...\n","tensor(34.4387, grad_fn=<MeanBackward0>)\n","tensor(373113.2188, grad_fn=<MeanBackward0>)\n","tensor(35.9297, grad_fn=<MeanBackward0>)\n","tensor(372836.7188, grad_fn=<MeanBackward0>)\n","tensor(35.9467, grad_fn=<MeanBackward0>)\n","tensor(354143.7812, grad_fn=<MeanBackward0>)\n","[ 454/1000] train_loss: 23.97212 valid_loss: 11.84263\n","EarlyStopping counter: 1 out of 20\n","tensor(36.4321, grad_fn=<MeanBackward0>)\n","tensor(368730.2812, grad_fn=<MeanBackward0>)\n","tensor(36.8683, grad_fn=<MeanBackward0>)\n","tensor(345789.7812, grad_fn=<MeanBackward0>)\n","tensor(34.2987, grad_fn=<MeanBackward0>)\n","tensor(367346.6562, grad_fn=<MeanBackward0>)\n","[ 455/1000] train_loss: 23.57307 valid_loss: 11.82937\n","EarlyStopping counter: 2 out of 20\n","tensor(35.4565, grad_fn=<MeanBackward0>)\n","tensor(364846.8750, grad_fn=<MeanBackward0>)\n","tensor(34.8560, grad_fn=<MeanBackward0>)\n","tensor(346108.5938, grad_fn=<MeanBackward0>)\n","tensor(37.9360, grad_fn=<MeanBackward0>)\n","tensor(363124.7188, grad_fn=<MeanBackward0>)\n","[ 456/1000] train_loss: 23.65069 valid_loss: 11.82635\n","EarlyStopping counter: 3 out of 20\n","tensor(39.7769, grad_fn=<MeanBackward0>)\n","tensor(367003.8750, grad_fn=<MeanBackward0>)\n","tensor(36.7576, grad_fn=<MeanBackward0>)\n","tensor(374930.2188, grad_fn=<MeanBackward0>)\n","tensor(38.0874, grad_fn=<MeanBackward0>)\n","tensor(349237.7500, grad_fn=<MeanBackward0>)\n","[ 457/1000] train_loss: 24.08440 valid_loss: 11.88327\n","EarlyStopping counter: 4 out of 20\n","tensor(37.3674, grad_fn=<MeanBackward0>)\n","tensor(381294.3438, grad_fn=<MeanBackward0>)\n","tensor(35.6586, grad_fn=<MeanBackward0>)\n","tensor(346165.3438, grad_fn=<MeanBackward0>)\n","tensor(36.4999, grad_fn=<MeanBackward0>)\n","tensor(337731.9688, grad_fn=<MeanBackward0>)\n","[ 458/1000] train_loss: 23.75401 valid_loss: 11.96869\n","EarlyStopping counter: 5 out of 20\n","tensor(38.1173, grad_fn=<MeanBackward0>)\n","tensor(380462.7500, grad_fn=<MeanBackward0>)\n","tensor(37.9093, grad_fn=<MeanBackward0>)\n","tensor(382822.8750, grad_fn=<MeanBackward0>)\n","tensor(35.9703, grad_fn=<MeanBackward0>)\n","tensor(363214.9688, grad_fn=<MeanBackward0>)\n","[ 459/1000] train_loss: 23.73340 valid_loss: 11.83799\n","EarlyStopping counter: 6 out of 20\n","tensor(34.1414, grad_fn=<MeanBackward0>)\n","tensor(382152.1250, grad_fn=<MeanBackward0>)\n","tensor(34.9050, grad_fn=<MeanBackward0>)\n","tensor(350140.1250, grad_fn=<MeanBackward0>)\n","tensor(38.1697, grad_fn=<MeanBackward0>)\n","tensor(355246.6562, grad_fn=<MeanBackward0>)\n","[ 460/1000] train_loss: 24.20358 valid_loss: 11.77966\n","Validation loss decreased (11.807467 --> 11.779655).  Saving model ...\n","tensor(35.0443, grad_fn=<MeanBackward0>)\n","tensor(353429.1250, grad_fn=<MeanBackward0>)\n","tensor(37.9223, grad_fn=<MeanBackward0>)\n","tensor(351132.4688, grad_fn=<MeanBackward0>)\n","tensor(37.8053, grad_fn=<MeanBackward0>)\n","tensor(359703.2500, grad_fn=<MeanBackward0>)\n","[ 461/1000] train_loss: 23.84386 valid_loss: 11.84037\n","EarlyStopping counter: 1 out of 20\n","tensor(39.0805, grad_fn=<MeanBackward0>)\n","tensor(346998.0938, grad_fn=<MeanBackward0>)\n","tensor(36.6545, grad_fn=<MeanBackward0>)\n","tensor(330958.0312, grad_fn=<MeanBackward0>)\n","tensor(34.6215, grad_fn=<MeanBackward0>)\n","tensor(367577.5000, grad_fn=<MeanBackward0>)\n","[ 462/1000] train_loss: 23.22879 valid_loss: 11.93488\n","EarlyStopping counter: 2 out of 20\n","tensor(34.1664, grad_fn=<MeanBackward0>)\n","tensor(355810.8438, grad_fn=<MeanBackward0>)\n","tensor(35.3277, grad_fn=<MeanBackward0>)\n","tensor(364293., grad_fn=<MeanBackward0>)\n","tensor(39.3034, grad_fn=<MeanBackward0>)\n","tensor(354705.6875, grad_fn=<MeanBackward0>)\n","[ 463/1000] train_loss: 23.61890 valid_loss: 11.82301\n","EarlyStopping counter: 3 out of 20\n","tensor(35.3683, grad_fn=<MeanBackward0>)\n","tensor(383302.8438, grad_fn=<MeanBackward0>)\n","tensor(35.6893, grad_fn=<MeanBackward0>)\n","tensor(340846., grad_fn=<MeanBackward0>)\n","tensor(37.7878, grad_fn=<MeanBackward0>)\n","tensor(365404.1250, grad_fn=<MeanBackward0>)\n","[ 464/1000] train_loss: 23.84347 valid_loss: 11.74756\n","Validation loss decreased (11.779655 --> 11.747564).  Saving model ...\n","tensor(36.5604, grad_fn=<MeanBackward0>)\n","tensor(376717.5000, grad_fn=<MeanBackward0>)\n","tensor(36.3402, grad_fn=<MeanBackward0>)\n","tensor(364446.2500, grad_fn=<MeanBackward0>)\n","tensor(34.5858, grad_fn=<MeanBackward0>)\n","tensor(370477.6875, grad_fn=<MeanBackward0>)\n","[ 465/1000] train_loss: 23.53453 valid_loss: 11.72711\n","Validation loss decreased (11.747564 --> 11.727106).  Saving model ...\n","tensor(37.5899, grad_fn=<MeanBackward0>)\n","tensor(325036.7500, grad_fn=<MeanBackward0>)\n","tensor(36.3593, grad_fn=<MeanBackward0>)\n","tensor(340802.9062, grad_fn=<MeanBackward0>)\n","tensor(36.0926, grad_fn=<MeanBackward0>)\n","tensor(380590.8438, grad_fn=<MeanBackward0>)\n","[ 466/1000] train_loss: 23.66208 valid_loss: 11.73436\n","EarlyStopping counter: 1 out of 20\n","tensor(37.7853, grad_fn=<MeanBackward0>)\n","tensor(360964.4062, grad_fn=<MeanBackward0>)\n","tensor(38.1445, grad_fn=<MeanBackward0>)\n","tensor(363918.2500, grad_fn=<MeanBackward0>)\n","tensor(34.3188, grad_fn=<MeanBackward0>)\n","tensor(313501., grad_fn=<MeanBackward0>)\n","[ 467/1000] train_loss: 23.48858 valid_loss: 11.76414\n","EarlyStopping counter: 2 out of 20\n","tensor(33.0574, grad_fn=<MeanBackward0>)\n","tensor(358009.6562, grad_fn=<MeanBackward0>)\n","tensor(35.5927, grad_fn=<MeanBackward0>)\n","tensor(363777.3750, grad_fn=<MeanBackward0>)\n","tensor(36.0018, grad_fn=<MeanBackward0>)\n","tensor(357993.2188, grad_fn=<MeanBackward0>)\n","[ 468/1000] train_loss: 23.51277 valid_loss: 11.72524\n","Validation loss decreased (11.727106 --> 11.725239).  Saving model ...\n","tensor(32.6376, grad_fn=<MeanBackward0>)\n","tensor(343832.4062, grad_fn=<MeanBackward0>)\n","tensor(38.0521, grad_fn=<MeanBackward0>)\n","tensor(365046.3750, grad_fn=<MeanBackward0>)\n","tensor(32.8163, grad_fn=<MeanBackward0>)\n","tensor(358373.5938, grad_fn=<MeanBackward0>)\n","[ 469/1000] train_loss: 23.42448 valid_loss: 11.71163\n","Validation loss decreased (11.725239 --> 11.711629).  Saving model ...\n","tensor(35.8837, grad_fn=<MeanBackward0>)\n","tensor(362486.1250, grad_fn=<MeanBackward0>)\n","tensor(36.0650, grad_fn=<MeanBackward0>)\n","tensor(345155., grad_fn=<MeanBackward0>)\n","tensor(33.2758, grad_fn=<MeanBackward0>)\n","tensor(358284.9375, grad_fn=<MeanBackward0>)\n","[ 470/1000] train_loss: 23.04712 valid_loss: 11.71852\n","EarlyStopping counter: 1 out of 20\n","tensor(32.5204, grad_fn=<MeanBackward0>)\n","tensor(341687.4062, grad_fn=<MeanBackward0>)\n","tensor(38.5509, grad_fn=<MeanBackward0>)\n","tensor(391149., grad_fn=<MeanBackward0>)\n","tensor(33.6080, grad_fn=<MeanBackward0>)\n","tensor(364750.2188, grad_fn=<MeanBackward0>)\n","[ 471/1000] train_loss: 23.40949 valid_loss: 11.69244\n","Validation loss decreased (11.711629 --> 11.692444).  Saving model ...\n","tensor(36.3151, grad_fn=<MeanBackward0>)\n","tensor(349604.4688, grad_fn=<MeanBackward0>)\n","tensor(34.9454, grad_fn=<MeanBackward0>)\n","tensor(337613.9062, grad_fn=<MeanBackward0>)\n","tensor(38.0869, grad_fn=<MeanBackward0>)\n","tensor(365731.9062, grad_fn=<MeanBackward0>)\n","[ 472/1000] train_loss: 23.15956 valid_loss: 11.67101\n","Validation loss decreased (11.692444 --> 11.671012).  Saving model ...\n","tensor(36.9115, grad_fn=<MeanBackward0>)\n","tensor(344750.1562, grad_fn=<MeanBackward0>)\n","tensor(36.3639, grad_fn=<MeanBackward0>)\n","tensor(354176.8438, grad_fn=<MeanBackward0>)\n","tensor(35.6545, grad_fn=<MeanBackward0>)\n","tensor(349548.9375, grad_fn=<MeanBackward0>)\n","[ 473/1000] train_loss: 22.95492 valid_loss: 11.73521\n","EarlyStopping counter: 1 out of 20\n","tensor(36.3468, grad_fn=<MeanBackward0>)\n","tensor(340365.7188, grad_fn=<MeanBackward0>)\n","tensor(37.4716, grad_fn=<MeanBackward0>)\n","tensor(374009.6250, grad_fn=<MeanBackward0>)\n","tensor(34.0470, grad_fn=<MeanBackward0>)\n","tensor(371363.4375, grad_fn=<MeanBackward0>)\n","[ 474/1000] train_loss: 23.18678 valid_loss: 11.72446\n","EarlyStopping counter: 2 out of 20\n","tensor(36.8356, grad_fn=<MeanBackward0>)\n","tensor(359548.6250, grad_fn=<MeanBackward0>)\n","tensor(34.3823, grad_fn=<MeanBackward0>)\n","tensor(319330.9062, grad_fn=<MeanBackward0>)\n","tensor(36.1725, grad_fn=<MeanBackward0>)\n","tensor(358584.0625, grad_fn=<MeanBackward0>)\n","[ 475/1000] train_loss: 23.19581 valid_loss: 11.71370\n","EarlyStopping counter: 3 out of 20\n","tensor(35.5201, grad_fn=<MeanBackward0>)\n","tensor(300175.7188, grad_fn=<MeanBackward0>)\n","tensor(36.9088, grad_fn=<MeanBackward0>)\n","tensor(363939.3438, grad_fn=<MeanBackward0>)\n","tensor(36.2301, grad_fn=<MeanBackward0>)\n","tensor(349783.7812, grad_fn=<MeanBackward0>)\n","[ 476/1000] train_loss: 23.27416 valid_loss: 11.67292\n","EarlyStopping counter: 4 out of 20\n","tensor(34.7759, grad_fn=<MeanBackward0>)\n","tensor(354878.4688, grad_fn=<MeanBackward0>)\n","tensor(38.5562, grad_fn=<MeanBackward0>)\n","tensor(339095.4688, grad_fn=<MeanBackward0>)\n","tensor(35.5367, grad_fn=<MeanBackward0>)\n","tensor(375937.2188, grad_fn=<MeanBackward0>)\n","[ 477/1000] train_loss: 23.21129 valid_loss: 11.67815\n","EarlyStopping counter: 5 out of 20\n","tensor(36.0488, grad_fn=<MeanBackward0>)\n","tensor(334526.3438, grad_fn=<MeanBackward0>)\n","tensor(33.7999, grad_fn=<MeanBackward0>)\n","tensor(363011.9688, grad_fn=<MeanBackward0>)\n","tensor(39.3237, grad_fn=<MeanBackward0>)\n","tensor(380629.5938, grad_fn=<MeanBackward0>)\n","[ 478/1000] train_loss: 23.60691 valid_loss: 11.65734\n","Validation loss decreased (11.671012 --> 11.657340).  Saving model ...\n","tensor(33.5731, grad_fn=<MeanBackward0>)\n","tensor(336682.3750, grad_fn=<MeanBackward0>)\n","tensor(35.6483, grad_fn=<MeanBackward0>)\n","tensor(331799.8438, grad_fn=<MeanBackward0>)\n","tensor(35.3163, grad_fn=<MeanBackward0>)\n","tensor(375538.5000, grad_fn=<MeanBackward0>)\n","[ 479/1000] train_loss: 23.19169 valid_loss: 11.62365\n","Validation loss decreased (11.657340 --> 11.623647).  Saving model ...\n","tensor(34.1013, grad_fn=<MeanBackward0>)\n","tensor(359470.0312, grad_fn=<MeanBackward0>)\n","tensor(36.4898, grad_fn=<MeanBackward0>)\n","tensor(348995.9688, grad_fn=<MeanBackward0>)\n","tensor(37.1356, grad_fn=<MeanBackward0>)\n","tensor(398059.0312, grad_fn=<MeanBackward0>)\n","[ 480/1000] train_loss: 23.55204 valid_loss: 11.67146\n","EarlyStopping counter: 1 out of 20\n","tensor(36.5794, grad_fn=<MeanBackward0>)\n","tensor(405947.0938, grad_fn=<MeanBackward0>)\n","tensor(38.1010, grad_fn=<MeanBackward0>)\n","tensor(342890.9688, grad_fn=<MeanBackward0>)\n","tensor(32.5154, grad_fn=<MeanBackward0>)\n","tensor(324466.3750, grad_fn=<MeanBackward0>)\n","[ 481/1000] train_loss: 23.16577 valid_loss: 11.63758\n","EarlyStopping counter: 2 out of 20\n","tensor(33.2605, grad_fn=<MeanBackward0>)\n","tensor(343169.2500, grad_fn=<MeanBackward0>)\n","tensor(36.7146, grad_fn=<MeanBackward0>)\n","tensor(344927.8438, grad_fn=<MeanBackward0>)\n","tensor(37.1076, grad_fn=<MeanBackward0>)\n","tensor(370013.5000, grad_fn=<MeanBackward0>)\n","[ 482/1000] train_loss: 23.33124 valid_loss: 11.63028\n","EarlyStopping counter: 3 out of 20\n","tensor(34.0857, grad_fn=<MeanBackward0>)\n","tensor(340228.6875, grad_fn=<MeanBackward0>)\n","tensor(36.5220, grad_fn=<MeanBackward0>)\n","tensor(344114.7188, grad_fn=<MeanBackward0>)\n","tensor(36.3418, grad_fn=<MeanBackward0>)\n","tensor(366893.4375, grad_fn=<MeanBackward0>)\n","[ 483/1000] train_loss: 23.05439 valid_loss: 11.62127\n","Validation loss decreased (11.623647 --> 11.621273).  Saving model ...\n","tensor(37.3559, grad_fn=<MeanBackward0>)\n","tensor(348198.0625, grad_fn=<MeanBackward0>)\n","tensor(34.8074, grad_fn=<MeanBackward0>)\n","tensor(327871.0938, grad_fn=<MeanBackward0>)\n","tensor(36.0064, grad_fn=<MeanBackward0>)\n","tensor(390647.9688, grad_fn=<MeanBackward0>)\n","[ 484/1000] train_loss: 23.10060 valid_loss: 11.63174\n","EarlyStopping counter: 1 out of 20\n","tensor(34.1548, grad_fn=<MeanBackward0>)\n","tensor(339140.3125, grad_fn=<MeanBackward0>)\n","tensor(35.6817, grad_fn=<MeanBackward0>)\n","tensor(360638.1250, grad_fn=<MeanBackward0>)\n","tensor(32.0316, grad_fn=<MeanBackward0>)\n","tensor(349877.0938, grad_fn=<MeanBackward0>)\n","[ 485/1000] train_loss: 22.87931 valid_loss: 11.60659\n","Validation loss decreased (11.621273 --> 11.606594).  Saving model ...\n","tensor(35.1491, grad_fn=<MeanBackward0>)\n","tensor(357637.5938, grad_fn=<MeanBackward0>)\n","tensor(32.9175, grad_fn=<MeanBackward0>)\n","tensor(337043.0938, grad_fn=<MeanBackward0>)\n","tensor(35.4402, grad_fn=<MeanBackward0>)\n","tensor(346620.8750, grad_fn=<MeanBackward0>)\n","[ 486/1000] train_loss: 22.97395 valid_loss: 11.59104\n","Validation loss decreased (11.606594 --> 11.591036).  Saving model ...\n","tensor(34.2793, grad_fn=<MeanBackward0>)\n","tensor(353539.6250, grad_fn=<MeanBackward0>)\n","tensor(35.0376, grad_fn=<MeanBackward0>)\n","tensor(369559.2812, grad_fn=<MeanBackward0>)\n","tensor(34.3000, grad_fn=<MeanBackward0>)\n","tensor(324350.9375, grad_fn=<MeanBackward0>)\n","[ 487/1000] train_loss: 23.09695 valid_loss: 11.58967\n","Validation loss decreased (11.591036 --> 11.589675).  Saving model ...\n","tensor(34.4470, grad_fn=<MeanBackward0>)\n","tensor(341447., grad_fn=<MeanBackward0>)\n","tensor(34.9703, grad_fn=<MeanBackward0>)\n","tensor(355689.5938, grad_fn=<MeanBackward0>)\n","tensor(36.4299, grad_fn=<MeanBackward0>)\n","tensor(344480.7500, grad_fn=<MeanBackward0>)\n","[ 488/1000] train_loss: 22.89862 valid_loss: 11.59379\n","EarlyStopping counter: 1 out of 20\n","tensor(36.3941, grad_fn=<MeanBackward0>)\n","tensor(340426.4062, grad_fn=<MeanBackward0>)\n","tensor(37.3081, grad_fn=<MeanBackward0>)\n","tensor(337126.9062, grad_fn=<MeanBackward0>)\n","tensor(35.0072, grad_fn=<MeanBackward0>)\n","tensor(356786.9062, grad_fn=<MeanBackward0>)\n","[ 489/1000] train_loss: 22.75989 valid_loss: 11.59969\n","EarlyStopping counter: 2 out of 20\n","tensor(33.8983, grad_fn=<MeanBackward0>)\n","tensor(341938.3438, grad_fn=<MeanBackward0>)\n","tensor(34.4720, grad_fn=<MeanBackward0>)\n","tensor(327336.1562, grad_fn=<MeanBackward0>)\n","tensor(33.8407, grad_fn=<MeanBackward0>)\n","tensor(378056.9062, grad_fn=<MeanBackward0>)\n","[ 490/1000] train_loss: 23.11384 valid_loss: 11.58810\n","Validation loss decreased (11.589675 --> 11.588101).  Saving model ...\n","tensor(33.0979, grad_fn=<MeanBackward0>)\n","tensor(344140.5312, grad_fn=<MeanBackward0>)\n","tensor(35.7009, grad_fn=<MeanBackward0>)\n","tensor(359821.7188, grad_fn=<MeanBackward0>)\n","tensor(35.3108, grad_fn=<MeanBackward0>)\n","tensor(368088.6875, grad_fn=<MeanBackward0>)\n","[ 491/1000] train_loss: 22.80400 valid_loss: 11.54622\n","Validation loss decreased (11.588101 --> 11.546221).  Saving model ...\n","tensor(36.2780, grad_fn=<MeanBackward0>)\n","tensor(353518.9062, grad_fn=<MeanBackward0>)\n","tensor(32.7063, grad_fn=<MeanBackward0>)\n","tensor(335476.7812, grad_fn=<MeanBackward0>)\n","tensor(37.3080, grad_fn=<MeanBackward0>)\n","tensor(368073.2188, grad_fn=<MeanBackward0>)\n","[ 492/1000] train_loss: 22.82120 valid_loss: 11.55363\n","EarlyStopping counter: 1 out of 20\n","tensor(36.3728, grad_fn=<MeanBackward0>)\n","tensor(322816.8438, grad_fn=<MeanBackward0>)\n","tensor(32.7613, grad_fn=<MeanBackward0>)\n","tensor(356940.9688, grad_fn=<MeanBackward0>)\n","tensor(36.4897, grad_fn=<MeanBackward0>)\n","tensor(353621.0312, grad_fn=<MeanBackward0>)\n","[ 493/1000] train_loss: 23.21709 valid_loss: 11.60821\n","EarlyStopping counter: 2 out of 20\n","tensor(36.0461, grad_fn=<MeanBackward0>)\n","tensor(331150.5938, grad_fn=<MeanBackward0>)\n","tensor(34.8967, grad_fn=<MeanBackward0>)\n","tensor(376522.3750, grad_fn=<MeanBackward0>)\n","tensor(34.0885, grad_fn=<MeanBackward0>)\n","tensor(348334.5000, grad_fn=<MeanBackward0>)\n","[ 494/1000] train_loss: 22.76465 valid_loss: 11.59564\n","EarlyStopping counter: 3 out of 20\n","tensor(33.0491, grad_fn=<MeanBackward0>)\n","tensor(338787.5312, grad_fn=<MeanBackward0>)\n","tensor(32.6317, grad_fn=<MeanBackward0>)\n","tensor(349711.5938, grad_fn=<MeanBackward0>)\n","tensor(37.8787, grad_fn=<MeanBackward0>)\n","tensor(358256.2812, grad_fn=<MeanBackward0>)\n","[ 495/1000] train_loss: 22.85176 valid_loss: 11.64154\n","EarlyStopping counter: 4 out of 20\n","tensor(34.7297, grad_fn=<MeanBackward0>)\n","tensor(327031.0938, grad_fn=<MeanBackward0>)\n","tensor(35.1540, grad_fn=<MeanBackward0>)\n","tensor(334833.5938, grad_fn=<MeanBackward0>)\n","tensor(32.8334, grad_fn=<MeanBackward0>)\n","tensor(350218.2812, grad_fn=<MeanBackward0>)\n","[ 496/1000] train_loss: 22.71180 valid_loss: 11.54293\n","Validation loss decreased (11.546221 --> 11.542932).  Saving model ...\n","tensor(31.4628, grad_fn=<MeanBackward0>)\n","tensor(296483.5938, grad_fn=<MeanBackward0>)\n","tensor(33.9915, grad_fn=<MeanBackward0>)\n","tensor(366266.1562, grad_fn=<MeanBackward0>)\n","tensor(36.8699, grad_fn=<MeanBackward0>)\n","tensor(347474.6562, grad_fn=<MeanBackward0>)\n","[ 497/1000] train_loss: 22.83639 valid_loss: 11.53320\n","Validation loss decreased (11.542932 --> 11.533198).  Saving model ...\n","tensor(32.8406, grad_fn=<MeanBackward0>)\n","tensor(322781.3125, grad_fn=<MeanBackward0>)\n","tensor(37.2021, grad_fn=<MeanBackward0>)\n","tensor(354073.6250, grad_fn=<MeanBackward0>)\n","tensor(36.0203, grad_fn=<MeanBackward0>)\n","tensor(339897., grad_fn=<MeanBackward0>)\n","[ 498/1000] train_loss: 22.91943 valid_loss: 11.53232\n","Validation loss decreased (11.533198 --> 11.532317).  Saving model ...\n","tensor(34.7609, grad_fn=<MeanBackward0>)\n","tensor(321511.8438, grad_fn=<MeanBackward0>)\n","tensor(36.3938, grad_fn=<MeanBackward0>)\n","tensor(362388.0938, grad_fn=<MeanBackward0>)\n","tensor(31.7558, grad_fn=<MeanBackward0>)\n","tensor(375169.0625, grad_fn=<MeanBackward0>)\n","[ 499/1000] train_loss: 22.54053 valid_loss: 11.54422\n","EarlyStopping counter: 1 out of 20\n","tensor(37.4823, grad_fn=<MeanBackward0>)\n","tensor(335869.9062, grad_fn=<MeanBackward0>)\n","tensor(37.8302, grad_fn=<MeanBackward0>)\n","tensor(351567.1562, grad_fn=<MeanBackward0>)\n","tensor(33.5302, grad_fn=<MeanBackward0>)\n","tensor(323146.3438, grad_fn=<MeanBackward0>)\n","[ 500/1000] train_loss: 22.74719 valid_loss: 11.57925\n","EarlyStopping counter: 2 out of 20\n","tensor(35.8181, grad_fn=<MeanBackward0>)\n","tensor(334646.7188, grad_fn=<MeanBackward0>)\n","tensor(35.3605, grad_fn=<MeanBackward0>)\n","tensor(333937.9062, grad_fn=<MeanBackward0>)\n","tensor(37.0632, grad_fn=<MeanBackward0>)\n","tensor(328042.1250, grad_fn=<MeanBackward0>)\n","[ 501/1000] train_loss: 22.89506 valid_loss: 11.61776\n","EarlyStopping counter: 3 out of 20\n","tensor(34.2066, grad_fn=<MeanBackward0>)\n","tensor(333397.3750, grad_fn=<MeanBackward0>)\n","tensor(35.3433, grad_fn=<MeanBackward0>)\n","tensor(368263.4688, grad_fn=<MeanBackward0>)\n","tensor(33.9073, grad_fn=<MeanBackward0>)\n","tensor(369695.2812, grad_fn=<MeanBackward0>)\n","[ 502/1000] train_loss: 22.93599 valid_loss: 11.55396\n","EarlyStopping counter: 4 out of 20\n","tensor(33.6580, grad_fn=<MeanBackward0>)\n","tensor(349012.3125, grad_fn=<MeanBackward0>)\n","tensor(33.9581, grad_fn=<MeanBackward0>)\n","tensor(349323.8438, grad_fn=<MeanBackward0>)\n","tensor(35.9097, grad_fn=<MeanBackward0>)\n","tensor(328605.5625, grad_fn=<MeanBackward0>)\n","[ 503/1000] train_loss: 22.71520 valid_loss: 11.50142\n","Validation loss decreased (11.532317 --> 11.501421).  Saving model ...\n","tensor(35.0160, grad_fn=<MeanBackward0>)\n","tensor(343543.2188, grad_fn=<MeanBackward0>)\n","tensor(37.1678, grad_fn=<MeanBackward0>)\n","tensor(360127.6250, grad_fn=<MeanBackward0>)\n","tensor(34.1437, grad_fn=<MeanBackward0>)\n","tensor(320955.8438, grad_fn=<MeanBackward0>)\n","[ 504/1000] train_loss: 22.77523 valid_loss: 11.51398\n","EarlyStopping counter: 1 out of 20\n","tensor(34.9803, grad_fn=<MeanBackward0>)\n","tensor(350326.7812, grad_fn=<MeanBackward0>)\n","tensor(34.0911, grad_fn=<MeanBackward0>)\n","tensor(341240.6562, grad_fn=<MeanBackward0>)\n","tensor(33.9610, grad_fn=<MeanBackward0>)\n","tensor(328448.5938, grad_fn=<MeanBackward0>)\n","[ 505/1000] train_loss: 22.38831 valid_loss: 11.48824\n","Validation loss decreased (11.501421 --> 11.488237).  Saving model ...\n","tensor(34.4908, grad_fn=<MeanBackward0>)\n","tensor(340290.5312, grad_fn=<MeanBackward0>)\n","tensor(32.6153, grad_fn=<MeanBackward0>)\n","tensor(342586.0312, grad_fn=<MeanBackward0>)\n","tensor(32.7601, grad_fn=<MeanBackward0>)\n","tensor(357422.5312, grad_fn=<MeanBackward0>)\n","[ 506/1000] train_loss: 22.70052 valid_loss: 11.49849\n","EarlyStopping counter: 1 out of 20\n","tensor(35.5547, grad_fn=<MeanBackward0>)\n","tensor(362516.0312, grad_fn=<MeanBackward0>)\n","tensor(33.7848, grad_fn=<MeanBackward0>)\n","tensor(335332.0312, grad_fn=<MeanBackward0>)\n","tensor(31.2896, grad_fn=<MeanBackward0>)\n","tensor(337371.4688, grad_fn=<MeanBackward0>)\n","[ 507/1000] train_loss: 22.94710 valid_loss: 11.47845\n","Validation loss decreased (11.488237 --> 11.478450).  Saving model ...\n","tensor(34.2733, grad_fn=<MeanBackward0>)\n","tensor(342700.5312, grad_fn=<MeanBackward0>)\n","tensor(35.7525, grad_fn=<MeanBackward0>)\n","tensor(328847.4375, grad_fn=<MeanBackward0>)\n","tensor(37.1378, grad_fn=<MeanBackward0>)\n","tensor(319662.1250, grad_fn=<MeanBackward0>)\n","[ 508/1000] train_loss: 22.83909 valid_loss: 11.48704\n","EarlyStopping counter: 1 out of 20\n","tensor(34.3467, grad_fn=<MeanBackward0>)\n","tensor(340185.9062, grad_fn=<MeanBackward0>)\n","tensor(33.9212, grad_fn=<MeanBackward0>)\n","tensor(321127.1250, grad_fn=<MeanBackward0>)\n","tensor(35.5076, grad_fn=<MeanBackward0>)\n","tensor(379455.0625, grad_fn=<MeanBackward0>)\n","[ 509/1000] train_loss: 22.32128 valid_loss: 11.46591\n","Validation loss decreased (11.478450 --> 11.465911).  Saving model ...\n","tensor(33.8818, grad_fn=<MeanBackward0>)\n","tensor(353933.5000, grad_fn=<MeanBackward0>)\n","tensor(34.2126, grad_fn=<MeanBackward0>)\n","tensor(319569.8438, grad_fn=<MeanBackward0>)\n","tensor(36.3816, grad_fn=<MeanBackward0>)\n","tensor(329536.4062, grad_fn=<MeanBackward0>)\n","[ 510/1000] train_loss: 22.32787 valid_loss: 11.45734\n","Validation loss decreased (11.465911 --> 11.457342).  Saving model ...\n","tensor(33.3712, grad_fn=<MeanBackward0>)\n","tensor(348395.6875, grad_fn=<MeanBackward0>)\n","tensor(33.4699, grad_fn=<MeanBackward0>)\n","tensor(348645.8750, grad_fn=<MeanBackward0>)\n","tensor(33.4801, grad_fn=<MeanBackward0>)\n","tensor(326500.4688, grad_fn=<MeanBackward0>)\n","[ 511/1000] train_loss: 22.74142 valid_loss: 11.44607\n","Validation loss decreased (11.457342 --> 11.446070).  Saving model ...\n","tensor(34.1184, grad_fn=<MeanBackward0>)\n","tensor(365106.5000, grad_fn=<MeanBackward0>)\n","tensor(37.1128, grad_fn=<MeanBackward0>)\n","tensor(342332.3750, grad_fn=<MeanBackward0>)\n","tensor(33.0127, grad_fn=<MeanBackward0>)\n","tensor(319108.8438, grad_fn=<MeanBackward0>)\n","[ 512/1000] train_loss: 22.62329 valid_loss: 11.40110\n","Validation loss decreased (11.446070 --> 11.401103).  Saving model ...\n","tensor(34.6901, grad_fn=<MeanBackward0>)\n","tensor(360201.5000, grad_fn=<MeanBackward0>)\n","tensor(31.7181, grad_fn=<MeanBackward0>)\n","tensor(311156.1875, grad_fn=<MeanBackward0>)\n","tensor(38.3134, grad_fn=<MeanBackward0>)\n","tensor(350196.6875, grad_fn=<MeanBackward0>)\n","[ 513/1000] train_loss: 22.60386 valid_loss: 11.44016\n","EarlyStopping counter: 1 out of 20\n","tensor(34.0517, grad_fn=<MeanBackward0>)\n","tensor(323336.4688, grad_fn=<MeanBackward0>)\n","tensor(39.7562, grad_fn=<MeanBackward0>)\n","tensor(386005.9062, grad_fn=<MeanBackward0>)\n","tensor(35.1012, grad_fn=<MeanBackward0>)\n","tensor(340422.5938, grad_fn=<MeanBackward0>)\n","[ 514/1000] train_loss: 22.66187 valid_loss: 11.43297\n","EarlyStopping counter: 2 out of 20\n","tensor(35.5691, grad_fn=<MeanBackward0>)\n","tensor(360685.2500, grad_fn=<MeanBackward0>)\n","tensor(35.4055, grad_fn=<MeanBackward0>)\n","tensor(333620.8438, grad_fn=<MeanBackward0>)\n","tensor(31.7933, grad_fn=<MeanBackward0>)\n","tensor(315676.5625, grad_fn=<MeanBackward0>)\n","[ 515/1000] train_loss: 22.46932 valid_loss: 11.42405\n","EarlyStopping counter: 3 out of 20\n","tensor(34.7461, grad_fn=<MeanBackward0>)\n","tensor(325239.5000, grad_fn=<MeanBackward0>)\n","tensor(31.2155, grad_fn=<MeanBackward0>)\n","tensor(328429.5000, grad_fn=<MeanBackward0>)\n","tensor(35.5451, grad_fn=<MeanBackward0>)\n","tensor(339615.9375, grad_fn=<MeanBackward0>)\n","[ 516/1000] train_loss: 22.36864 valid_loss: 11.43184\n","EarlyStopping counter: 4 out of 20\n","tensor(34.9435, grad_fn=<MeanBackward0>)\n","tensor(347301.2188, grad_fn=<MeanBackward0>)\n","tensor(36.2433, grad_fn=<MeanBackward0>)\n","tensor(340956.1562, grad_fn=<MeanBackward0>)\n","tensor(31.9048, grad_fn=<MeanBackward0>)\n","tensor(311284.3438, grad_fn=<MeanBackward0>)\n","[ 517/1000] train_loss: 22.33871 valid_loss: 11.43557\n","EarlyStopping counter: 5 out of 20\n","tensor(33.8907, grad_fn=<MeanBackward0>)\n","tensor(337397.5625, grad_fn=<MeanBackward0>)\n","tensor(34.5175, grad_fn=<MeanBackward0>)\n","tensor(353581.1250, grad_fn=<MeanBackward0>)\n","tensor(33.7220, grad_fn=<MeanBackward0>)\n","tensor(328688.7812, grad_fn=<MeanBackward0>)\n","[ 518/1000] train_loss: 22.24275 valid_loss: 11.37813\n","Validation loss decreased (11.401103 --> 11.378130).  Saving model ...\n","tensor(34.0413, grad_fn=<MeanBackward0>)\n","tensor(353035., grad_fn=<MeanBackward0>)\n","tensor(35.7497, grad_fn=<MeanBackward0>)\n","tensor(314074.6875, grad_fn=<MeanBackward0>)\n","tensor(33.7824, grad_fn=<MeanBackward0>)\n","tensor(344033., grad_fn=<MeanBackward0>)\n","[ 519/1000] train_loss: 22.50698 valid_loss: 11.37286\n","Validation loss decreased (11.378130 --> 11.372862).  Saving model ...\n","tensor(33.8787, grad_fn=<MeanBackward0>)\n","tensor(331044.9688, grad_fn=<MeanBackward0>)\n","tensor(33.1539, grad_fn=<MeanBackward0>)\n","tensor(328346.1250, grad_fn=<MeanBackward0>)\n","tensor(35.1906, grad_fn=<MeanBackward0>)\n","tensor(358182.5625, grad_fn=<MeanBackward0>)\n","[ 520/1000] train_loss: 22.63687 valid_loss: 11.40423\n","EarlyStopping counter: 1 out of 20\n","tensor(36.6344, grad_fn=<MeanBackward0>)\n","tensor(346572.8438, grad_fn=<MeanBackward0>)\n","tensor(33.8620, grad_fn=<MeanBackward0>)\n","tensor(335197.0312, grad_fn=<MeanBackward0>)\n","tensor(31.5796, grad_fn=<MeanBackward0>)\n","tensor(340236.8125, grad_fn=<MeanBackward0>)\n","[ 521/1000] train_loss: 22.45929 valid_loss: 11.39648\n","EarlyStopping counter: 2 out of 20\n","tensor(35.1325, grad_fn=<MeanBackward0>)\n","tensor(348976.4688, grad_fn=<MeanBackward0>)\n","tensor(34.1525, grad_fn=<MeanBackward0>)\n","tensor(325549.9688, grad_fn=<MeanBackward0>)\n","tensor(33.5829, grad_fn=<MeanBackward0>)\n","tensor(336233.1562, grad_fn=<MeanBackward0>)\n","[ 522/1000] train_loss: 22.35103 valid_loss: 11.37274\n","Validation loss decreased (11.372862 --> 11.372740).  Saving model ...\n","tensor(34.7683, grad_fn=<MeanBackward0>)\n","tensor(316650.8125, grad_fn=<MeanBackward0>)\n","tensor(32.2339, grad_fn=<MeanBackward0>)\n","tensor(348050.0938, grad_fn=<MeanBackward0>)\n","tensor(33.4132, grad_fn=<MeanBackward0>)\n","tensor(352880.1875, grad_fn=<MeanBackward0>)\n","[ 523/1000] train_loss: 21.92016 valid_loss: 11.38795\n","EarlyStopping counter: 1 out of 20\n","tensor(34.1604, grad_fn=<MeanBackward0>)\n","tensor(334439.7188, grad_fn=<MeanBackward0>)\n","tensor(35.3895, grad_fn=<MeanBackward0>)\n","tensor(333993.5000, grad_fn=<MeanBackward0>)\n","tensor(37.6821, grad_fn=<MeanBackward0>)\n","tensor(323315.4062, grad_fn=<MeanBackward0>)\n","[ 524/1000] train_loss: 22.80584 valid_loss: 11.39619\n","EarlyStopping counter: 2 out of 20\n","tensor(35.2508, grad_fn=<MeanBackward0>)\n","tensor(349877.3750, grad_fn=<MeanBackward0>)\n","tensor(33.9716, grad_fn=<MeanBackward0>)\n","tensor(334340.4688, grad_fn=<MeanBackward0>)\n","tensor(34.7877, grad_fn=<MeanBackward0>)\n","tensor(326333.4375, grad_fn=<MeanBackward0>)\n","[ 525/1000] train_loss: 22.36044 valid_loss: 11.39653\n","EarlyStopping counter: 3 out of 20\n","tensor(32.6654, grad_fn=<MeanBackward0>)\n","tensor(327515.3125, grad_fn=<MeanBackward0>)\n","tensor(35.9633, grad_fn=<MeanBackward0>)\n","tensor(341887.0625, grad_fn=<MeanBackward0>)\n","tensor(32.3511, grad_fn=<MeanBackward0>)\n","tensor(321820.6562, grad_fn=<MeanBackward0>)\n","[ 526/1000] train_loss: 22.04088 valid_loss: 11.39457\n","EarlyStopping counter: 4 out of 20\n","tensor(33.0521, grad_fn=<MeanBackward0>)\n","tensor(357945.4688, grad_fn=<MeanBackward0>)\n","tensor(33.3058, grad_fn=<MeanBackward0>)\n","tensor(340210.1562, grad_fn=<MeanBackward0>)\n","tensor(35.8703, grad_fn=<MeanBackward0>)\n","tensor(348708.4688, grad_fn=<MeanBackward0>)\n","[ 527/1000] train_loss: 22.37185 valid_loss: 11.45495\n","EarlyStopping counter: 5 out of 20\n","tensor(35.6268, grad_fn=<MeanBackward0>)\n","tensor(367064.6250, grad_fn=<MeanBackward0>)\n","tensor(34.3026, grad_fn=<MeanBackward0>)\n","tensor(337857.7500, grad_fn=<MeanBackward0>)\n","tensor(33.6798, grad_fn=<MeanBackward0>)\n","tensor(302017.5938, grad_fn=<MeanBackward0>)\n","[ 528/1000] train_loss: 22.22435 valid_loss: 11.43134\n","EarlyStopping counter: 6 out of 20\n","tensor(38.4532, grad_fn=<MeanBackward0>)\n","tensor(334228.0312, grad_fn=<MeanBackward0>)\n","tensor(36.8506, grad_fn=<MeanBackward0>)\n","tensor(330116.5312, grad_fn=<MeanBackward0>)\n","tensor(33.0930, grad_fn=<MeanBackward0>)\n","tensor(319229.4062, grad_fn=<MeanBackward0>)\n","[ 529/1000] train_loss: 22.20622 valid_loss: 11.41612\n","EarlyStopping counter: 7 out of 20\n","tensor(32.9004, grad_fn=<MeanBackward0>)\n","tensor(338492.8438, grad_fn=<MeanBackward0>)\n","tensor(33.7538, grad_fn=<MeanBackward0>)\n","tensor(356374.7812, grad_fn=<MeanBackward0>)\n","tensor(33.5750, grad_fn=<MeanBackward0>)\n","tensor(328302.1250, grad_fn=<MeanBackward0>)\n","[ 530/1000] train_loss: 22.18344 valid_loss: 11.37027\n","Validation loss decreased (11.372740 --> 11.370268).  Saving model ...\n","tensor(32.5974, grad_fn=<MeanBackward0>)\n","tensor(320475., grad_fn=<MeanBackward0>)\n","tensor(37.9036, grad_fn=<MeanBackward0>)\n","tensor(323990.4688, grad_fn=<MeanBackward0>)\n","tensor(35.8718, grad_fn=<MeanBackward0>)\n","tensor(314961.0312, grad_fn=<MeanBackward0>)\n","[ 531/1000] train_loss: 22.41413 valid_loss: 11.35073\n","Validation loss decreased (11.370268 --> 11.350735).  Saving model ...\n","tensor(32.7305, grad_fn=<MeanBackward0>)\n","tensor(316514.3438, grad_fn=<MeanBackward0>)\n","tensor(36.0721, grad_fn=<MeanBackward0>)\n","tensor(366577.4062, grad_fn=<MeanBackward0>)\n","tensor(31.5834, grad_fn=<MeanBackward0>)\n","tensor(322235.7500, grad_fn=<MeanBackward0>)\n","[ 532/1000] train_loss: 21.87150 valid_loss: 11.45074\n","EarlyStopping counter: 1 out of 20\n","tensor(31.2487, grad_fn=<MeanBackward0>)\n","tensor(337906.4062, grad_fn=<MeanBackward0>)\n","tensor(30.7489, grad_fn=<MeanBackward0>)\n","tensor(325726.4688, grad_fn=<MeanBackward0>)\n","tensor(34.3522, grad_fn=<MeanBackward0>)\n","tensor(364652.3438, grad_fn=<MeanBackward0>)\n","[ 533/1000] train_loss: 22.08331 valid_loss: 11.56190\n","EarlyStopping counter: 2 out of 20\n","tensor(34.2856, grad_fn=<MeanBackward0>)\n","tensor(331481.7812, grad_fn=<MeanBackward0>)\n","tensor(32.4850, grad_fn=<MeanBackward0>)\n","tensor(321390.7188, grad_fn=<MeanBackward0>)\n","tensor(35.6370, grad_fn=<MeanBackward0>)\n","tensor(337643.5312, grad_fn=<MeanBackward0>)\n","[ 534/1000] train_loss: 21.68483 valid_loss: 11.44644\n","EarlyStopping counter: 3 out of 20\n","tensor(34.4542, grad_fn=<MeanBackward0>)\n","tensor(331554.7812, grad_fn=<MeanBackward0>)\n","tensor(33.3508, grad_fn=<MeanBackward0>)\n","tensor(328997.1562, grad_fn=<MeanBackward0>)\n","tensor(36.6966, grad_fn=<MeanBackward0>)\n","tensor(346994.6250, grad_fn=<MeanBackward0>)\n","[ 535/1000] train_loss: 22.10383 valid_loss: 11.35335\n","EarlyStopping counter: 4 out of 20\n","tensor(33.7177, grad_fn=<MeanBackward0>)\n","tensor(311948.0938, grad_fn=<MeanBackward0>)\n","tensor(33.5513, grad_fn=<MeanBackward0>)\n","tensor(325129.0312, grad_fn=<MeanBackward0>)\n","tensor(37.3490, grad_fn=<MeanBackward0>)\n","tensor(336796.4375, grad_fn=<MeanBackward0>)\n","[ 536/1000] train_loss: 21.88930 valid_loss: 11.31437\n","Validation loss decreased (11.350735 --> 11.314371).  Saving model ...\n","tensor(32.0306, grad_fn=<MeanBackward0>)\n","tensor(325493.8438, grad_fn=<MeanBackward0>)\n","tensor(36.9622, grad_fn=<MeanBackward0>)\n","tensor(337754.5312, grad_fn=<MeanBackward0>)\n","tensor(36.2354, grad_fn=<MeanBackward0>)\n","tensor(322191.8125, grad_fn=<MeanBackward0>)\n","[ 537/1000] train_loss: 22.24555 valid_loss: 11.37797\n","EarlyStopping counter: 1 out of 20\n","tensor(35.6595, grad_fn=<MeanBackward0>)\n","tensor(348359.1250, grad_fn=<MeanBackward0>)\n","tensor(33.5465, grad_fn=<MeanBackward0>)\n","tensor(341245.0312, grad_fn=<MeanBackward0>)\n","tensor(30.4686, grad_fn=<MeanBackward0>)\n","tensor(327826., grad_fn=<MeanBackward0>)\n","[ 538/1000] train_loss: 22.05422 valid_loss: 11.32930\n","EarlyStopping counter: 2 out of 20\n","tensor(32.1692, grad_fn=<MeanBackward0>)\n","tensor(320767.1875, grad_fn=<MeanBackward0>)\n","tensor(32.7251, grad_fn=<MeanBackward0>)\n","tensor(343003.7188, grad_fn=<MeanBackward0>)\n","tensor(34.5072, grad_fn=<MeanBackward0>)\n","tensor(295558.6875, grad_fn=<MeanBackward0>)\n","[ 539/1000] train_loss: 22.06451 valid_loss: 11.26734\n","Validation loss decreased (11.314371 --> 11.267344).  Saving model ...\n","tensor(31.6500, grad_fn=<MeanBackward0>)\n","tensor(280337.9375, grad_fn=<MeanBackward0>)\n","tensor(33.4823, grad_fn=<MeanBackward0>)\n","tensor(328342.3438, grad_fn=<MeanBackward0>)\n","tensor(34.9191, grad_fn=<MeanBackward0>)\n","tensor(352276.7812, grad_fn=<MeanBackward0>)\n","[ 540/1000] train_loss: 21.79111 valid_loss: 11.29987\n","EarlyStopping counter: 1 out of 20\n","tensor(32.1216, grad_fn=<MeanBackward0>)\n","tensor(337568.3438, grad_fn=<MeanBackward0>)\n","tensor(33.8027, grad_fn=<MeanBackward0>)\n","tensor(338028.5312, grad_fn=<MeanBackward0>)\n","tensor(33.3599, grad_fn=<MeanBackward0>)\n","tensor(342626.9062, grad_fn=<MeanBackward0>)\n","[ 541/1000] train_loss: 21.92555 valid_loss: 11.25993\n","Validation loss decreased (11.267344 --> 11.259933).  Saving model ...\n","tensor(35.1196, grad_fn=<MeanBackward0>)\n","tensor(318767.1250, grad_fn=<MeanBackward0>)\n","tensor(33.9344, grad_fn=<MeanBackward0>)\n","tensor(332292.5312, grad_fn=<MeanBackward0>)\n","tensor(33.2922, grad_fn=<MeanBackward0>)\n","tensor(309731.5938, grad_fn=<MeanBackward0>)\n","[ 542/1000] train_loss: 21.90409 valid_loss: 11.27280\n","EarlyStopping counter: 1 out of 20\n","tensor(31.6683, grad_fn=<MeanBackward0>)\n","tensor(321812.7812, grad_fn=<MeanBackward0>)\n","tensor(30.2578, grad_fn=<MeanBackward0>)\n","tensor(306542.9375, grad_fn=<MeanBackward0>)\n","tensor(33.0426, grad_fn=<MeanBackward0>)\n","tensor(356998.6250, grad_fn=<MeanBackward0>)\n","[ 543/1000] train_loss: 22.18181 valid_loss: 11.30228\n","EarlyStopping counter: 2 out of 20\n","tensor(34.6305, grad_fn=<MeanBackward0>)\n","tensor(327979.2188, grad_fn=<MeanBackward0>)\n","tensor(34.0760, grad_fn=<MeanBackward0>)\n","tensor(344744.2188, grad_fn=<MeanBackward0>)\n","tensor(34.0602, grad_fn=<MeanBackward0>)\n","tensor(328864.5000, grad_fn=<MeanBackward0>)\n","[ 544/1000] train_loss: 21.92720 valid_loss: 11.24711\n","Validation loss decreased (11.259933 --> 11.247112).  Saving model ...\n","tensor(33.6690, grad_fn=<MeanBackward0>)\n","tensor(329864.5938, grad_fn=<MeanBackward0>)\n","tensor(34.9172, grad_fn=<MeanBackward0>)\n","tensor(317843.4688, grad_fn=<MeanBackward0>)\n","tensor(33.9685, grad_fn=<MeanBackward0>)\n","tensor(337773.8125, grad_fn=<MeanBackward0>)\n","[ 545/1000] train_loss: 21.87646 valid_loss: 11.23931\n","Validation loss decreased (11.247112 --> 11.239307).  Saving model ...\n","tensor(34.7902, grad_fn=<MeanBackward0>)\n","tensor(322300.4688, grad_fn=<MeanBackward0>)\n","tensor(34.0129, grad_fn=<MeanBackward0>)\n","tensor(324180.4688, grad_fn=<MeanBackward0>)\n","tensor(32.2324, grad_fn=<MeanBackward0>)\n","tensor(333611.2500, grad_fn=<MeanBackward0>)\n","[ 546/1000] train_loss: 22.09853 valid_loss: 11.26902\n","EarlyStopping counter: 1 out of 20\n","tensor(33.6374, grad_fn=<MeanBackward0>)\n","tensor(344332.2812, grad_fn=<MeanBackward0>)\n","tensor(36.7559, grad_fn=<MeanBackward0>)\n","tensor(319696.2500, grad_fn=<MeanBackward0>)\n","tensor(30.6524, grad_fn=<MeanBackward0>)\n","tensor(316944.1250, grad_fn=<MeanBackward0>)\n","[ 547/1000] train_loss: 21.88585 valid_loss: 11.28427\n","EarlyStopping counter: 2 out of 20\n","tensor(33.4230, grad_fn=<MeanBackward0>)\n","tensor(315742.6562, grad_fn=<MeanBackward0>)\n","tensor(31.5276, grad_fn=<MeanBackward0>)\n","tensor(318335.5312, grad_fn=<MeanBackward0>)\n","tensor(33.9025, grad_fn=<MeanBackward0>)\n","tensor(340544.7188, grad_fn=<MeanBackward0>)\n","[ 548/1000] train_loss: 21.79948 valid_loss: 11.23391\n","Validation loss decreased (11.239307 --> 11.233912).  Saving model ...\n","tensor(35.0765, grad_fn=<MeanBackward0>)\n","tensor(364793.2500, grad_fn=<MeanBackward0>)\n","tensor(34.0026, grad_fn=<MeanBackward0>)\n","tensor(309653.7500, grad_fn=<MeanBackward0>)\n","tensor(32.3002, grad_fn=<MeanBackward0>)\n","tensor(283905.5312, grad_fn=<MeanBackward0>)\n","[ 549/1000] train_loss: 21.89520 valid_loss: 11.24401\n","EarlyStopping counter: 1 out of 20\n","tensor(33.3819, grad_fn=<MeanBackward0>)\n","tensor(320002.8438, grad_fn=<MeanBackward0>)\n","tensor(33.3220, grad_fn=<MeanBackward0>)\n","tensor(301912.0938, grad_fn=<MeanBackward0>)\n","tensor(33.5526, grad_fn=<MeanBackward0>)\n","tensor(322834.0312, grad_fn=<MeanBackward0>)\n","[ 550/1000] train_loss: 21.82704 valid_loss: 11.23107\n","Validation loss decreased (11.233912 --> 11.231074).  Saving model ...\n","tensor(35.4346, grad_fn=<MeanBackward0>)\n","tensor(346425.3438, grad_fn=<MeanBackward0>)\n","tensor(32.6557, grad_fn=<MeanBackward0>)\n","tensor(309474.2188, grad_fn=<MeanBackward0>)\n","tensor(34.5393, grad_fn=<MeanBackward0>)\n","tensor(323446.7812, grad_fn=<MeanBackward0>)\n","[ 551/1000] train_loss: 21.85659 valid_loss: 11.23358\n","EarlyStopping counter: 1 out of 20\n","tensor(29.6650, grad_fn=<MeanBackward0>)\n","tensor(359501.5938, grad_fn=<MeanBackward0>)\n","tensor(30.1345, grad_fn=<MeanBackward0>)\n","tensor(309484.0938, grad_fn=<MeanBackward0>)\n","tensor(33.0562, grad_fn=<MeanBackward0>)\n","tensor(344778.3125, grad_fn=<MeanBackward0>)\n","[ 552/1000] train_loss: 21.75821 valid_loss: 11.21185\n","Validation loss decreased (11.231074 --> 11.211854).  Saving model ...\n","tensor(32.8245, grad_fn=<MeanBackward0>)\n","tensor(323791.5312, grad_fn=<MeanBackward0>)\n","tensor(31.9872, grad_fn=<MeanBackward0>)\n","tensor(321028.8125, grad_fn=<MeanBackward0>)\n","tensor(33.3428, grad_fn=<MeanBackward0>)\n","tensor(345954.6562, grad_fn=<MeanBackward0>)\n","[ 553/1000] train_loss: 21.89471 valid_loss: 11.24698\n","EarlyStopping counter: 1 out of 20\n","tensor(32.2745, grad_fn=<MeanBackward0>)\n","tensor(323790.6562, grad_fn=<MeanBackward0>)\n","tensor(33.1949, grad_fn=<MeanBackward0>)\n","tensor(326156.0938, grad_fn=<MeanBackward0>)\n","tensor(32.4150, grad_fn=<MeanBackward0>)\n","tensor(315727.7188, grad_fn=<MeanBackward0>)\n","[ 554/1000] train_loss: 21.38665 valid_loss: 11.25459\n","EarlyStopping counter: 2 out of 20\n","tensor(32.7227, grad_fn=<MeanBackward0>)\n","tensor(304158.2812, grad_fn=<MeanBackward0>)\n","tensor(35.1372, grad_fn=<MeanBackward0>)\n","tensor(334280.9062, grad_fn=<MeanBackward0>)\n","tensor(30.4732, grad_fn=<MeanBackward0>)\n","tensor(289632.8750, grad_fn=<MeanBackward0>)\n","[ 555/1000] train_loss: 21.82904 valid_loss: 11.19536\n","Validation loss decreased (11.211854 --> 11.195356).  Saving model ...\n","tensor(34.7703, grad_fn=<MeanBackward0>)\n","tensor(325452.4688, grad_fn=<MeanBackward0>)\n","tensor(30.1667, grad_fn=<MeanBackward0>)\n","tensor(309122.7812, grad_fn=<MeanBackward0>)\n","tensor(36.7204, grad_fn=<MeanBackward0>)\n","tensor(327650.0312, grad_fn=<MeanBackward0>)\n","[ 556/1000] train_loss: 21.94372 valid_loss: 11.20694\n","EarlyStopping counter: 1 out of 20\n","tensor(31.8585, grad_fn=<MeanBackward0>)\n","tensor(294189.8750, grad_fn=<MeanBackward0>)\n","tensor(34.5380, grad_fn=<MeanBackward0>)\n","tensor(320674.0312, grad_fn=<MeanBackward0>)\n","tensor(33.6859, grad_fn=<MeanBackward0>)\n","tensor(340198.4375, grad_fn=<MeanBackward0>)\n","[ 557/1000] train_loss: 21.61948 valid_loss: 11.21545\n","EarlyStopping counter: 2 out of 20\n","tensor(31.4367, grad_fn=<MeanBackward0>)\n","tensor(320406.3125, grad_fn=<MeanBackward0>)\n","tensor(33.9733, grad_fn=<MeanBackward0>)\n","tensor(307129.4688, grad_fn=<MeanBackward0>)\n","tensor(34.5271, grad_fn=<MeanBackward0>)\n","tensor(325206.0625, grad_fn=<MeanBackward0>)\n","[ 558/1000] train_loss: 21.98542 valid_loss: 11.17843\n","Validation loss decreased (11.195356 --> 11.178428).  Saving model ...\n","tensor(31.3404, grad_fn=<MeanBackward0>)\n","tensor(325159.9688, grad_fn=<MeanBackward0>)\n","tensor(30.3489, grad_fn=<MeanBackward0>)\n","tensor(269403.6562, grad_fn=<MeanBackward0>)\n","tensor(34.5457, grad_fn=<MeanBackward0>)\n","tensor(342925.0625, grad_fn=<MeanBackward0>)\n","[ 559/1000] train_loss: 21.48358 valid_loss: 11.18971\n","EarlyStopping counter: 1 out of 20\n","tensor(31.6390, grad_fn=<MeanBackward0>)\n","tensor(323492.2188, grad_fn=<MeanBackward0>)\n","tensor(30.2259, grad_fn=<MeanBackward0>)\n","tensor(330861.4062, grad_fn=<MeanBackward0>)\n","tensor(32.3029, grad_fn=<MeanBackward0>)\n","tensor(354257.7812, grad_fn=<MeanBackward0>)\n","[ 560/1000] train_loss: 21.54479 valid_loss: 11.18541\n","EarlyStopping counter: 2 out of 20\n","tensor(31.9384, grad_fn=<MeanBackward0>)\n","tensor(300020.2188, grad_fn=<MeanBackward0>)\n","tensor(34.2530, grad_fn=<MeanBackward0>)\n","tensor(338881.2188, grad_fn=<MeanBackward0>)\n","tensor(31.9691, grad_fn=<MeanBackward0>)\n","tensor(312425.2812, grad_fn=<MeanBackward0>)\n","[ 561/1000] train_loss: 21.75480 valid_loss: 11.19855\n","EarlyStopping counter: 3 out of 20\n","tensor(34.2876, grad_fn=<MeanBackward0>)\n","tensor(310547.3438, grad_fn=<MeanBackward0>)\n","tensor(34.9110, grad_fn=<MeanBackward0>)\n","tensor(339653.5625, grad_fn=<MeanBackward0>)\n","tensor(30.0612, grad_fn=<MeanBackward0>)\n","tensor(320975.8750, grad_fn=<MeanBackward0>)\n","[ 562/1000] train_loss: 21.46245 valid_loss: 11.17008\n","Validation loss decreased (11.178428 --> 11.170084).  Saving model ...\n","tensor(33.6014, grad_fn=<MeanBackward0>)\n","tensor(321672.4062, grad_fn=<MeanBackward0>)\n","tensor(32.6418, grad_fn=<MeanBackward0>)\n","tensor(336492.5625, grad_fn=<MeanBackward0>)\n","tensor(31.3328, grad_fn=<MeanBackward0>)\n","tensor(290937.3750, grad_fn=<MeanBackward0>)\n","[ 563/1000] train_loss: 21.58808 valid_loss: 11.16620\n","Validation loss decreased (11.170084 --> 11.166200).  Saving model ...\n","tensor(30.2913, grad_fn=<MeanBackward0>)\n","tensor(317974.3750, grad_fn=<MeanBackward0>)\n","tensor(33.6388, grad_fn=<MeanBackward0>)\n","tensor(297746.0938, grad_fn=<MeanBackward0>)\n","tensor(34.7304, grad_fn=<MeanBackward0>)\n","tensor(337246.1250, grad_fn=<MeanBackward0>)\n","[ 564/1000] train_loss: 21.48353 valid_loss: 11.17389\n","EarlyStopping counter: 1 out of 20\n","tensor(34.7233, grad_fn=<MeanBackward0>)\n","tensor(352511.5938, grad_fn=<MeanBackward0>)\n","tensor(34.1629, grad_fn=<MeanBackward0>)\n","tensor(332854.4688, grad_fn=<MeanBackward0>)\n","tensor(29.3286, grad_fn=<MeanBackward0>)\n","tensor(275939.0312, grad_fn=<MeanBackward0>)\n","[ 565/1000] train_loss: 21.56068 valid_loss: 11.19853\n","EarlyStopping counter: 2 out of 20\n","tensor(31.5137, grad_fn=<MeanBackward0>)\n","tensor(282336.6250, grad_fn=<MeanBackward0>)\n","tensor(34.3878, grad_fn=<MeanBackward0>)\n","tensor(328473.9375, grad_fn=<MeanBackward0>)\n","tensor(33.9856, grad_fn=<MeanBackward0>)\n","tensor(297132.3125, grad_fn=<MeanBackward0>)\n","[ 566/1000] train_loss: 21.46304 valid_loss: 11.15937\n","Validation loss decreased (11.166200 --> 11.159369).  Saving model ...\n","tensor(34.0870, grad_fn=<MeanBackward0>)\n","tensor(326258.0938, grad_fn=<MeanBackward0>)\n","tensor(33.1769, grad_fn=<MeanBackward0>)\n","tensor(280808.2188, grad_fn=<MeanBackward0>)\n","tensor(30.5160, grad_fn=<MeanBackward0>)\n","tensor(322964.0938, grad_fn=<MeanBackward0>)\n","[ 567/1000] train_loss: 21.69802 valid_loss: 11.21834\n","EarlyStopping counter: 1 out of 20\n","tensor(31.7733, grad_fn=<MeanBackward0>)\n","tensor(317608.6562, grad_fn=<MeanBackward0>)\n","tensor(32.2290, grad_fn=<MeanBackward0>)\n","tensor(319802.9688, grad_fn=<MeanBackward0>)\n","tensor(32.1828, grad_fn=<MeanBackward0>)\n","tensor(337913.9375, grad_fn=<MeanBackward0>)\n","[ 568/1000] train_loss: 21.29035 valid_loss: 11.13916\n","Validation loss decreased (11.159369 --> 11.139164).  Saving model ...\n","tensor(32.0898, grad_fn=<MeanBackward0>)\n","tensor(312858.0312, grad_fn=<MeanBackward0>)\n","tensor(34.1931, grad_fn=<MeanBackward0>)\n","tensor(329891.4062, grad_fn=<MeanBackward0>)\n","tensor(32.6764, grad_fn=<MeanBackward0>)\n","tensor(318047.5625, grad_fn=<MeanBackward0>)\n","[ 569/1000] train_loss: 21.45504 valid_loss: 11.14384\n","EarlyStopping counter: 1 out of 20\n","tensor(32.8079, grad_fn=<MeanBackward0>)\n","tensor(310913.2188, grad_fn=<MeanBackward0>)\n","tensor(35.9997, grad_fn=<MeanBackward0>)\n","tensor(311832.4062, grad_fn=<MeanBackward0>)\n","tensor(31.6496, grad_fn=<MeanBackward0>)\n","tensor(302729.8750, grad_fn=<MeanBackward0>)\n","[ 570/1000] train_loss: 21.43998 valid_loss: 11.14220\n","EarlyStopping counter: 2 out of 20\n","tensor(32.0588, grad_fn=<MeanBackward0>)\n","tensor(309551.2500, grad_fn=<MeanBackward0>)\n","tensor(32.4596, grad_fn=<MeanBackward0>)\n","tensor(312776.0938, grad_fn=<MeanBackward0>)\n","tensor(33.9059, grad_fn=<MeanBackward0>)\n","tensor(317961.9688, grad_fn=<MeanBackward0>)\n","[ 571/1000] train_loss: 21.76125 valid_loss: 11.13869\n","Validation loss decreased (11.139164 --> 11.138693).  Saving model ...\n","tensor(36.8601, grad_fn=<MeanBackward0>)\n","tensor(362680.4688, grad_fn=<MeanBackward0>)\n","tensor(30.8879, grad_fn=<MeanBackward0>)\n","tensor(294971.4062, grad_fn=<MeanBackward0>)\n","tensor(33.7013, grad_fn=<MeanBackward0>)\n","tensor(294266.2500, grad_fn=<MeanBackward0>)\n","[ 572/1000] train_loss: 21.58273 valid_loss: 11.09842\n","Validation loss decreased (11.138693 --> 11.098417).  Saving model ...\n","tensor(30.5611, grad_fn=<MeanBackward0>)\n","tensor(309211.9688, grad_fn=<MeanBackward0>)\n","tensor(31.0075, grad_fn=<MeanBackward0>)\n","tensor(334607.2500, grad_fn=<MeanBackward0>)\n","tensor(31.2753, grad_fn=<MeanBackward0>)\n","tensor(324507.7812, grad_fn=<MeanBackward0>)\n","[ 573/1000] train_loss: 21.30523 valid_loss: 11.11172\n","EarlyStopping counter: 1 out of 20\n","tensor(29.9424, grad_fn=<MeanBackward0>)\n","tensor(314658.4062, grad_fn=<MeanBackward0>)\n","tensor(32.4876, grad_fn=<MeanBackward0>)\n","tensor(321857.0938, grad_fn=<MeanBackward0>)\n","tensor(34.2342, grad_fn=<MeanBackward0>)\n","tensor(312230.4375, grad_fn=<MeanBackward0>)\n","[ 574/1000] train_loss: 21.44648 valid_loss: 11.11257\n","EarlyStopping counter: 2 out of 20\n","tensor(32.4048, grad_fn=<MeanBackward0>)\n","tensor(326210.9375, grad_fn=<MeanBackward0>)\n","tensor(29.7887, grad_fn=<MeanBackward0>)\n","tensor(304382.5000, grad_fn=<MeanBackward0>)\n","tensor(33.8768, grad_fn=<MeanBackward0>)\n","tensor(333822.9375, grad_fn=<MeanBackward0>)\n","[ 575/1000] train_loss: 21.21470 valid_loss: 11.09080\n","Validation loss decreased (11.098417 --> 11.090797).  Saving model ...\n","tensor(32.4969, grad_fn=<MeanBackward0>)\n","tensor(287885.2812, grad_fn=<MeanBackward0>)\n","tensor(34.7759, grad_fn=<MeanBackward0>)\n","tensor(308326.7188, grad_fn=<MeanBackward0>)\n","tensor(30.8111, grad_fn=<MeanBackward0>)\n","tensor(341757.6875, grad_fn=<MeanBackward0>)\n","[ 576/1000] train_loss: 21.42962 valid_loss: 11.09449\n","EarlyStopping counter: 1 out of 20\n","tensor(37.2850, grad_fn=<MeanBackward0>)\n","tensor(324467.7812, grad_fn=<MeanBackward0>)\n","tensor(33.0926, grad_fn=<MeanBackward0>)\n","tensor(324770.1250, grad_fn=<MeanBackward0>)\n","tensor(29.5016, grad_fn=<MeanBackward0>)\n","tensor(298736.1562, grad_fn=<MeanBackward0>)\n","[ 577/1000] train_loss: 21.54709 valid_loss: 11.09952\n","EarlyStopping counter: 2 out of 20\n","tensor(35.0761, grad_fn=<MeanBackward0>)\n","tensor(323633.8125, grad_fn=<MeanBackward0>)\n","tensor(29.7801, grad_fn=<MeanBackward0>)\n","tensor(325556.6562, grad_fn=<MeanBackward0>)\n","tensor(31.6115, grad_fn=<MeanBackward0>)\n","tensor(320584.5312, grad_fn=<MeanBackward0>)\n","[ 578/1000] train_loss: 21.49074 valid_loss: 11.08564\n","Validation loss decreased (11.090797 --> 11.085644).  Saving model ...\n","tensor(31.3951, grad_fn=<MeanBackward0>)\n","tensor(316774.9062, grad_fn=<MeanBackward0>)\n","tensor(32.6557, grad_fn=<MeanBackward0>)\n","tensor(313475.4688, grad_fn=<MeanBackward0>)\n","tensor(30.2761, grad_fn=<MeanBackward0>)\n","tensor(304365.6875, grad_fn=<MeanBackward0>)\n","[ 579/1000] train_loss: 21.00468 valid_loss: 11.06319\n","Validation loss decreased (11.085644 --> 11.063188).  Saving model ...\n","tensor(32.3675, grad_fn=<MeanBackward0>)\n","tensor(325223.2188, grad_fn=<MeanBackward0>)\n","tensor(31.8854, grad_fn=<MeanBackward0>)\n","tensor(306513.0625, grad_fn=<MeanBackward0>)\n","tensor(32.6889, grad_fn=<MeanBackward0>)\n","tensor(309335.5625, grad_fn=<MeanBackward0>)\n","[ 580/1000] train_loss: 21.24849 valid_loss: 11.05895\n","Validation loss decreased (11.063188 --> 11.058949).  Saving model ...\n","tensor(31.1681, grad_fn=<MeanBackward0>)\n","tensor(333942.6250, grad_fn=<MeanBackward0>)\n","tensor(34.3694, grad_fn=<MeanBackward0>)\n","tensor(317845.2812, grad_fn=<MeanBackward0>)\n","tensor(30.0723, grad_fn=<MeanBackward0>)\n","tensor(296429.3125, grad_fn=<MeanBackward0>)\n","[ 581/1000] train_loss: 21.35542 valid_loss: 11.06623\n","EarlyStopping counter: 1 out of 20\n","tensor(32.5097, grad_fn=<MeanBackward0>)\n","tensor(319995.9062, grad_fn=<MeanBackward0>)\n","tensor(32.9898, grad_fn=<MeanBackward0>)\n","tensor(292574.0625, grad_fn=<MeanBackward0>)\n","tensor(32.9878, grad_fn=<MeanBackward0>)\n","tensor(320915.8438, grad_fn=<MeanBackward0>)\n","[ 582/1000] train_loss: 21.35545 valid_loss: 11.10755\n","EarlyStopping counter: 2 out of 20\n","tensor(32.2992, grad_fn=<MeanBackward0>)\n","tensor(306200.3750, grad_fn=<MeanBackward0>)\n","tensor(35.7613, grad_fn=<MeanBackward0>)\n","tensor(307933.7812, grad_fn=<MeanBackward0>)\n","tensor(28.4921, grad_fn=<MeanBackward0>)\n","tensor(289036.7812, grad_fn=<MeanBackward0>)\n","[ 583/1000] train_loss: 21.07429 valid_loss: 11.06805\n","EarlyStopping counter: 3 out of 20\n","tensor(31.2901, grad_fn=<MeanBackward0>)\n","tensor(327598.0938, grad_fn=<MeanBackward0>)\n","tensor(33.4425, grad_fn=<MeanBackward0>)\n","tensor(307167.9688, grad_fn=<MeanBackward0>)\n","tensor(32.5927, grad_fn=<MeanBackward0>)\n","tensor(315194.2812, grad_fn=<MeanBackward0>)\n","[ 584/1000] train_loss: 21.28888 valid_loss: 11.07338\n","EarlyStopping counter: 4 out of 20\n","tensor(31.2240, grad_fn=<MeanBackward0>)\n","tensor(327003.0312, grad_fn=<MeanBackward0>)\n","tensor(31.7757, grad_fn=<MeanBackward0>)\n","tensor(307919.3438, grad_fn=<MeanBackward0>)\n","tensor(33.8467, grad_fn=<MeanBackward0>)\n","tensor(319095.7188, grad_fn=<MeanBackward0>)\n","[ 585/1000] train_loss: 21.50398 valid_loss: 11.05715\n","Validation loss decreased (11.058949 --> 11.057146).  Saving model ...\n","tensor(32.6850, grad_fn=<MeanBackward0>)\n","tensor(297859.9688, grad_fn=<MeanBackward0>)\n","tensor(31.3148, grad_fn=<MeanBackward0>)\n","tensor(322092.8125, grad_fn=<MeanBackward0>)\n","tensor(29.7165, grad_fn=<MeanBackward0>)\n","tensor(299635.2188, grad_fn=<MeanBackward0>)\n","[ 586/1000] train_loss: 21.39071 valid_loss: 11.02918\n","Validation loss decreased (11.057146 --> 11.029176).  Saving model ...\n","tensor(30.6565, grad_fn=<MeanBackward0>)\n","tensor(300387.5938, grad_fn=<MeanBackward0>)\n","tensor(35.4153, grad_fn=<MeanBackward0>)\n","tensor(331338.2812, grad_fn=<MeanBackward0>)\n","tensor(30.7308, grad_fn=<MeanBackward0>)\n","tensor(290480.7812, grad_fn=<MeanBackward0>)\n","[ 587/1000] train_loss: 21.29553 valid_loss: 11.07045\n","EarlyStopping counter: 1 out of 20\n","tensor(29.9929, grad_fn=<MeanBackward0>)\n","tensor(294259.8438, grad_fn=<MeanBackward0>)\n","tensor(33.9326, grad_fn=<MeanBackward0>)\n","tensor(334340.9062, grad_fn=<MeanBackward0>)\n","tensor(33.7513, grad_fn=<MeanBackward0>)\n","tensor(314511.5625, grad_fn=<MeanBackward0>)\n","[ 588/1000] train_loss: 20.95961 valid_loss: 11.02310\n","Validation loss decreased (11.029176 --> 11.023102).  Saving model ...\n","tensor(33.0534, grad_fn=<MeanBackward0>)\n","tensor(309495.4375, grad_fn=<MeanBackward0>)\n","tensor(31.8420, grad_fn=<MeanBackward0>)\n","tensor(305854.8750, grad_fn=<MeanBackward0>)\n","tensor(30.0347, grad_fn=<MeanBackward0>)\n","tensor(308799.7188, grad_fn=<MeanBackward0>)\n","[ 589/1000] train_loss: 21.16395 valid_loss: 11.02935\n","EarlyStopping counter: 1 out of 20\n","tensor(31.4240, grad_fn=<MeanBackward0>)\n","tensor(303923.2188, grad_fn=<MeanBackward0>)\n","tensor(30.5231, grad_fn=<MeanBackward0>)\n","tensor(290645.1562, grad_fn=<MeanBackward0>)\n","tensor(33.0936, grad_fn=<MeanBackward0>)\n","tensor(319173.5000, grad_fn=<MeanBackward0>)\n","[ 590/1000] train_loss: 21.03663 valid_loss: 11.03893\n","EarlyStopping counter: 2 out of 20\n","tensor(33.2435, grad_fn=<MeanBackward0>)\n","tensor(302931.4062, grad_fn=<MeanBackward0>)\n","tensor(33.3300, grad_fn=<MeanBackward0>)\n","tensor(321874.9688, grad_fn=<MeanBackward0>)\n","tensor(32.7838, grad_fn=<MeanBackward0>)\n","tensor(328332.3438, grad_fn=<MeanBackward0>)\n","[ 591/1000] train_loss: 21.10843 valid_loss: 11.08517\n","EarlyStopping counter: 3 out of 20\n","tensor(30.9352, grad_fn=<MeanBackward0>)\n","tensor(316212.7500, grad_fn=<MeanBackward0>)\n","tensor(32.5264, grad_fn=<MeanBackward0>)\n","tensor(301737.1250, grad_fn=<MeanBackward0>)\n","tensor(32.5220, grad_fn=<MeanBackward0>)\n","tensor(318824.6562, grad_fn=<MeanBackward0>)\n","[ 592/1000] train_loss: 21.04262 valid_loss: 11.03707\n","EarlyStopping counter: 4 out of 20\n","tensor(34.5550, grad_fn=<MeanBackward0>)\n","tensor(316246.3438, grad_fn=<MeanBackward0>)\n","tensor(30.8092, grad_fn=<MeanBackward0>)\n","tensor(306210.3438, grad_fn=<MeanBackward0>)\n","tensor(31.4037, grad_fn=<MeanBackward0>)\n","tensor(307671., grad_fn=<MeanBackward0>)\n","[ 593/1000] train_loss: 21.19730 valid_loss: 11.02933\n","EarlyStopping counter: 5 out of 20\n","tensor(30.5317, grad_fn=<MeanBackward0>)\n","tensor(276267.7812, grad_fn=<MeanBackward0>)\n","tensor(34.9524, grad_fn=<MeanBackward0>)\n","tensor(347899.6562, grad_fn=<MeanBackward0>)\n","tensor(32.5197, grad_fn=<MeanBackward0>)\n","tensor(315649.3125, grad_fn=<MeanBackward0>)\n","[ 594/1000] train_loss: 21.10930 valid_loss: 11.03819\n","EarlyStopping counter: 6 out of 20\n","tensor(32.5516, grad_fn=<MeanBackward0>)\n","tensor(314290.9062, grad_fn=<MeanBackward0>)\n","tensor(30.7233, grad_fn=<MeanBackward0>)\n","tensor(301838.4688, grad_fn=<MeanBackward0>)\n","tensor(32.5156, grad_fn=<MeanBackward0>)\n","tensor(312427.3438, grad_fn=<MeanBackward0>)\n","[ 595/1000] train_loss: 21.09576 valid_loss: 11.07062\n","EarlyStopping counter: 7 out of 20\n","tensor(32.1671, grad_fn=<MeanBackward0>)\n","tensor(331854.7812, grad_fn=<MeanBackward0>)\n","tensor(36.7747, grad_fn=<MeanBackward0>)\n","tensor(306589.3438, grad_fn=<MeanBackward0>)\n","tensor(29.5077, grad_fn=<MeanBackward0>)\n","tensor(289191.2812, grad_fn=<MeanBackward0>)\n","[ 596/1000] train_loss: 20.91677 valid_loss: 11.03178\n","EarlyStopping counter: 8 out of 20\n","tensor(30.3120, grad_fn=<MeanBackward0>)\n","tensor(300118.9375, grad_fn=<MeanBackward0>)\n","tensor(32.4699, grad_fn=<MeanBackward0>)\n","tensor(306786.8750, grad_fn=<MeanBackward0>)\n","tensor(34.5498, grad_fn=<MeanBackward0>)\n","tensor(286507.1250, grad_fn=<MeanBackward0>)\n","[ 597/1000] train_loss: 20.89860 valid_loss: 10.98047\n","Validation loss decreased (11.023102 --> 10.980466).  Saving model ...\n","tensor(29.2560, grad_fn=<MeanBackward0>)\n","tensor(299168.2500, grad_fn=<MeanBackward0>)\n","tensor(33.1071, grad_fn=<MeanBackward0>)\n","tensor(328202.6562, grad_fn=<MeanBackward0>)\n","tensor(29.9500, grad_fn=<MeanBackward0>)\n","tensor(337410.7188, grad_fn=<MeanBackward0>)\n","[ 598/1000] train_loss: 20.85626 valid_loss: 10.99778\n","EarlyStopping counter: 1 out of 20\n","tensor(32.6885, grad_fn=<MeanBackward0>)\n","tensor(315752.2812, grad_fn=<MeanBackward0>)\n","tensor(30.6552, grad_fn=<MeanBackward0>)\n","tensor(286330.3438, grad_fn=<MeanBackward0>)\n","tensor(31.3609, grad_fn=<MeanBackward0>)\n","tensor(316701.8125, grad_fn=<MeanBackward0>)\n","[ 599/1000] train_loss: 21.03018 valid_loss: 10.95836\n","Validation loss decreased (10.980466 --> 10.958358).  Saving model ...\n","tensor(30.2328, grad_fn=<MeanBackward0>)\n","tensor(295497.2500, grad_fn=<MeanBackward0>)\n","tensor(30.9834, grad_fn=<MeanBackward0>)\n","tensor(304426.4062, grad_fn=<MeanBackward0>)\n","tensor(30.1561, grad_fn=<MeanBackward0>)\n","tensor(319454.6250, grad_fn=<MeanBackward0>)\n","[ 600/1000] train_loss: 21.05789 valid_loss: 10.97841\n","EarlyStopping counter: 1 out of 20\n","tensor(31.7439, grad_fn=<MeanBackward0>)\n","tensor(287960.7812, grad_fn=<MeanBackward0>)\n","tensor(31.0567, grad_fn=<MeanBackward0>)\n","tensor(314613.8438, grad_fn=<MeanBackward0>)\n","tensor(32.8148, grad_fn=<MeanBackward0>)\n","tensor(296509.3125, grad_fn=<MeanBackward0>)\n","[ 601/1000] train_loss: 20.92045 valid_loss: 11.02506\n","EarlyStopping counter: 2 out of 20\n","tensor(32.9135, grad_fn=<MeanBackward0>)\n","tensor(306489.2188, grad_fn=<MeanBackward0>)\n","tensor(33.2698, grad_fn=<MeanBackward0>)\n","tensor(315429.3438, grad_fn=<MeanBackward0>)\n","tensor(32.8944, grad_fn=<MeanBackward0>)\n","tensor(286265.9375, grad_fn=<MeanBackward0>)\n","[ 602/1000] train_loss: 20.75747 valid_loss: 10.97960\n","EarlyStopping counter: 3 out of 20\n","tensor(33.4743, grad_fn=<MeanBackward0>)\n","tensor(311631.1562, grad_fn=<MeanBackward0>)\n","tensor(30.7296, grad_fn=<MeanBackward0>)\n","tensor(300385.9688, grad_fn=<MeanBackward0>)\n","tensor(31.2545, grad_fn=<MeanBackward0>)\n","tensor(298882.5000, grad_fn=<MeanBackward0>)\n","[ 603/1000] train_loss: 20.92569 valid_loss: 10.95595\n","Validation loss decreased (10.958358 --> 10.955945).  Saving model ...\n","tensor(30.0907, grad_fn=<MeanBackward0>)\n","tensor(301299.0312, grad_fn=<MeanBackward0>)\n","tensor(27.9286, grad_fn=<MeanBackward0>)\n","tensor(303919.6562, grad_fn=<MeanBackward0>)\n","tensor(33.2157, grad_fn=<MeanBackward0>)\n","tensor(323900.8125, grad_fn=<MeanBackward0>)\n","[ 604/1000] train_loss: 21.11010 valid_loss: 10.95364\n","Validation loss decreased (10.955945 --> 10.953639).  Saving model ...\n","tensor(29.8915, grad_fn=<MeanBackward0>)\n","tensor(321541.4062, grad_fn=<MeanBackward0>)\n","tensor(31.2930, grad_fn=<MeanBackward0>)\n","tensor(295403.3125, grad_fn=<MeanBackward0>)\n","tensor(31.5153, grad_fn=<MeanBackward0>)\n","tensor(307466.2188, grad_fn=<MeanBackward0>)\n","[ 605/1000] train_loss: 20.92378 valid_loss: 10.99323\n","EarlyStopping counter: 1 out of 20\n","tensor(33.9874, grad_fn=<MeanBackward0>)\n","tensor(302265.2188, grad_fn=<MeanBackward0>)\n","tensor(32.8576, grad_fn=<MeanBackward0>)\n","tensor(290779., grad_fn=<MeanBackward0>)\n","tensor(30.4862, grad_fn=<MeanBackward0>)\n","tensor(286909.9688, grad_fn=<MeanBackward0>)\n","[ 606/1000] train_loss: 20.77250 valid_loss: 10.95009\n","Validation loss decreased (10.953639 --> 10.950088).  Saving model ...\n","tensor(30.1549, grad_fn=<MeanBackward0>)\n","tensor(297643.5625, grad_fn=<MeanBackward0>)\n","tensor(34.3698, grad_fn=<MeanBackward0>)\n","tensor(300058.2500, grad_fn=<MeanBackward0>)\n","tensor(35.3016, grad_fn=<MeanBackward0>)\n","tensor(286345.2188, grad_fn=<MeanBackward0>)\n","[ 607/1000] train_loss: 21.06885 valid_loss: 11.00842\n","EarlyStopping counter: 1 out of 20\n","tensor(31.4804, grad_fn=<MeanBackward0>)\n","tensor(314911.4375, grad_fn=<MeanBackward0>)\n","tensor(29.8535, grad_fn=<MeanBackward0>)\n","tensor(306773.2188, grad_fn=<MeanBackward0>)\n","tensor(29.4811, grad_fn=<MeanBackward0>)\n","tensor(299773.5000, grad_fn=<MeanBackward0>)\n","[ 608/1000] train_loss: 20.81981 valid_loss: 10.97730\n","EarlyStopping counter: 2 out of 20\n","tensor(33.5084, grad_fn=<MeanBackward0>)\n","tensor(314318.3438, grad_fn=<MeanBackward0>)\n","tensor(31.0519, grad_fn=<MeanBackward0>)\n","tensor(302849.5625, grad_fn=<MeanBackward0>)\n","tensor(32.0892, grad_fn=<MeanBackward0>)\n","tensor(303323.6875, grad_fn=<MeanBackward0>)\n","[ 609/1000] train_loss: 21.11660 valid_loss: 10.96141\n","EarlyStopping counter: 3 out of 20\n","tensor(33.3864, grad_fn=<MeanBackward0>)\n","tensor(292962.2188, grad_fn=<MeanBackward0>)\n","tensor(29.1767, grad_fn=<MeanBackward0>)\n","tensor(296456.9062, grad_fn=<MeanBackward0>)\n","tensor(32.3621, grad_fn=<MeanBackward0>)\n","tensor(296879.7500, grad_fn=<MeanBackward0>)\n","[ 610/1000] train_loss: 20.77306 valid_loss: 10.96570\n","EarlyStopping counter: 4 out of 20\n","tensor(29.3337, grad_fn=<MeanBackward0>)\n","tensor(308223.6250, grad_fn=<MeanBackward0>)\n","tensor(30.5805, grad_fn=<MeanBackward0>)\n","tensor(308630.1250, grad_fn=<MeanBackward0>)\n","tensor(33.4554, grad_fn=<MeanBackward0>)\n","tensor(296577.5312, grad_fn=<MeanBackward0>)\n","[ 611/1000] train_loss: 20.95364 valid_loss: 10.94634\n","Validation loss decreased (10.950088 --> 10.946344).  Saving model ...\n","tensor(30.4668, grad_fn=<MeanBackward0>)\n","tensor(316888.2812, grad_fn=<MeanBackward0>)\n","tensor(33.4474, grad_fn=<MeanBackward0>)\n","tensor(303255.7500, grad_fn=<MeanBackward0>)\n","tensor(29.7047, grad_fn=<MeanBackward0>)\n","tensor(288687.3125, grad_fn=<MeanBackward0>)\n","[ 612/1000] train_loss: 20.89599 valid_loss: 10.93441\n","Validation loss decreased (10.946344 --> 10.934414).  Saving model ...\n","tensor(29.2284, grad_fn=<MeanBackward0>)\n","tensor(273238.7812, grad_fn=<MeanBackward0>)\n","tensor(32.3831, grad_fn=<MeanBackward0>)\n","tensor(322867.4062, grad_fn=<MeanBackward0>)\n","tensor(30.6923, grad_fn=<MeanBackward0>)\n","tensor(329782.6875, grad_fn=<MeanBackward0>)\n","[ 613/1000] train_loss: 20.83889 valid_loss: 10.94032\n","EarlyStopping counter: 1 out of 20\n","tensor(31.3074, grad_fn=<MeanBackward0>)\n","tensor(292678.4062, grad_fn=<MeanBackward0>)\n","tensor(29.9797, grad_fn=<MeanBackward0>)\n","tensor(285627.8438, grad_fn=<MeanBackward0>)\n","tensor(32.0971, grad_fn=<MeanBackward0>)\n","tensor(323097.0625, grad_fn=<MeanBackward0>)\n","[ 614/1000] train_loss: 21.00958 valid_loss: 10.96386\n","EarlyStopping counter: 2 out of 20\n","tensor(31.6260, grad_fn=<MeanBackward0>)\n","tensor(315128.4062, grad_fn=<MeanBackward0>)\n","tensor(32.1888, grad_fn=<MeanBackward0>)\n","tensor(286199.5312, grad_fn=<MeanBackward0>)\n","tensor(30.7252, grad_fn=<MeanBackward0>)\n","tensor(301413.0312, grad_fn=<MeanBackward0>)\n","[ 615/1000] train_loss: 20.41815 valid_loss: 10.92197\n","Validation loss decreased (10.934414 --> 10.921967).  Saving model ...\n","tensor(27.0716, grad_fn=<MeanBackward0>)\n","tensor(315773.5312, grad_fn=<MeanBackward0>)\n","tensor(32.6270, grad_fn=<MeanBackward0>)\n","tensor(302348.9062, grad_fn=<MeanBackward0>)\n","tensor(30.3749, grad_fn=<MeanBackward0>)\n","tensor(292999.0938, grad_fn=<MeanBackward0>)\n","[ 616/1000] train_loss: 20.63121 valid_loss: 10.91296\n","Validation loss decreased (10.921967 --> 10.912959).  Saving model ...\n","tensor(31.0242, grad_fn=<MeanBackward0>)\n","tensor(299931.4688, grad_fn=<MeanBackward0>)\n","tensor(28.2594, grad_fn=<MeanBackward0>)\n","tensor(290635.4375, grad_fn=<MeanBackward0>)\n","tensor(32.8673, grad_fn=<MeanBackward0>)\n","tensor(290113.4688, grad_fn=<MeanBackward0>)\n","[ 617/1000] train_loss: 20.66782 valid_loss: 10.93411\n","EarlyStopping counter: 1 out of 20\n","tensor(31.8461, grad_fn=<MeanBackward0>)\n","tensor(312686.7500, grad_fn=<MeanBackward0>)\n","tensor(28.0101, grad_fn=<MeanBackward0>)\n","tensor(292028.0312, grad_fn=<MeanBackward0>)\n","tensor(33.2300, grad_fn=<MeanBackward0>)\n","tensor(305078.9062, grad_fn=<MeanBackward0>)\n","[ 618/1000] train_loss: 20.77327 valid_loss: 10.88266\n","Validation loss decreased (10.912959 --> 10.882665).  Saving model ...\n","tensor(28.0267, grad_fn=<MeanBackward0>)\n","tensor(289214.1562, grad_fn=<MeanBackward0>)\n","tensor(33.0374, grad_fn=<MeanBackward0>)\n","tensor(300276.9062, grad_fn=<MeanBackward0>)\n","tensor(32.6927, grad_fn=<MeanBackward0>)\n","tensor(287359.9688, grad_fn=<MeanBackward0>)\n","[ 619/1000] train_loss: 20.78844 valid_loss: 10.88665\n","EarlyStopping counter: 1 out of 20\n","tensor(32.5100, grad_fn=<MeanBackward0>)\n","tensor(301551.2188, grad_fn=<MeanBackward0>)\n","tensor(30.0868, grad_fn=<MeanBackward0>)\n","tensor(305043.7188, grad_fn=<MeanBackward0>)\n","tensor(30.7810, grad_fn=<MeanBackward0>)\n","tensor(285744.7500, grad_fn=<MeanBackward0>)\n","[ 620/1000] train_loss: 20.54588 valid_loss: 10.92475\n","EarlyStopping counter: 2 out of 20\n","tensor(30.9727, grad_fn=<MeanBackward0>)\n","tensor(292956.5938, grad_fn=<MeanBackward0>)\n","tensor(30.4147, grad_fn=<MeanBackward0>)\n","tensor(292284.8125, grad_fn=<MeanBackward0>)\n","tensor(31.0349, grad_fn=<MeanBackward0>)\n","tensor(314244.7812, grad_fn=<MeanBackward0>)\n","[ 621/1000] train_loss: 20.54648 valid_loss: 10.90446\n","EarlyStopping counter: 3 out of 20\n","tensor(29.9949, grad_fn=<MeanBackward0>)\n","tensor(290135.4688, grad_fn=<MeanBackward0>)\n","tensor(32.1566, grad_fn=<MeanBackward0>)\n","tensor(290438.1562, grad_fn=<MeanBackward0>)\n","tensor(31.5896, grad_fn=<MeanBackward0>)\n","tensor(297062.2812, grad_fn=<MeanBackward0>)\n","[ 622/1000] train_loss: 20.85622 valid_loss: 10.89095\n","EarlyStopping counter: 4 out of 20\n","tensor(31.6110, grad_fn=<MeanBackward0>)\n","tensor(278979.1250, grad_fn=<MeanBackward0>)\n","tensor(29.4419, grad_fn=<MeanBackward0>)\n","tensor(299709.5312, grad_fn=<MeanBackward0>)\n","tensor(30.5286, grad_fn=<MeanBackward0>)\n","tensor(337036.1562, grad_fn=<MeanBackward0>)\n","[ 623/1000] train_loss: 20.73347 valid_loss: 10.88179\n","Validation loss decreased (10.882665 --> 10.881789).  Saving model ...\n","tensor(34.0635, grad_fn=<MeanBackward0>)\n","tensor(327305.6875, grad_fn=<MeanBackward0>)\n","tensor(30.9684, grad_fn=<MeanBackward0>)\n","tensor(291765.1562, grad_fn=<MeanBackward0>)\n","tensor(28.8523, grad_fn=<MeanBackward0>)\n","tensor(270826.1875, grad_fn=<MeanBackward0>)\n","[ 624/1000] train_loss: 20.73276 valid_loss: 10.85371\n","Validation loss decreased (10.881789 --> 10.853715).  Saving model ...\n","tensor(29.3240, grad_fn=<MeanBackward0>)\n","tensor(296959.6562, grad_fn=<MeanBackward0>)\n","tensor(31.7548, grad_fn=<MeanBackward0>)\n","tensor(287231.2500, grad_fn=<MeanBackward0>)\n","tensor(30.7556, grad_fn=<MeanBackward0>)\n","tensor(300316.6250, grad_fn=<MeanBackward0>)\n","[ 625/1000] train_loss: 20.75895 valid_loss: 10.91904\n","EarlyStopping counter: 1 out of 20\n","tensor(30.6923, grad_fn=<MeanBackward0>)\n","tensor(285266.5625, grad_fn=<MeanBackward0>)\n","tensor(33.3440, grad_fn=<MeanBackward0>)\n","tensor(308725.6562, grad_fn=<MeanBackward0>)\n","tensor(31.3115, grad_fn=<MeanBackward0>)\n","tensor(284541.9062, grad_fn=<MeanBackward0>)\n","[ 626/1000] train_loss: 20.63616 valid_loss: 10.91652\n","EarlyStopping counter: 2 out of 20\n","tensor(31.6096, grad_fn=<MeanBackward0>)\n","tensor(314345.0938, grad_fn=<MeanBackward0>)\n","tensor(31.3751, grad_fn=<MeanBackward0>)\n","tensor(290456.9375, grad_fn=<MeanBackward0>)\n","tensor(31.8104, grad_fn=<MeanBackward0>)\n","tensor(290208.9375, grad_fn=<MeanBackward0>)\n","[ 627/1000] train_loss: 20.64484 valid_loss: 10.88804\n","EarlyStopping counter: 3 out of 20\n","tensor(31.8134, grad_fn=<MeanBackward0>)\n","tensor(303742.9688, grad_fn=<MeanBackward0>)\n","tensor(31.0564, grad_fn=<MeanBackward0>)\n","tensor(279884.3438, grad_fn=<MeanBackward0>)\n","tensor(30.1290, grad_fn=<MeanBackward0>)\n","tensor(285955.2812, grad_fn=<MeanBackward0>)\n","[ 628/1000] train_loss: 20.44735 valid_loss: 10.88043\n","EarlyStopping counter: 4 out of 20\n","tensor(30.5639, grad_fn=<MeanBackward0>)\n","tensor(297490.8438, grad_fn=<MeanBackward0>)\n","tensor(31.7254, grad_fn=<MeanBackward0>)\n","tensor(288443.8438, grad_fn=<MeanBackward0>)\n","tensor(31.0375, grad_fn=<MeanBackward0>)\n","tensor(304013.0625, grad_fn=<MeanBackward0>)\n","[ 629/1000] train_loss: 20.55298 valid_loss: 10.88667\n","EarlyStopping counter: 5 out of 20\n","tensor(29.4886, grad_fn=<MeanBackward0>)\n","tensor(287516.3438, grad_fn=<MeanBackward0>)\n","tensor(31.0684, grad_fn=<MeanBackward0>)\n","tensor(303323.7188, grad_fn=<MeanBackward0>)\n","tensor(31.1729, grad_fn=<MeanBackward0>)\n","tensor(299160.2812, grad_fn=<MeanBackward0>)\n","[ 630/1000] train_loss: 20.62333 valid_loss: 10.83129\n","Validation loss decreased (10.853715 --> 10.831289).  Saving model ...\n","tensor(28.1801, grad_fn=<MeanBackward0>)\n","tensor(300389.7500, grad_fn=<MeanBackward0>)\n","tensor(31.3426, grad_fn=<MeanBackward0>)\n","tensor(282950.1562, grad_fn=<MeanBackward0>)\n","tensor(32.0784, grad_fn=<MeanBackward0>)\n","tensor(295054.5625, grad_fn=<MeanBackward0>)\n","[ 631/1000] train_loss: 20.15115 valid_loss: 10.84898\n","EarlyStopping counter: 1 out of 20\n","tensor(30.5052, grad_fn=<MeanBackward0>)\n","tensor(295262.6250, grad_fn=<MeanBackward0>)\n","tensor(31.4346, grad_fn=<MeanBackward0>)\n","tensor(291820.8438, grad_fn=<MeanBackward0>)\n","tensor(28.9377, grad_fn=<MeanBackward0>)\n","tensor(266053.6875, grad_fn=<MeanBackward0>)\n","[ 632/1000] train_loss: 20.57292 valid_loss: 10.84430\n","EarlyStopping counter: 2 out of 20\n","tensor(30.2658, grad_fn=<MeanBackward0>)\n","tensor(281780.2188, grad_fn=<MeanBackward0>)\n","tensor(29.8692, grad_fn=<MeanBackward0>)\n","tensor(290599.7188, grad_fn=<MeanBackward0>)\n","tensor(32.3224, grad_fn=<MeanBackward0>)\n","tensor(307012.3750, grad_fn=<MeanBackward0>)\n","[ 633/1000] train_loss: 20.83164 valid_loss: 10.84865\n","EarlyStopping counter: 3 out of 20\n","tensor(28.2287, grad_fn=<MeanBackward0>)\n","tensor(295804.9375, grad_fn=<MeanBackward0>)\n","tensor(32.3956, grad_fn=<MeanBackward0>)\n","tensor(299066.4062, grad_fn=<MeanBackward0>)\n","tensor(28.1440, grad_fn=<MeanBackward0>)\n","tensor(290385.0312, grad_fn=<MeanBackward0>)\n","[ 634/1000] train_loss: 20.53375 valid_loss: 10.80714\n","Validation loss decreased (10.831289 --> 10.807144).  Saving model ...\n","tensor(32.7514, grad_fn=<MeanBackward0>)\n","tensor(278288.0938, grad_fn=<MeanBackward0>)\n","tensor(29.5979, grad_fn=<MeanBackward0>)\n","tensor(294373.4062, grad_fn=<MeanBackward0>)\n","tensor(31.0799, grad_fn=<MeanBackward0>)\n","tensor(314318.3125, grad_fn=<MeanBackward0>)\n","[ 635/1000] train_loss: 20.61437 valid_loss: 10.85428\n","EarlyStopping counter: 1 out of 20\n","tensor(31.4582, grad_fn=<MeanBackward0>)\n","tensor(277526.9688, grad_fn=<MeanBackward0>)\n","tensor(33.2596, grad_fn=<MeanBackward0>)\n","tensor(308857.4688, grad_fn=<MeanBackward0>)\n","tensor(30.4334, grad_fn=<MeanBackward0>)\n","tensor(284554.2500, grad_fn=<MeanBackward0>)\n","[ 636/1000] train_loss: 20.41108 valid_loss: 10.79489\n","Validation loss decreased (10.807144 --> 10.794894).  Saving model ...\n","tensor(29.3237, grad_fn=<MeanBackward0>)\n","tensor(291175.6250, grad_fn=<MeanBackward0>)\n","tensor(31.6065, grad_fn=<MeanBackward0>)\n","tensor(287314.3438, grad_fn=<MeanBackward0>)\n","tensor(32.1416, grad_fn=<MeanBackward0>)\n","tensor(270152.9062, grad_fn=<MeanBackward0>)\n","[ 637/1000] train_loss: 20.58341 valid_loss: 10.82759\n","EarlyStopping counter: 1 out of 20\n","tensor(31.4173, grad_fn=<MeanBackward0>)\n","tensor(289216.2500, grad_fn=<MeanBackward0>)\n","tensor(29.6499, grad_fn=<MeanBackward0>)\n","tensor(286815.2188, grad_fn=<MeanBackward0>)\n","tensor(31.8894, grad_fn=<MeanBackward0>)\n","tensor(326481.2812, grad_fn=<MeanBackward0>)\n","[ 638/1000] train_loss: 20.57383 valid_loss: 10.84225\n","EarlyStopping counter: 2 out of 20\n","tensor(26.1994, grad_fn=<MeanBackward0>)\n","tensor(268149.5312, grad_fn=<MeanBackward0>)\n","tensor(33.3267, grad_fn=<MeanBackward0>)\n","tensor(310050.5938, grad_fn=<MeanBackward0>)\n","tensor(32.8771, grad_fn=<MeanBackward0>)\n","tensor(293227.9375, grad_fn=<MeanBackward0>)\n","[ 639/1000] train_loss: 20.43316 valid_loss: 10.80564\n","EarlyStopping counter: 3 out of 20\n","tensor(31.0424, grad_fn=<MeanBackward0>)\n","tensor(315582.3438, grad_fn=<MeanBackward0>)\n","tensor(27.2366, grad_fn=<MeanBackward0>)\n","tensor(286365.4688, grad_fn=<MeanBackward0>)\n","tensor(30.1097, grad_fn=<MeanBackward0>)\n","tensor(287893.6562, grad_fn=<MeanBackward0>)\n","[ 640/1000] train_loss: 20.42187 valid_loss: 10.80556\n","EarlyStopping counter: 4 out of 20\n","tensor(30.0480, grad_fn=<MeanBackward0>)\n","tensor(284720.5938, grad_fn=<MeanBackward0>)\n","tensor(29.4463, grad_fn=<MeanBackward0>)\n","tensor(300329.9688, grad_fn=<MeanBackward0>)\n","tensor(31.1076, grad_fn=<MeanBackward0>)\n","tensor(302484.4062, grad_fn=<MeanBackward0>)\n","[ 641/1000] train_loss: 20.19097 valid_loss: 10.83874\n","EarlyStopping counter: 5 out of 20\n","tensor(31.4083, grad_fn=<MeanBackward0>)\n","tensor(294545.9375, grad_fn=<MeanBackward0>)\n","tensor(30.9828, grad_fn=<MeanBackward0>)\n","tensor(260781.4219, grad_fn=<MeanBackward0>)\n","tensor(30.8696, grad_fn=<MeanBackward0>)\n","tensor(308568.2188, grad_fn=<MeanBackward0>)\n","[ 642/1000] train_loss: 20.21707 valid_loss: 10.81255\n","EarlyStopping counter: 6 out of 20\n","tensor(32.2510, grad_fn=<MeanBackward0>)\n","tensor(313220.2500, grad_fn=<MeanBackward0>)\n","tensor(29.0081, grad_fn=<MeanBackward0>)\n","tensor(296151.0938, grad_fn=<MeanBackward0>)\n","tensor(28.3583, grad_fn=<MeanBackward0>)\n","tensor(259791.3438, grad_fn=<MeanBackward0>)\n","[ 643/1000] train_loss: 20.42640 valid_loss: 10.81444\n","EarlyStopping counter: 7 out of 20\n","tensor(26.3196, grad_fn=<MeanBackward0>)\n","tensor(255014.3125, grad_fn=<MeanBackward0>)\n","tensor(33.2603, grad_fn=<MeanBackward0>)\n","tensor(305639.3438, grad_fn=<MeanBackward0>)\n","tensor(32.5842, grad_fn=<MeanBackward0>)\n","tensor(299233.2188, grad_fn=<MeanBackward0>)\n","[ 644/1000] train_loss: 20.41578 valid_loss: 10.79657\n","EarlyStopping counter: 8 out of 20\n","tensor(31.5496, grad_fn=<MeanBackward0>)\n","tensor(288275.3125, grad_fn=<MeanBackward0>)\n","tensor(29.1557, grad_fn=<MeanBackward0>)\n","tensor(284009.0312, grad_fn=<MeanBackward0>)\n","tensor(32.4583, grad_fn=<MeanBackward0>)\n","tensor(292462.4375, grad_fn=<MeanBackward0>)\n","[ 645/1000] train_loss: 20.13749 valid_loss: 10.76704\n","Validation loss decreased (10.794894 --> 10.767044).  Saving model ...\n","tensor(30.3378, grad_fn=<MeanBackward0>)\n","tensor(285517.0938, grad_fn=<MeanBackward0>)\n","tensor(31.2492, grad_fn=<MeanBackward0>)\n","tensor(291457.2500, grad_fn=<MeanBackward0>)\n","tensor(28.4669, grad_fn=<MeanBackward0>)\n","tensor(275688.5625, grad_fn=<MeanBackward0>)\n","[ 646/1000] train_loss: 20.37099 valid_loss: 10.78928\n","EarlyStopping counter: 1 out of 20\n","tensor(30.6184, grad_fn=<MeanBackward0>)\n","tensor(309462.2812, grad_fn=<MeanBackward0>)\n","tensor(28.9226, grad_fn=<MeanBackward0>)\n","tensor(297773.3438, grad_fn=<MeanBackward0>)\n","tensor(29.3866, grad_fn=<MeanBackward0>)\n","tensor(293568.4375, grad_fn=<MeanBackward0>)\n","[ 647/1000] train_loss: 20.40434 valid_loss: 10.77626\n","EarlyStopping counter: 2 out of 20\n","tensor(30.7324, grad_fn=<MeanBackward0>)\n","tensor(279737.2188, grad_fn=<MeanBackward0>)\n","tensor(28.2438, grad_fn=<MeanBackward0>)\n","tensor(300429.7188, grad_fn=<MeanBackward0>)\n","tensor(29.9047, grad_fn=<MeanBackward0>)\n","tensor(276581.5000, grad_fn=<MeanBackward0>)\n","[ 648/1000] train_loss: 20.13583 valid_loss: 10.76315\n","Validation loss decreased (10.767044 --> 10.763151).  Saving model ...\n","tensor(29.7527, grad_fn=<MeanBackward0>)\n","tensor(284980.4375, grad_fn=<MeanBackward0>)\n","tensor(30.6020, grad_fn=<MeanBackward0>)\n","tensor(300271.5312, grad_fn=<MeanBackward0>)\n","tensor(29.9632, grad_fn=<MeanBackward0>)\n","tensor(286016.3438, grad_fn=<MeanBackward0>)\n","[ 649/1000] train_loss: 20.04677 valid_loss: 10.75237\n","Validation loss decreased (10.763151 --> 10.752373).  Saving model ...\n","tensor(30.0450, grad_fn=<MeanBackward0>)\n","tensor(287155.0312, grad_fn=<MeanBackward0>)\n","tensor(30.1371, grad_fn=<MeanBackward0>)\n","tensor(288372.8438, grad_fn=<MeanBackward0>)\n","tensor(31.8623, grad_fn=<MeanBackward0>)\n","tensor(278252., grad_fn=<MeanBackward0>)\n","[ 650/1000] train_loss: 20.35304 valid_loss: 10.77094\n","EarlyStopping counter: 1 out of 20\n","tensor(30.4277, grad_fn=<MeanBackward0>)\n","tensor(280021., grad_fn=<MeanBackward0>)\n","tensor(32.9756, grad_fn=<MeanBackward0>)\n","tensor(310869.4062, grad_fn=<MeanBackward0>)\n","tensor(29.2198, grad_fn=<MeanBackward0>)\n","tensor(264457.8438, grad_fn=<MeanBackward0>)\n","[ 651/1000] train_loss: 20.24312 valid_loss: 10.77017\n","EarlyStopping counter: 2 out of 20\n","tensor(28.4587, grad_fn=<MeanBackward0>)\n","tensor(266967.5625, grad_fn=<MeanBackward0>)\n","tensor(31.7491, grad_fn=<MeanBackward0>)\n","tensor(294839.1875, grad_fn=<MeanBackward0>)\n","tensor(33.3283, grad_fn=<MeanBackward0>)\n","tensor(297782.3750, grad_fn=<MeanBackward0>)\n","[ 652/1000] train_loss: 20.22328 valid_loss: 10.75368\n","EarlyStopping counter: 3 out of 20\n","tensor(28.3466, grad_fn=<MeanBackward0>)\n","tensor(303470.6562, grad_fn=<MeanBackward0>)\n","tensor(32.2893, grad_fn=<MeanBackward0>)\n","tensor(312636.7188, grad_fn=<MeanBackward0>)\n","tensor(28.7824, grad_fn=<MeanBackward0>)\n","tensor(269077.6562, grad_fn=<MeanBackward0>)\n","[ 653/1000] train_loss: 20.33244 valid_loss: 10.75245\n","EarlyStopping counter: 4 out of 20\n","tensor(29.6346, grad_fn=<MeanBackward0>)\n","tensor(303354.9688, grad_fn=<MeanBackward0>)\n","tensor(29.9582, grad_fn=<MeanBackward0>)\n","tensor(266823.8438, grad_fn=<MeanBackward0>)\n","tensor(30.5229, grad_fn=<MeanBackward0>)\n","tensor(281038.7812, grad_fn=<MeanBackward0>)\n","[ 654/1000] train_loss: 20.20595 valid_loss: 10.75180\n","Validation loss decreased (10.752373 --> 10.751802).  Saving model ...\n","tensor(28.1661, grad_fn=<MeanBackward0>)\n","tensor(277437.2188, grad_fn=<MeanBackward0>)\n","tensor(32.3014, grad_fn=<MeanBackward0>)\n","tensor(316160.5938, grad_fn=<MeanBackward0>)\n","tensor(29.1544, grad_fn=<MeanBackward0>)\n","tensor(279797.6562, grad_fn=<MeanBackward0>)\n","[ 655/1000] train_loss: 19.83628 valid_loss: 10.74310\n","Validation loss decreased (10.751802 --> 10.743095).  Saving model ...\n","tensor(32.5655, grad_fn=<MeanBackward0>)\n","tensor(300443.7812, grad_fn=<MeanBackward0>)\n","tensor(28.9772, grad_fn=<MeanBackward0>)\n","tensor(287092.9062, grad_fn=<MeanBackward0>)\n","tensor(29.0912, grad_fn=<MeanBackward0>)\n","tensor(265421.9062, grad_fn=<MeanBackward0>)\n","[ 656/1000] train_loss: 20.18842 valid_loss: 10.74754\n","EarlyStopping counter: 1 out of 20\n","tensor(29.4322, grad_fn=<MeanBackward0>)\n","tensor(282669.7188, grad_fn=<MeanBackward0>)\n","tensor(28.9769, grad_fn=<MeanBackward0>)\n","tensor(273465.6875, grad_fn=<MeanBackward0>)\n","tensor(29.0675, grad_fn=<MeanBackward0>)\n","tensor(286433.5938, grad_fn=<MeanBackward0>)\n","[ 657/1000] train_loss: 19.99653 valid_loss: 10.70361\n","Validation loss decreased (10.743095 --> 10.703609).  Saving model ...\n","tensor(28.5814, grad_fn=<MeanBackward0>)\n","tensor(276187.9062, grad_fn=<MeanBackward0>)\n","tensor(28.2250, grad_fn=<MeanBackward0>)\n","tensor(255540.3125, grad_fn=<MeanBackward0>)\n","tensor(32.8492, grad_fn=<MeanBackward0>)\n","tensor(312528., grad_fn=<MeanBackward0>)\n","[ 658/1000] train_loss: 19.79439 valid_loss: 10.71980\n","EarlyStopping counter: 1 out of 20\n","tensor(31.2698, grad_fn=<MeanBackward0>)\n","tensor(295363.4688, grad_fn=<MeanBackward0>)\n","tensor(31.0181, grad_fn=<MeanBackward0>)\n","tensor(286862.0938, grad_fn=<MeanBackward0>)\n","tensor(31.3444, grad_fn=<MeanBackward0>)\n","tensor(264822.8438, grad_fn=<MeanBackward0>)\n","[ 659/1000] train_loss: 20.18681 valid_loss: 10.76045\n","EarlyStopping counter: 2 out of 20\n","tensor(30.2460, grad_fn=<MeanBackward0>)\n","tensor(270967.2812, grad_fn=<MeanBackward0>)\n","tensor(28.9152, grad_fn=<MeanBackward0>)\n","tensor(291263.9688, grad_fn=<MeanBackward0>)\n","tensor(30.1571, grad_fn=<MeanBackward0>)\n","tensor(287359.6875, grad_fn=<MeanBackward0>)\n","[ 660/1000] train_loss: 20.05621 valid_loss: 10.76119\n","EarlyStopping counter: 3 out of 20\n","tensor(27.0434, grad_fn=<MeanBackward0>)\n","tensor(266468.8125, grad_fn=<MeanBackward0>)\n","tensor(31.5141, grad_fn=<MeanBackward0>)\n","tensor(313641.5938, grad_fn=<MeanBackward0>)\n","tensor(30.5888, grad_fn=<MeanBackward0>)\n","tensor(285266.1875, grad_fn=<MeanBackward0>)\n","[ 661/1000] train_loss: 19.86841 valid_loss: 10.71481\n","EarlyStopping counter: 4 out of 20\n","tensor(28.4501, grad_fn=<MeanBackward0>)\n","tensor(272911.4375, grad_fn=<MeanBackward0>)\n","tensor(32.6706, grad_fn=<MeanBackward0>)\n","tensor(303793.7188, grad_fn=<MeanBackward0>)\n","tensor(29.2737, grad_fn=<MeanBackward0>)\n","tensor(274419.5000, grad_fn=<MeanBackward0>)\n","[ 662/1000] train_loss: 20.04021 valid_loss: 10.72088\n","EarlyStopping counter: 5 out of 20\n","tensor(27.0927, grad_fn=<MeanBackward0>)\n","tensor(285895.8750, grad_fn=<MeanBackward0>)\n","tensor(31.1058, grad_fn=<MeanBackward0>)\n","tensor(294641.8438, grad_fn=<MeanBackward0>)\n","tensor(32.4827, grad_fn=<MeanBackward0>)\n","tensor(274638.1562, grad_fn=<MeanBackward0>)\n","[ 663/1000] train_loss: 20.30398 valid_loss: 10.74230\n","EarlyStopping counter: 6 out of 20\n","tensor(29.0631, grad_fn=<MeanBackward0>)\n","tensor(274761.0312, grad_fn=<MeanBackward0>)\n","tensor(29.7372, grad_fn=<MeanBackward0>)\n","tensor(303916.8750, grad_fn=<MeanBackward0>)\n","tensor(29.5003, grad_fn=<MeanBackward0>)\n","tensor(270888.6562, grad_fn=<MeanBackward0>)\n","[ 664/1000] train_loss: 20.05445 valid_loss: 10.73151\n","EarlyStopping counter: 7 out of 20\n","tensor(30.2754, grad_fn=<MeanBackward0>)\n","tensor(255649., grad_fn=<MeanBackward0>)\n","tensor(28.2851, grad_fn=<MeanBackward0>)\n","tensor(288779.0938, grad_fn=<MeanBackward0>)\n","tensor(29.5195, grad_fn=<MeanBackward0>)\n","tensor(298111.7500, grad_fn=<MeanBackward0>)\n","[ 665/1000] train_loss: 20.20546 valid_loss: 10.71212\n","EarlyStopping counter: 8 out of 20\n","tensor(29.0251, grad_fn=<MeanBackward0>)\n","tensor(294491.4375, grad_fn=<MeanBackward0>)\n","tensor(26.2697, grad_fn=<MeanBackward0>)\n","tensor(288179.2500, grad_fn=<MeanBackward0>)\n","tensor(30.0658, grad_fn=<MeanBackward0>)\n","tensor(305004.4062, grad_fn=<MeanBackward0>)\n","[ 666/1000] train_loss: 20.05453 valid_loss: 10.69767\n","Validation loss decreased (10.703609 --> 10.697670).  Saving model ...\n","tensor(28.6175, grad_fn=<MeanBackward0>)\n","tensor(264806.2188, grad_fn=<MeanBackward0>)\n","tensor(27.8230, grad_fn=<MeanBackward0>)\n","tensor(295358.4688, grad_fn=<MeanBackward0>)\n","tensor(28.8976, grad_fn=<MeanBackward0>)\n","tensor(256265.9531, grad_fn=<MeanBackward0>)\n","[ 667/1000] train_loss: 19.91971 valid_loss: 10.70137\n","EarlyStopping counter: 1 out of 20\n","tensor(30.3073, grad_fn=<MeanBackward0>)\n","tensor(269434.5312, grad_fn=<MeanBackward0>)\n","tensor(30.3624, grad_fn=<MeanBackward0>)\n","tensor(278733.1562, grad_fn=<MeanBackward0>)\n","tensor(32.0037, grad_fn=<MeanBackward0>)\n","tensor(271506.8438, grad_fn=<MeanBackward0>)\n","[ 668/1000] train_loss: 19.94494 valid_loss: 10.75711\n","EarlyStopping counter: 2 out of 20\n","tensor(30.9769, grad_fn=<MeanBackward0>)\n","tensor(283128.7500, grad_fn=<MeanBackward0>)\n","tensor(33.1572, grad_fn=<MeanBackward0>)\n","tensor(296676.3125, grad_fn=<MeanBackward0>)\n","tensor(30.5040, grad_fn=<MeanBackward0>)\n","tensor(271449.4062, grad_fn=<MeanBackward0>)\n","[ 669/1000] train_loss: 20.15199 valid_loss: 10.70057\n","EarlyStopping counter: 3 out of 20\n","tensor(28.3002, grad_fn=<MeanBackward0>)\n","tensor(276608.3125, grad_fn=<MeanBackward0>)\n","tensor(32.3553, grad_fn=<MeanBackward0>)\n","tensor(291969.2812, grad_fn=<MeanBackward0>)\n","tensor(30.3305, grad_fn=<MeanBackward0>)\n","tensor(280083.4375, grad_fn=<MeanBackward0>)\n","[ 670/1000] train_loss: 19.93004 valid_loss: 10.68800\n","Validation loss decreased (10.697670 --> 10.688000).  Saving model ...\n","tensor(27.8357, grad_fn=<MeanBackward0>)\n","tensor(294055.5938, grad_fn=<MeanBackward0>)\n","tensor(29.2629, grad_fn=<MeanBackward0>)\n","tensor(281243.9062, grad_fn=<MeanBackward0>)\n","tensor(28.0505, grad_fn=<MeanBackward0>)\n","tensor(275953.9062, grad_fn=<MeanBackward0>)\n","[ 671/1000] train_loss: 19.86835 valid_loss: 10.69975\n","EarlyStopping counter: 1 out of 20\n","tensor(29.6354, grad_fn=<MeanBackward0>)\n","tensor(287341.7188, grad_fn=<MeanBackward0>)\n","tensor(27.8932, grad_fn=<MeanBackward0>)\n","tensor(292457.2500, grad_fn=<MeanBackward0>)\n","tensor(29.5087, grad_fn=<MeanBackward0>)\n","tensor(270670.7812, grad_fn=<MeanBackward0>)\n","[ 672/1000] train_loss: 20.02336 valid_loss: 10.71248\n","EarlyStopping counter: 2 out of 20\n","tensor(28.9600, grad_fn=<MeanBackward0>)\n","tensor(265592.9375, grad_fn=<MeanBackward0>)\n","tensor(29.4716, grad_fn=<MeanBackward0>)\n","tensor(281280.8438, grad_fn=<MeanBackward0>)\n","tensor(29.8408, grad_fn=<MeanBackward0>)\n","tensor(281744.7500, grad_fn=<MeanBackward0>)\n","[ 673/1000] train_loss: 20.05681 valid_loss: 10.69254\n","EarlyStopping counter: 3 out of 20\n","tensor(31.8569, grad_fn=<MeanBackward0>)\n","tensor(275667.9375, grad_fn=<MeanBackward0>)\n","tensor(28.7886, grad_fn=<MeanBackward0>)\n","tensor(257731.7031, grad_fn=<MeanBackward0>)\n","tensor(31.4615, grad_fn=<MeanBackward0>)\n","tensor(283569.5625, grad_fn=<MeanBackward0>)\n","[ 674/1000] train_loss: 20.22918 valid_loss: 10.71388\n","EarlyStopping counter: 4 out of 20\n","tensor(32.3610, grad_fn=<MeanBackward0>)\n","tensor(279882.4062, grad_fn=<MeanBackward0>)\n","tensor(28.4318, grad_fn=<MeanBackward0>)\n","tensor(287350.6562, grad_fn=<MeanBackward0>)\n","tensor(28.8558, grad_fn=<MeanBackward0>)\n","tensor(257764.6875, grad_fn=<MeanBackward0>)\n","[ 675/1000] train_loss: 20.07577 valid_loss: 10.72305\n","EarlyStopping counter: 5 out of 20\n","tensor(29.4843, grad_fn=<MeanBackward0>)\n","tensor(293790.4688, grad_fn=<MeanBackward0>)\n","tensor(28.2997, grad_fn=<MeanBackward0>)\n","tensor(267505.4375, grad_fn=<MeanBackward0>)\n","tensor(27.2367, grad_fn=<MeanBackward0>)\n","tensor(263272.9688, grad_fn=<MeanBackward0>)\n","[ 676/1000] train_loss: 19.85886 valid_loss: 10.71230\n","EarlyStopping counter: 6 out of 20\n","tensor(29.4001, grad_fn=<MeanBackward0>)\n","tensor(292908.8750, grad_fn=<MeanBackward0>)\n","tensor(27.4022, grad_fn=<MeanBackward0>)\n","tensor(304602., grad_fn=<MeanBackward0>)\n","tensor(27.6212, grad_fn=<MeanBackward0>)\n","tensor(267816.9062, grad_fn=<MeanBackward0>)\n","[ 677/1000] train_loss: 19.81914 valid_loss: 10.70652\n","EarlyStopping counter: 7 out of 20\n","tensor(29.2129, grad_fn=<MeanBackward0>)\n","tensor(280482.5000, grad_fn=<MeanBackward0>)\n","tensor(28.6073, grad_fn=<MeanBackward0>)\n","tensor(290460.8750, grad_fn=<MeanBackward0>)\n","tensor(27.5547, grad_fn=<MeanBackward0>)\n","tensor(288163.5938, grad_fn=<MeanBackward0>)\n","[ 678/1000] train_loss: 19.88974 valid_loss: 10.67608\n","Validation loss decreased (10.688000 --> 10.676077).  Saving model ...\n","tensor(29.6703, grad_fn=<MeanBackward0>)\n","tensor(299701.3438, grad_fn=<MeanBackward0>)\n","tensor(31.5433, grad_fn=<MeanBackward0>)\n","tensor(269174.7812, grad_fn=<MeanBackward0>)\n","tensor(28.3184, grad_fn=<MeanBackward0>)\n","tensor(273495.3125, grad_fn=<MeanBackward0>)\n","[ 679/1000] train_loss: 19.95024 valid_loss: 10.67564\n","Validation loss decreased (10.676077 --> 10.675644).  Saving model ...\n","tensor(29.9764, grad_fn=<MeanBackward0>)\n","tensor(252990.0156, grad_fn=<MeanBackward0>)\n","tensor(28.6941, grad_fn=<MeanBackward0>)\n","tensor(269456.9375, grad_fn=<MeanBackward0>)\n","tensor(31.0788, grad_fn=<MeanBackward0>)\n","tensor(290900.8750, grad_fn=<MeanBackward0>)\n","[ 680/1000] train_loss: 19.77314 valid_loss: 10.72856\n","EarlyStopping counter: 1 out of 20\n","tensor(32.4580, grad_fn=<MeanBackward0>)\n","tensor(302220.2188, grad_fn=<MeanBackward0>)\n","tensor(27.9079, grad_fn=<MeanBackward0>)\n","tensor(252498.6406, grad_fn=<MeanBackward0>)\n","tensor(27.3567, grad_fn=<MeanBackward0>)\n","tensor(271138.5312, grad_fn=<MeanBackward0>)\n","[ 681/1000] train_loss: 20.05630 valid_loss: 10.66561\n","Validation loss decreased (10.675644 --> 10.665610).  Saving model ...\n","tensor(31.0892, grad_fn=<MeanBackward0>)\n","tensor(287417.0938, grad_fn=<MeanBackward0>)\n","tensor(28.9862, grad_fn=<MeanBackward0>)\n","tensor(271546.5938, grad_fn=<MeanBackward0>)\n","tensor(29.6414, grad_fn=<MeanBackward0>)\n","tensor(260079.4844, grad_fn=<MeanBackward0>)\n","[ 682/1000] train_loss: 19.82701 valid_loss: 10.67384\n","EarlyStopping counter: 1 out of 20\n","tensor(26.9586, grad_fn=<MeanBackward0>)\n","tensor(268137.9688, grad_fn=<MeanBackward0>)\n","tensor(26.0732, grad_fn=<MeanBackward0>)\n","tensor(274978.3438, grad_fn=<MeanBackward0>)\n","tensor(30.5233, grad_fn=<MeanBackward0>)\n","tensor(262628.6875, grad_fn=<MeanBackward0>)\n","[ 683/1000] train_loss: 19.73747 valid_loss: 10.64137\n","Validation loss decreased (10.665610 --> 10.641368).  Saving model ...\n","tensor(27.8221, grad_fn=<MeanBackward0>)\n","tensor(250359.1719, grad_fn=<MeanBackward0>)\n","tensor(30.8875, grad_fn=<MeanBackward0>)\n","tensor(302315.6875, grad_fn=<MeanBackward0>)\n","tensor(32.4885, grad_fn=<MeanBackward0>)\n","tensor(275434.7188, grad_fn=<MeanBackward0>)\n","[ 684/1000] train_loss: 19.64744 valid_loss: 10.67879\n","EarlyStopping counter: 1 out of 20\n","tensor(29.7441, grad_fn=<MeanBackward0>)\n","tensor(276073.8438, grad_fn=<MeanBackward0>)\n","tensor(28.7247, grad_fn=<MeanBackward0>)\n","tensor(274506.0938, grad_fn=<MeanBackward0>)\n","tensor(29.6586, grad_fn=<MeanBackward0>)\n","tensor(285877.0938, grad_fn=<MeanBackward0>)\n","[ 685/1000] train_loss: 19.82901 valid_loss: 10.65338\n","EarlyStopping counter: 2 out of 20\n","tensor(29.6297, grad_fn=<MeanBackward0>)\n","tensor(281527.6562, grad_fn=<MeanBackward0>)\n","tensor(30.9640, grad_fn=<MeanBackward0>)\n","tensor(278267.8750, grad_fn=<MeanBackward0>)\n","tensor(25.9360, grad_fn=<MeanBackward0>)\n","tensor(258974.0781, grad_fn=<MeanBackward0>)\n","[ 686/1000] train_loss: 19.65291 valid_loss: 10.64469\n","EarlyStopping counter: 3 out of 20\n","tensor(26.8201, grad_fn=<MeanBackward0>)\n","tensor(272054.7812, grad_fn=<MeanBackward0>)\n","tensor(29.5393, grad_fn=<MeanBackward0>)\n","tensor(267898.1562, grad_fn=<MeanBackward0>)\n","tensor(27.9721, grad_fn=<MeanBackward0>)\n","tensor(267040.1250, grad_fn=<MeanBackward0>)\n","[ 687/1000] train_loss: 19.40291 valid_loss: 10.65139\n","EarlyStopping counter: 4 out of 20\n","tensor(29.0683, grad_fn=<MeanBackward0>)\n","tensor(251223.7969, grad_fn=<MeanBackward0>)\n","tensor(28.6154, grad_fn=<MeanBackward0>)\n","tensor(276331.9688, grad_fn=<MeanBackward0>)\n","tensor(29.3173, grad_fn=<MeanBackward0>)\n","tensor(280043.4062, grad_fn=<MeanBackward0>)\n","[ 688/1000] train_loss: 19.61536 valid_loss: 10.66785\n","EarlyStopping counter: 5 out of 20\n","tensor(28.2891, grad_fn=<MeanBackward0>)\n","tensor(266824.6562, grad_fn=<MeanBackward0>)\n","tensor(29.6783, grad_fn=<MeanBackward0>)\n","tensor(262580.8438, grad_fn=<MeanBackward0>)\n","tensor(32.1339, grad_fn=<MeanBackward0>)\n","tensor(288482.0625, grad_fn=<MeanBackward0>)\n","[ 689/1000] train_loss: 19.68574 valid_loss: 10.64961\n","EarlyStopping counter: 6 out of 20\n","tensor(31.7811, grad_fn=<MeanBackward0>)\n","tensor(295230.5938, grad_fn=<MeanBackward0>)\n","tensor(29.2466, grad_fn=<MeanBackward0>)\n","tensor(271061.9062, grad_fn=<MeanBackward0>)\n","tensor(27.7751, grad_fn=<MeanBackward0>)\n","tensor(264477.8438, grad_fn=<MeanBackward0>)\n","[ 690/1000] train_loss: 19.72408 valid_loss: 10.66133\n","EarlyStopping counter: 7 out of 20\n","tensor(29.6703, grad_fn=<MeanBackward0>)\n","tensor(273821.6562, grad_fn=<MeanBackward0>)\n","tensor(29.1004, grad_fn=<MeanBackward0>)\n","tensor(256734.2031, grad_fn=<MeanBackward0>)\n","tensor(30.3871, grad_fn=<MeanBackward0>)\n","tensor(294044.1562, grad_fn=<MeanBackward0>)\n","[ 691/1000] train_loss: 19.54515 valid_loss: 10.65516\n","EarlyStopping counter: 8 out of 20\n","tensor(26.7874, grad_fn=<MeanBackward0>)\n","tensor(263263.1250, grad_fn=<MeanBackward0>)\n","tensor(29.0503, grad_fn=<MeanBackward0>)\n","tensor(284813.5312, grad_fn=<MeanBackward0>)\n","tensor(27.3408, grad_fn=<MeanBackward0>)\n","tensor(278901.0938, grad_fn=<MeanBackward0>)\n","[ 692/1000] train_loss: 19.40807 valid_loss: 10.62605\n","Validation loss decreased (10.641368 --> 10.626050).  Saving model ...\n","tensor(27.6801, grad_fn=<MeanBackward0>)\n","tensor(258882.3906, grad_fn=<MeanBackward0>)\n","tensor(28.0535, grad_fn=<MeanBackward0>)\n","tensor(271092.1562, grad_fn=<MeanBackward0>)\n","tensor(29.7170, grad_fn=<MeanBackward0>)\n","tensor(277166.6875, grad_fn=<MeanBackward0>)\n","[ 693/1000] train_loss: 19.45367 valid_loss: 10.59893\n","Validation loss decreased (10.626050 --> 10.598927).  Saving model ...\n","tensor(27.9488, grad_fn=<MeanBackward0>)\n","tensor(264404.1562, grad_fn=<MeanBackward0>)\n","tensor(28.1908, grad_fn=<MeanBackward0>)\n","tensor(272850.9062, grad_fn=<MeanBackward0>)\n","tensor(30.1441, grad_fn=<MeanBackward0>)\n","tensor(284479.5625, grad_fn=<MeanBackward0>)\n","[ 694/1000] train_loss: 19.62137 valid_loss: 10.60078\n","EarlyStopping counter: 1 out of 20\n","tensor(27.7695, grad_fn=<MeanBackward0>)\n","tensor(246887.1094, grad_fn=<MeanBackward0>)\n","tensor(29.3107, grad_fn=<MeanBackward0>)\n","tensor(252612.2344, grad_fn=<MeanBackward0>)\n","tensor(27.6463, grad_fn=<MeanBackward0>)\n","tensor(290374.5625, grad_fn=<MeanBackward0>)\n","[ 695/1000] train_loss: 19.63083 valid_loss: 10.59445\n","Validation loss decreased (10.598927 --> 10.594455).  Saving model ...\n","tensor(29.2229, grad_fn=<MeanBackward0>)\n","tensor(290109.9688, grad_fn=<MeanBackward0>)\n","tensor(24.7168, grad_fn=<MeanBackward0>)\n","tensor(246517.9219, grad_fn=<MeanBackward0>)\n","tensor(27.0000, grad_fn=<MeanBackward0>)\n","tensor(260806.2344, grad_fn=<MeanBackward0>)\n","[ 696/1000] train_loss: 19.53144 valid_loss: 10.62011\n","EarlyStopping counter: 1 out of 20\n","tensor(26.9050, grad_fn=<MeanBackward0>)\n","tensor(294618.7188, grad_fn=<MeanBackward0>)\n","tensor(30.4901, grad_fn=<MeanBackward0>)\n","tensor(264378.9688, grad_fn=<MeanBackward0>)\n","tensor(30.6471, grad_fn=<MeanBackward0>)\n","tensor(250713.0938, grad_fn=<MeanBackward0>)\n","[ 697/1000] train_loss: 19.39818 valid_loss: 10.63320\n","EarlyStopping counter: 2 out of 20\n","tensor(30.3050, grad_fn=<MeanBackward0>)\n","tensor(261725.7656, grad_fn=<MeanBackward0>)\n","tensor(27.2386, grad_fn=<MeanBackward0>)\n","tensor(257377.2969, grad_fn=<MeanBackward0>)\n","tensor(31.2884, grad_fn=<MeanBackward0>)\n","tensor(255892.2812, grad_fn=<MeanBackward0>)\n","[ 698/1000] train_loss: 19.46940 valid_loss: 10.57824\n","Validation loss decreased (10.594455 --> 10.578236).  Saving model ...\n","tensor(31.5651, grad_fn=<MeanBackward0>)\n","tensor(270102.2812, grad_fn=<MeanBackward0>)\n","tensor(28.0428, grad_fn=<MeanBackward0>)\n","tensor(257933.8281, grad_fn=<MeanBackward0>)\n","tensor(28.7819, grad_fn=<MeanBackward0>)\n","tensor(272818.8750, grad_fn=<MeanBackward0>)\n","[ 699/1000] train_loss: 19.85917 valid_loss: 10.59273\n","EarlyStopping counter: 1 out of 20\n","tensor(27.5575, grad_fn=<MeanBackward0>)\n","tensor(284156.6562, grad_fn=<MeanBackward0>)\n","tensor(27.0412, grad_fn=<MeanBackward0>)\n","tensor(229361.3281, grad_fn=<MeanBackward0>)\n","tensor(28.0228, grad_fn=<MeanBackward0>)\n","tensor(297852.9688, grad_fn=<MeanBackward0>)\n","[ 700/1000] train_loss: 19.55309 valid_loss: 10.62427\n","EarlyStopping counter: 2 out of 20\n","tensor(30.4212, grad_fn=<MeanBackward0>)\n","tensor(268053.2812, grad_fn=<MeanBackward0>)\n","tensor(27.9298, grad_fn=<MeanBackward0>)\n","tensor(255011.9844, grad_fn=<MeanBackward0>)\n","tensor(28.0219, grad_fn=<MeanBackward0>)\n","tensor(290463.5938, grad_fn=<MeanBackward0>)\n","[ 701/1000] train_loss: 19.55859 valid_loss: 10.57556\n","Validation loss decreased (10.578236 --> 10.575559).  Saving model ...\n","tensor(28.2955, grad_fn=<MeanBackward0>)\n","tensor(268729.2812, grad_fn=<MeanBackward0>)\n","tensor(25.8392, grad_fn=<MeanBackward0>)\n","tensor(284124.0312, grad_fn=<MeanBackward0>)\n","tensor(28.2165, grad_fn=<MeanBackward0>)\n","tensor(258589., grad_fn=<MeanBackward0>)\n","[ 702/1000] train_loss: 19.35870 valid_loss: 10.56026\n","Validation loss decreased (10.575559 --> 10.560262).  Saving model ...\n","tensor(29.4333, grad_fn=<MeanBackward0>)\n","tensor(262983.2812, grad_fn=<MeanBackward0>)\n","tensor(30.7843, grad_fn=<MeanBackward0>)\n","tensor(262073.4219, grad_fn=<MeanBackward0>)\n","tensor(26.2189, grad_fn=<MeanBackward0>)\n","tensor(260583.9531, grad_fn=<MeanBackward0>)\n","[ 703/1000] train_loss: 19.51584 valid_loss: 10.57216\n","EarlyStopping counter: 1 out of 20\n","tensor(28.9988, grad_fn=<MeanBackward0>)\n","tensor(276620.4375, grad_fn=<MeanBackward0>)\n","tensor(30.3434, grad_fn=<MeanBackward0>)\n","tensor(262998.0938, grad_fn=<MeanBackward0>)\n","tensor(26.4830, grad_fn=<MeanBackward0>)\n","tensor(256878.8594, grad_fn=<MeanBackward0>)\n","[ 704/1000] train_loss: 19.56203 valid_loss: 10.57783\n","EarlyStopping counter: 2 out of 20\n","tensor(27.8356, grad_fn=<MeanBackward0>)\n","tensor(259881.9531, grad_fn=<MeanBackward0>)\n","tensor(28.6036, grad_fn=<MeanBackward0>)\n","tensor(276833.1562, grad_fn=<MeanBackward0>)\n","tensor(27.9948, grad_fn=<MeanBackward0>)\n","tensor(275374.1875, grad_fn=<MeanBackward0>)\n","[ 705/1000] train_loss: 19.33059 valid_loss: 10.55265\n","Validation loss decreased (10.560262 --> 10.552649).  Saving model ...\n","tensor(26.4318, grad_fn=<MeanBackward0>)\n","tensor(251425.5781, grad_fn=<MeanBackward0>)\n","tensor(29.2938, grad_fn=<MeanBackward0>)\n","tensor(264643.8125, grad_fn=<MeanBackward0>)\n","tensor(30.7114, grad_fn=<MeanBackward0>)\n","tensor(264806.8125, grad_fn=<MeanBackward0>)\n","[ 706/1000] train_loss: 19.57405 valid_loss: 10.59389\n","EarlyStopping counter: 1 out of 20\n","tensor(26.4743, grad_fn=<MeanBackward0>)\n","tensor(271902.5625, grad_fn=<MeanBackward0>)\n","tensor(29.7992, grad_fn=<MeanBackward0>)\n","tensor(256983.1250, grad_fn=<MeanBackward0>)\n","tensor(27.4447, grad_fn=<MeanBackward0>)\n","tensor(270874.0625, grad_fn=<MeanBackward0>)\n","[ 707/1000] train_loss: 19.36777 valid_loss: 10.65108\n","EarlyStopping counter: 2 out of 20\n","tensor(30.4908, grad_fn=<MeanBackward0>)\n","tensor(280706.9062, grad_fn=<MeanBackward0>)\n","tensor(28.0693, grad_fn=<MeanBackward0>)\n","tensor(259136.4219, grad_fn=<MeanBackward0>)\n","tensor(25.7541, grad_fn=<MeanBackward0>)\n","tensor(262040.1562, grad_fn=<MeanBackward0>)\n","[ 708/1000] train_loss: 19.48992 valid_loss: 10.60395\n","EarlyStopping counter: 3 out of 20\n","tensor(27.0117, grad_fn=<MeanBackward0>)\n","tensor(239976.7500, grad_fn=<MeanBackward0>)\n","tensor(25.4164, grad_fn=<MeanBackward0>)\n","tensor(261661.5781, grad_fn=<MeanBackward0>)\n","tensor(29.7550, grad_fn=<MeanBackward0>)\n","tensor(272299.6875, grad_fn=<MeanBackward0>)\n","[ 709/1000] train_loss: 19.44259 valid_loss: 10.58334\n","EarlyStopping counter: 4 out of 20\n","tensor(28.1221, grad_fn=<MeanBackward0>)\n","tensor(254818.7031, grad_fn=<MeanBackward0>)\n","tensor(30.6629, grad_fn=<MeanBackward0>)\n","tensor(278460.7812, grad_fn=<MeanBackward0>)\n","tensor(31.1882, grad_fn=<MeanBackward0>)\n","tensor(271815.7500, grad_fn=<MeanBackward0>)\n","[ 710/1000] train_loss: 19.37780 valid_loss: 10.55097\n","Validation loss decreased (10.552649 --> 10.550970).  Saving model ...\n","tensor(28.5815, grad_fn=<MeanBackward0>)\n","tensor(245680.3281, grad_fn=<MeanBackward0>)\n","tensor(30.1031, grad_fn=<MeanBackward0>)\n","tensor(260989.9844, grad_fn=<MeanBackward0>)\n","tensor(30.3877, grad_fn=<MeanBackward0>)\n","tensor(280128.5000, grad_fn=<MeanBackward0>)\n","[ 711/1000] train_loss: 19.60291 valid_loss: 10.53431\n","Validation loss decreased (10.550970 --> 10.534310).  Saving model ...\n","tensor(26.9480, grad_fn=<MeanBackward0>)\n","tensor(270334.0938, grad_fn=<MeanBackward0>)\n","tensor(27.2390, grad_fn=<MeanBackward0>)\n","tensor(242082.1875, grad_fn=<MeanBackward0>)\n","tensor(27.8635, grad_fn=<MeanBackward0>)\n","tensor(272880.3750, grad_fn=<MeanBackward0>)\n","[ 712/1000] train_loss: 19.37981 valid_loss: 10.56531\n","EarlyStopping counter: 1 out of 20\n","tensor(26.7637, grad_fn=<MeanBackward0>)\n","tensor(246514.6406, grad_fn=<MeanBackward0>)\n","tensor(30.3014, grad_fn=<MeanBackward0>)\n","tensor(269388.1250, grad_fn=<MeanBackward0>)\n","tensor(29.1012, grad_fn=<MeanBackward0>)\n","tensor(294406.1250, grad_fn=<MeanBackward0>)\n","[ 713/1000] train_loss: 19.31626 valid_loss: 10.54703\n","EarlyStopping counter: 2 out of 20\n","tensor(25.1971, grad_fn=<MeanBackward0>)\n","tensor(261032.5000, grad_fn=<MeanBackward0>)\n","tensor(27.7633, grad_fn=<MeanBackward0>)\n","tensor(262718.5000, grad_fn=<MeanBackward0>)\n","tensor(29.1393, grad_fn=<MeanBackward0>)\n","tensor(247793.6875, grad_fn=<MeanBackward0>)\n","[ 714/1000] train_loss: 19.34141 valid_loss: 10.51815\n","Validation loss decreased (10.534310 --> 10.518146).  Saving model ...\n","tensor(28.7696, grad_fn=<MeanBackward0>)\n","tensor(275206.9062, grad_fn=<MeanBackward0>)\n","tensor(27.3760, grad_fn=<MeanBackward0>)\n","tensor(241914.6094, grad_fn=<MeanBackward0>)\n","tensor(25.4111, grad_fn=<MeanBackward0>)\n","tensor(260061.8438, grad_fn=<MeanBackward0>)\n","[ 715/1000] train_loss: 19.53319 valid_loss: 10.57049\n","EarlyStopping counter: 1 out of 20\n","tensor(25.4261, grad_fn=<MeanBackward0>)\n","tensor(256912.3594, grad_fn=<MeanBackward0>)\n","tensor(34.4277, grad_fn=<MeanBackward0>)\n","tensor(306822.9375, grad_fn=<MeanBackward0>)\n","tensor(29.7891, grad_fn=<MeanBackward0>)\n","tensor(234835.3594, grad_fn=<MeanBackward0>)\n","[ 716/1000] train_loss: 19.52070 valid_loss: 10.55695\n","EarlyStopping counter: 2 out of 20\n","tensor(27.7943, grad_fn=<MeanBackward0>)\n","tensor(251975.7656, grad_fn=<MeanBackward0>)\n","tensor(27.9043, grad_fn=<MeanBackward0>)\n","tensor(267143.0312, grad_fn=<MeanBackward0>)\n","tensor(28.3161, grad_fn=<MeanBackward0>)\n","tensor(255710.6562, grad_fn=<MeanBackward0>)\n","[ 717/1000] train_loss: 19.47838 valid_loss: 10.59044\n","EarlyStopping counter: 3 out of 20\n","tensor(25.9507, grad_fn=<MeanBackward0>)\n","tensor(267334.2188, grad_fn=<MeanBackward0>)\n","tensor(26.1605, grad_fn=<MeanBackward0>)\n","tensor(264861.5625, grad_fn=<MeanBackward0>)\n","tensor(27.6425, grad_fn=<MeanBackward0>)\n","tensor(267364.5000, grad_fn=<MeanBackward0>)\n","[ 718/1000] train_loss: 19.28736 valid_loss: 10.58235\n","EarlyStopping counter: 4 out of 20\n","tensor(26.0854, grad_fn=<MeanBackward0>)\n","tensor(259236.9844, grad_fn=<MeanBackward0>)\n","tensor(27.7804, grad_fn=<MeanBackward0>)\n","tensor(231196.0625, grad_fn=<MeanBackward0>)\n","tensor(31.5858, grad_fn=<MeanBackward0>)\n","tensor(271906.5625, grad_fn=<MeanBackward0>)\n","[ 719/1000] train_loss: 19.10003 valid_loss: 10.71137\n","EarlyStopping counter: 5 out of 20\n","tensor(29.0436, grad_fn=<MeanBackward0>)\n","tensor(252065.3750, grad_fn=<MeanBackward0>)\n","tensor(27.5745, grad_fn=<MeanBackward0>)\n","tensor(259979.4531, grad_fn=<MeanBackward0>)\n","tensor(27.5843, grad_fn=<MeanBackward0>)\n","tensor(265996.8125, grad_fn=<MeanBackward0>)\n","[ 720/1000] train_loss: 18.95288 valid_loss: 10.59588\n","EarlyStopping counter: 6 out of 20\n","tensor(28.7172, grad_fn=<MeanBackward0>)\n","tensor(258205.9375, grad_fn=<MeanBackward0>)\n","tensor(26.3225, grad_fn=<MeanBackward0>)\n","tensor(272241., grad_fn=<MeanBackward0>)\n","tensor(27.7668, grad_fn=<MeanBackward0>)\n","tensor(264660.8750, grad_fn=<MeanBackward0>)\n","[ 721/1000] train_loss: 19.31134 valid_loss: 10.60866\n","EarlyStopping counter: 7 out of 20\n","tensor(30.6556, grad_fn=<MeanBackward0>)\n","tensor(276945.7500, grad_fn=<MeanBackward0>)\n","tensor(28.1643, grad_fn=<MeanBackward0>)\n","tensor(267377.9062, grad_fn=<MeanBackward0>)\n","tensor(27.8656, grad_fn=<MeanBackward0>)\n","tensor(234513.7500, grad_fn=<MeanBackward0>)\n","[ 722/1000] train_loss: 19.25119 valid_loss: 10.57757\n","EarlyStopping counter: 8 out of 20\n","tensor(25.4544, grad_fn=<MeanBackward0>)\n","tensor(256975.4531, grad_fn=<MeanBackward0>)\n","tensor(27.7325, grad_fn=<MeanBackward0>)\n","tensor(245980.9844, grad_fn=<MeanBackward0>)\n","tensor(27.9628, grad_fn=<MeanBackward0>)\n","tensor(273351.4062, grad_fn=<MeanBackward0>)\n","[ 723/1000] train_loss: 19.03399 valid_loss: 10.58862\n","EarlyStopping counter: 9 out of 20\n","tensor(27.4277, grad_fn=<MeanBackward0>)\n","tensor(235806.5469, grad_fn=<MeanBackward0>)\n","tensor(26.8705, grad_fn=<MeanBackward0>)\n","tensor(272453.2500, grad_fn=<MeanBackward0>)\n","tensor(28.5385, grad_fn=<MeanBackward0>)\n","tensor(259017.2344, grad_fn=<MeanBackward0>)\n","[ 724/1000] train_loss: 19.42017 valid_loss: 10.57063\n","EarlyStopping counter: 10 out of 20\n","tensor(28.0266, grad_fn=<MeanBackward0>)\n","tensor(263287.8750, grad_fn=<MeanBackward0>)\n","tensor(26.6730, grad_fn=<MeanBackward0>)\n","tensor(258919.3750, grad_fn=<MeanBackward0>)\n","tensor(28.9941, grad_fn=<MeanBackward0>)\n","tensor(257800.5625, grad_fn=<MeanBackward0>)\n","[ 725/1000] train_loss: 19.28400 valid_loss: 10.56184\n","EarlyStopping counter: 11 out of 20\n","tensor(28.4072, grad_fn=<MeanBackward0>)\n","tensor(263021.9375, grad_fn=<MeanBackward0>)\n","tensor(30.0944, grad_fn=<MeanBackward0>)\n","tensor(256764.3281, grad_fn=<MeanBackward0>)\n","tensor(29.0310, grad_fn=<MeanBackward0>)\n","tensor(265072.5000, grad_fn=<MeanBackward0>)\n","[ 726/1000] train_loss: 19.20527 valid_loss: 10.56044\n","EarlyStopping counter: 12 out of 20\n","tensor(27.6240, grad_fn=<MeanBackward0>)\n","tensor(283128.6250, grad_fn=<MeanBackward0>)\n","tensor(26.5878, grad_fn=<MeanBackward0>)\n","tensor(241663.0781, grad_fn=<MeanBackward0>)\n","tensor(27.1763, grad_fn=<MeanBackward0>)\n","tensor(247208.3125, grad_fn=<MeanBackward0>)\n","[ 727/1000] train_loss: 19.11434 valid_loss: 10.51556\n","Validation loss decreased (10.518146 --> 10.515559).  Saving model ...\n","tensor(27.5519, grad_fn=<MeanBackward0>)\n","tensor(259879.8750, grad_fn=<MeanBackward0>)\n","tensor(27.9034, grad_fn=<MeanBackward0>)\n","tensor(258478.7344, grad_fn=<MeanBackward0>)\n","tensor(27.1262, grad_fn=<MeanBackward0>)\n","tensor(249006.8594, grad_fn=<MeanBackward0>)\n","[ 728/1000] train_loss: 19.28707 valid_loss: 10.48013\n","Validation loss decreased (10.515559 --> 10.480129).  Saving model ...\n","tensor(27.5108, grad_fn=<MeanBackward0>)\n","tensor(247857.0781, grad_fn=<MeanBackward0>)\n","tensor(26.4181, grad_fn=<MeanBackward0>)\n","tensor(272823.7812, grad_fn=<MeanBackward0>)\n","tensor(29.8202, grad_fn=<MeanBackward0>)\n","tensor(242281.0938, grad_fn=<MeanBackward0>)\n","[ 729/1000] train_loss: 19.10404 valid_loss: 10.47217\n","Validation loss decreased (10.480129 --> 10.472166).  Saving model ...\n","tensor(27.3549, grad_fn=<MeanBackward0>)\n","tensor(276985.6250, grad_fn=<MeanBackward0>)\n","tensor(27.5352, grad_fn=<MeanBackward0>)\n","tensor(248663.5781, grad_fn=<MeanBackward0>)\n","tensor(29.6981, grad_fn=<MeanBackward0>)\n","tensor(256894.2031, grad_fn=<MeanBackward0>)\n","[ 730/1000] train_loss: 19.21373 valid_loss: 10.46749\n","Validation loss decreased (10.472166 --> 10.467486).  Saving model ...\n","tensor(27.8730, grad_fn=<MeanBackward0>)\n","tensor(265514.9688, grad_fn=<MeanBackward0>)\n","tensor(27.1346, grad_fn=<MeanBackward0>)\n","tensor(252647.1875, grad_fn=<MeanBackward0>)\n","tensor(27.3675, grad_fn=<MeanBackward0>)\n","tensor(235186.1250, grad_fn=<MeanBackward0>)\n","[ 731/1000] train_loss: 19.00137 valid_loss: 10.50571\n","EarlyStopping counter: 1 out of 20\n","tensor(26.8314, grad_fn=<MeanBackward0>)\n","tensor(262690.5312, grad_fn=<MeanBackward0>)\n","tensor(25.5749, grad_fn=<MeanBackward0>)\n","tensor(269480.4688, grad_fn=<MeanBackward0>)\n","tensor(29.1190, grad_fn=<MeanBackward0>)\n","tensor(247710.6094, grad_fn=<MeanBackward0>)\n","[ 732/1000] train_loss: 19.02879 valid_loss: 10.49629\n","EarlyStopping counter: 2 out of 20\n","tensor(25.5795, grad_fn=<MeanBackward0>)\n","tensor(253634.3594, grad_fn=<MeanBackward0>)\n","tensor(28.0716, grad_fn=<MeanBackward0>)\n","tensor(261016.8750, grad_fn=<MeanBackward0>)\n","tensor(26.2146, grad_fn=<MeanBackward0>)\n","tensor(247784.5781, grad_fn=<MeanBackward0>)\n","[ 733/1000] train_loss: 19.02522 valid_loss: 10.47129\n","EarlyStopping counter: 3 out of 20\n","tensor(27.8084, grad_fn=<MeanBackward0>)\n","tensor(254379.0469, grad_fn=<MeanBackward0>)\n","tensor(28.4583, grad_fn=<MeanBackward0>)\n","tensor(255820.1250, grad_fn=<MeanBackward0>)\n","tensor(25.8520, grad_fn=<MeanBackward0>)\n","tensor(260850.2344, grad_fn=<MeanBackward0>)\n","[ 734/1000] train_loss: 19.16135 valid_loss: 10.48731\n","EarlyStopping counter: 4 out of 20\n","tensor(27.2629, grad_fn=<MeanBackward0>)\n","tensor(257489.3594, grad_fn=<MeanBackward0>)\n","tensor(28.3106, grad_fn=<MeanBackward0>)\n","tensor(249107.4844, grad_fn=<MeanBackward0>)\n","tensor(28.0588, grad_fn=<MeanBackward0>)\n","tensor(266892.5625, grad_fn=<MeanBackward0>)\n","[ 735/1000] train_loss: 19.15336 valid_loss: 10.45952\n","Validation loss decreased (10.467486 --> 10.459518).  Saving model ...\n","tensor(28.4778, grad_fn=<MeanBackward0>)\n","tensor(246104.1875, grad_fn=<MeanBackward0>)\n","tensor(25.1073, grad_fn=<MeanBackward0>)\n","tensor(249864.6250, grad_fn=<MeanBackward0>)\n","tensor(27.4410, grad_fn=<MeanBackward0>)\n","tensor(242189.1719, grad_fn=<MeanBackward0>)\n","[ 736/1000] train_loss: 19.02904 valid_loss: 10.45653\n","Validation loss decreased (10.459518 --> 10.456528).  Saving model ...\n","tensor(25.1535, grad_fn=<MeanBackward0>)\n","tensor(252363.1094, grad_fn=<MeanBackward0>)\n","tensor(27.7365, grad_fn=<MeanBackward0>)\n","tensor(268507.0312, grad_fn=<MeanBackward0>)\n","tensor(28.2912, grad_fn=<MeanBackward0>)\n","tensor(251169.2500, grad_fn=<MeanBackward0>)\n","[ 737/1000] train_loss: 19.00612 valid_loss: 10.48309\n","EarlyStopping counter: 1 out of 20\n","tensor(30.8585, grad_fn=<MeanBackward0>)\n","tensor(268860.7188, grad_fn=<MeanBackward0>)\n","tensor(27.3802, grad_fn=<MeanBackward0>)\n","tensor(254175.0156, grad_fn=<MeanBackward0>)\n","tensor(27.0940, grad_fn=<MeanBackward0>)\n","tensor(251034.4219, grad_fn=<MeanBackward0>)\n","[ 738/1000] train_loss: 19.10471 valid_loss: 10.45924\n","EarlyStopping counter: 2 out of 20\n","tensor(26.6184, grad_fn=<MeanBackward0>)\n","tensor(239026.6406, grad_fn=<MeanBackward0>)\n","tensor(26.8578, grad_fn=<MeanBackward0>)\n","tensor(259449.6719, grad_fn=<MeanBackward0>)\n","tensor(26.9529, grad_fn=<MeanBackward0>)\n","tensor(230200.9688, grad_fn=<MeanBackward0>)\n","[ 739/1000] train_loss: 18.81719 valid_loss: 10.44338\n","Validation loss decreased (10.456528 --> 10.443382).  Saving model ...\n","tensor(26.8592, grad_fn=<MeanBackward0>)\n","tensor(255520.3750, grad_fn=<MeanBackward0>)\n","tensor(27.2002, grad_fn=<MeanBackward0>)\n","tensor(252782.3750, grad_fn=<MeanBackward0>)\n","tensor(26.4903, grad_fn=<MeanBackward0>)\n","tensor(247873.1250, grad_fn=<MeanBackward0>)\n","[ 740/1000] train_loss: 18.81005 valid_loss: 10.48394\n","EarlyStopping counter: 1 out of 20\n","tensor(26.1797, grad_fn=<MeanBackward0>)\n","tensor(253412.6719, grad_fn=<MeanBackward0>)\n","tensor(28.1842, grad_fn=<MeanBackward0>)\n","tensor(257299.6250, grad_fn=<MeanBackward0>)\n","tensor(27.8105, grad_fn=<MeanBackward0>)\n","tensor(252294.5938, grad_fn=<MeanBackward0>)\n","[ 741/1000] train_loss: 19.00979 valid_loss: 10.43153\n","Validation loss decreased (10.443382 --> 10.431531).  Saving model ...\n","tensor(24.2151, grad_fn=<MeanBackward0>)\n","tensor(232203.6406, grad_fn=<MeanBackward0>)\n","tensor(29.6263, grad_fn=<MeanBackward0>)\n","tensor(251017.7344, grad_fn=<MeanBackward0>)\n","tensor(25.9313, grad_fn=<MeanBackward0>)\n","tensor(253189.7344, grad_fn=<MeanBackward0>)\n","[ 742/1000] train_loss: 19.15424 valid_loss: 10.42775\n","Validation loss decreased (10.431531 --> 10.427750).  Saving model ...\n","tensor(24.6091, grad_fn=<MeanBackward0>)\n","tensor(266253.3438, grad_fn=<MeanBackward0>)\n","tensor(30.1051, grad_fn=<MeanBackward0>)\n","tensor(245720.8281, grad_fn=<MeanBackward0>)\n","tensor(28.2342, grad_fn=<MeanBackward0>)\n","tensor(233649.7031, grad_fn=<MeanBackward0>)\n","[ 743/1000] train_loss: 18.87443 valid_loss: 10.46206\n","EarlyStopping counter: 1 out of 20\n","tensor(27.1590, grad_fn=<MeanBackward0>)\n","tensor(251095.4844, grad_fn=<MeanBackward0>)\n","tensor(28.4097, grad_fn=<MeanBackward0>)\n","tensor(251716., grad_fn=<MeanBackward0>)\n","tensor(29.3857, grad_fn=<MeanBackward0>)\n","tensor(246500.3906, grad_fn=<MeanBackward0>)\n","[ 744/1000] train_loss: 19.02563 valid_loss: 10.41808\n","Validation loss decreased (10.427750 --> 10.418080).  Saving model ...\n","tensor(26.1061, grad_fn=<MeanBackward0>)\n","tensor(227017.7969, grad_fn=<MeanBackward0>)\n","tensor(29.0150, grad_fn=<MeanBackward0>)\n","tensor(250253.2031, grad_fn=<MeanBackward0>)\n","tensor(28.8305, grad_fn=<MeanBackward0>)\n","tensor(280091.0938, grad_fn=<MeanBackward0>)\n","[ 745/1000] train_loss: 19.14045 valid_loss: 10.41479\n","Validation loss decreased (10.418080 --> 10.414788).  Saving model ...\n","tensor(25.7151, grad_fn=<MeanBackward0>)\n","tensor(259705.7969, grad_fn=<MeanBackward0>)\n","tensor(28.8971, grad_fn=<MeanBackward0>)\n","tensor(247497.3594, grad_fn=<MeanBackward0>)\n","tensor(26.1906, grad_fn=<MeanBackward0>)\n","tensor(228322.5781, grad_fn=<MeanBackward0>)\n","[ 746/1000] train_loss: 18.96947 valid_loss: 10.40671\n","Validation loss decreased (10.414788 --> 10.406708).  Saving model ...\n","tensor(26.4594, grad_fn=<MeanBackward0>)\n","tensor(254844.1250, grad_fn=<MeanBackward0>)\n","tensor(26.7411, grad_fn=<MeanBackward0>)\n","tensor(264289.0938, grad_fn=<MeanBackward0>)\n","tensor(27.7669, grad_fn=<MeanBackward0>)\n","tensor(226092.1875, grad_fn=<MeanBackward0>)\n","[ 747/1000] train_loss: 18.87608 valid_loss: 10.40703\n","EarlyStopping counter: 1 out of 20\n","tensor(26.0531, grad_fn=<MeanBackward0>)\n","tensor(247034.1719, grad_fn=<MeanBackward0>)\n","tensor(26.1244, grad_fn=<MeanBackward0>)\n","tensor(256853.7500, grad_fn=<MeanBackward0>)\n","tensor(28.7530, grad_fn=<MeanBackward0>)\n","tensor(255489.6094, grad_fn=<MeanBackward0>)\n","[ 748/1000] train_loss: 18.81674 valid_loss: 10.42825\n","EarlyStopping counter: 2 out of 20\n","tensor(24.1201, grad_fn=<MeanBackward0>)\n","tensor(245685.1250, grad_fn=<MeanBackward0>)\n","tensor(26.7293, grad_fn=<MeanBackward0>)\n","tensor(243654.6406, grad_fn=<MeanBackward0>)\n","tensor(26.3893, grad_fn=<MeanBackward0>)\n","tensor(238402.5781, grad_fn=<MeanBackward0>)\n","[ 749/1000] train_loss: 18.62112 valid_loss: 10.40832\n","EarlyStopping counter: 3 out of 20\n","tensor(26.4981, grad_fn=<MeanBackward0>)\n","tensor(240991.0625, grad_fn=<MeanBackward0>)\n","tensor(26.0081, grad_fn=<MeanBackward0>)\n","tensor(245057.8750, grad_fn=<MeanBackward0>)\n","tensor(28.6352, grad_fn=<MeanBackward0>)\n","tensor(255433.4375, grad_fn=<MeanBackward0>)\n","[ 750/1000] train_loss: 18.81660 valid_loss: 10.39628\n","Validation loss decreased (10.406708 --> 10.396282).  Saving model ...\n","tensor(26.3281, grad_fn=<MeanBackward0>)\n","tensor(244014.9531, grad_fn=<MeanBackward0>)\n","tensor(26.3588, grad_fn=<MeanBackward0>)\n","tensor(260374.1250, grad_fn=<MeanBackward0>)\n","tensor(27.2140, grad_fn=<MeanBackward0>)\n","tensor(229486.4062, grad_fn=<MeanBackward0>)\n","[ 751/1000] train_loss: 18.61191 valid_loss: 10.38468\n","Validation loss decreased (10.396282 --> 10.384675).  Saving model ...\n","tensor(26.1388, grad_fn=<MeanBackward0>)\n","tensor(231659.2656, grad_fn=<MeanBackward0>)\n","tensor(26.0663, grad_fn=<MeanBackward0>)\n","tensor(250253.4219, grad_fn=<MeanBackward0>)\n","tensor(25.6643, grad_fn=<MeanBackward0>)\n","tensor(231575.5469, grad_fn=<MeanBackward0>)\n","[ 752/1000] train_loss: 18.64589 valid_loss: 10.40009\n","EarlyStopping counter: 1 out of 20\n","tensor(26.9725, grad_fn=<MeanBackward0>)\n","tensor(266626.7812, grad_fn=<MeanBackward0>)\n","tensor(25.9261, grad_fn=<MeanBackward0>)\n","tensor(244602.7656, grad_fn=<MeanBackward0>)\n","tensor(26.6417, grad_fn=<MeanBackward0>)\n","tensor(247397.7656, grad_fn=<MeanBackward0>)\n","[ 753/1000] train_loss: 18.90441 valid_loss: 10.43248\n","EarlyStopping counter: 2 out of 20\n","tensor(27.1845, grad_fn=<MeanBackward0>)\n","tensor(245090.8906, grad_fn=<MeanBackward0>)\n","tensor(23.6724, grad_fn=<MeanBackward0>)\n","tensor(228579.3750, grad_fn=<MeanBackward0>)\n","tensor(27.1569, grad_fn=<MeanBackward0>)\n","tensor(259696.4219, grad_fn=<MeanBackward0>)\n","[ 754/1000] train_loss: 18.68002 valid_loss: 10.40516\n","EarlyStopping counter: 3 out of 20\n","tensor(26.4178, grad_fn=<MeanBackward0>)\n","tensor(250410.4219, grad_fn=<MeanBackward0>)\n","tensor(27.8850, grad_fn=<MeanBackward0>)\n","tensor(255272.8281, grad_fn=<MeanBackward0>)\n","tensor(26.9521, grad_fn=<MeanBackward0>)\n","tensor(250633.4844, grad_fn=<MeanBackward0>)\n","[ 755/1000] train_loss: 19.13908 valid_loss: 10.40019\n","EarlyStopping counter: 4 out of 20\n","tensor(25.2474, grad_fn=<MeanBackward0>)\n","tensor(245938.2031, grad_fn=<MeanBackward0>)\n","tensor(26.2673, grad_fn=<MeanBackward0>)\n","tensor(249873.8750, grad_fn=<MeanBackward0>)\n","tensor(26.8603, grad_fn=<MeanBackward0>)\n","tensor(253455.6875, grad_fn=<MeanBackward0>)\n","[ 756/1000] train_loss: 18.93094 valid_loss: 10.39782\n","EarlyStopping counter: 5 out of 20\n","tensor(24.7130, grad_fn=<MeanBackward0>)\n","tensor(242528.8281, grad_fn=<MeanBackward0>)\n","tensor(29.1076, grad_fn=<MeanBackward0>)\n","tensor(264282.7500, grad_fn=<MeanBackward0>)\n","tensor(26.5358, grad_fn=<MeanBackward0>)\n","tensor(244651.9375, grad_fn=<MeanBackward0>)\n","[ 757/1000] train_loss: 18.73194 valid_loss: 10.40218\n","EarlyStopping counter: 6 out of 20\n","tensor(26.1394, grad_fn=<MeanBackward0>)\n","tensor(219111.7031, grad_fn=<MeanBackward0>)\n","tensor(29.7108, grad_fn=<MeanBackward0>)\n","tensor(246917.5000, grad_fn=<MeanBackward0>)\n","tensor(26.6017, grad_fn=<MeanBackward0>)\n","tensor(233366.1875, grad_fn=<MeanBackward0>)\n","[ 758/1000] train_loss: 18.76597 valid_loss: 10.38054\n","Validation loss decreased (10.384675 --> 10.380543).  Saving model ...\n","tensor(27.4970, grad_fn=<MeanBackward0>)\n","tensor(240149.7031, grad_fn=<MeanBackward0>)\n","tensor(26.1802, grad_fn=<MeanBackward0>)\n","tensor(248882.4844, grad_fn=<MeanBackward0>)\n","tensor(26.0275, grad_fn=<MeanBackward0>)\n","tensor(247457.9062, grad_fn=<MeanBackward0>)\n","[ 759/1000] train_loss: 18.52754 valid_loss: 10.36887\n","Validation loss decreased (10.380543 --> 10.368868).  Saving model ...\n","tensor(27.1191, grad_fn=<MeanBackward0>)\n","tensor(267214.3438, grad_fn=<MeanBackward0>)\n","tensor(25.2110, grad_fn=<MeanBackward0>)\n","tensor(241606.1094, grad_fn=<MeanBackward0>)\n","tensor(27.6742, grad_fn=<MeanBackward0>)\n","tensor(218906.2656, grad_fn=<MeanBackward0>)\n","[ 760/1000] train_loss: 18.58068 valid_loss: 10.38416\n","EarlyStopping counter: 1 out of 20\n","tensor(27.2542, grad_fn=<MeanBackward0>)\n","tensor(264996.6562, grad_fn=<MeanBackward0>)\n","tensor(28.3636, grad_fn=<MeanBackward0>)\n","tensor(227917.2969, grad_fn=<MeanBackward0>)\n","tensor(26.0542, grad_fn=<MeanBackward0>)\n","tensor(216989.8281, grad_fn=<MeanBackward0>)\n","[ 761/1000] train_loss: 18.88651 valid_loss: 10.34018\n","Validation loss decreased (10.368868 --> 10.340179).  Saving model ...\n","tensor(25.3588, grad_fn=<MeanBackward0>)\n","tensor(232522.1875, grad_fn=<MeanBackward0>)\n","tensor(27.0709, grad_fn=<MeanBackward0>)\n","tensor(257651.3281, grad_fn=<MeanBackward0>)\n","tensor(23.7967, grad_fn=<MeanBackward0>)\n","tensor(252169.2812, grad_fn=<MeanBackward0>)\n","[ 762/1000] train_loss: 18.57979 valid_loss: 10.35452\n","EarlyStopping counter: 1 out of 20\n","tensor(27.3888, grad_fn=<MeanBackward0>)\n","tensor(250029.6094, grad_fn=<MeanBackward0>)\n","tensor(26.9226, grad_fn=<MeanBackward0>)\n","tensor(251077.4219, grad_fn=<MeanBackward0>)\n","tensor(26.4876, grad_fn=<MeanBackward0>)\n","tensor(246252.3906, grad_fn=<MeanBackward0>)\n","[ 763/1000] train_loss: 18.88562 valid_loss: 10.37631\n","EarlyStopping counter: 2 out of 20\n","tensor(27.1621, grad_fn=<MeanBackward0>)\n","tensor(246021.5469, grad_fn=<MeanBackward0>)\n","tensor(23.7389, grad_fn=<MeanBackward0>)\n","tensor(228263.0625, grad_fn=<MeanBackward0>)\n","tensor(26.3211, grad_fn=<MeanBackward0>)\n","tensor(261820.6094, grad_fn=<MeanBackward0>)\n","[ 764/1000] train_loss: 19.00038 valid_loss: 10.39843\n","EarlyStopping counter: 3 out of 20\n","tensor(24.1845, grad_fn=<MeanBackward0>)\n","tensor(233807.9375, grad_fn=<MeanBackward0>)\n","tensor(25.0457, grad_fn=<MeanBackward0>)\n","tensor(227958.8906, grad_fn=<MeanBackward0>)\n","tensor(31.2383, grad_fn=<MeanBackward0>)\n","tensor(266772.9688, grad_fn=<MeanBackward0>)\n","[ 765/1000] train_loss: 18.60147 valid_loss: 10.37105\n","EarlyStopping counter: 4 out of 20\n","tensor(25.3283, grad_fn=<MeanBackward0>)\n","tensor(229148.3281, grad_fn=<MeanBackward0>)\n","tensor(23.6595, grad_fn=<MeanBackward0>)\n","tensor(266076.2500, grad_fn=<MeanBackward0>)\n","tensor(26.2527, grad_fn=<MeanBackward0>)\n","tensor(259767.1875, grad_fn=<MeanBackward0>)\n","[ 766/1000] train_loss: 18.63980 valid_loss: 10.35408\n","EarlyStopping counter: 5 out of 20\n","tensor(26.6122, grad_fn=<MeanBackward0>)\n","tensor(243130.1094, grad_fn=<MeanBackward0>)\n","tensor(26.4538, grad_fn=<MeanBackward0>)\n","tensor(244060.3281, grad_fn=<MeanBackward0>)\n","tensor(26.8808, grad_fn=<MeanBackward0>)\n","tensor(240696.8125, grad_fn=<MeanBackward0>)\n","[ 767/1000] train_loss: 18.66198 valid_loss: 10.39985\n","EarlyStopping counter: 6 out of 20\n","tensor(28.4850, grad_fn=<MeanBackward0>)\n","tensor(260240.4531, grad_fn=<MeanBackward0>)\n","tensor(26.0003, grad_fn=<MeanBackward0>)\n","tensor(231559.2500, grad_fn=<MeanBackward0>)\n","tensor(24.6394, grad_fn=<MeanBackward0>)\n","tensor(214543.1250, grad_fn=<MeanBackward0>)\n","[ 768/1000] train_loss: 18.77945 valid_loss: 10.39355\n","EarlyStopping counter: 7 out of 20\n","tensor(25.8867, grad_fn=<MeanBackward0>)\n","tensor(244014.7344, grad_fn=<MeanBackward0>)\n","tensor(27.6853, grad_fn=<MeanBackward0>)\n","tensor(245028.2500, grad_fn=<MeanBackward0>)\n","tensor(26.5176, grad_fn=<MeanBackward0>)\n","tensor(218045.5625, grad_fn=<MeanBackward0>)\n","[ 769/1000] train_loss: 18.76945 valid_loss: 10.36943\n","EarlyStopping counter: 8 out of 20\n","tensor(25.7017, grad_fn=<MeanBackward0>)\n","tensor(223177.2969, grad_fn=<MeanBackward0>)\n","tensor(27.0539, grad_fn=<MeanBackward0>)\n","tensor(256405.3125, grad_fn=<MeanBackward0>)\n","tensor(26.3211, grad_fn=<MeanBackward0>)\n","tensor(220662.6406, grad_fn=<MeanBackward0>)\n","[ 770/1000] train_loss: 18.55239 valid_loss: 10.37697\n","EarlyStopping counter: 9 out of 20\n","tensor(27.2936, grad_fn=<MeanBackward0>)\n","tensor(246984.2969, grad_fn=<MeanBackward0>)\n","tensor(24.3674, grad_fn=<MeanBackward0>)\n","tensor(231902.1094, grad_fn=<MeanBackward0>)\n","tensor(27.1190, grad_fn=<MeanBackward0>)\n","tensor(237214.6719, grad_fn=<MeanBackward0>)\n","[ 771/1000] train_loss: 18.78940 valid_loss: 10.35503\n","EarlyStopping counter: 10 out of 20\n","tensor(25.4636, grad_fn=<MeanBackward0>)\n","tensor(230407.4219, grad_fn=<MeanBackward0>)\n","tensor(24.6838, grad_fn=<MeanBackward0>)\n","tensor(250930.0156, grad_fn=<MeanBackward0>)\n","tensor(25.1215, grad_fn=<MeanBackward0>)\n","tensor(257686.4062, grad_fn=<MeanBackward0>)\n","[ 772/1000] train_loss: 18.67616 valid_loss: 10.32521\n","Validation loss decreased (10.340179 --> 10.325214).  Saving model ...\n","tensor(27.0998, grad_fn=<MeanBackward0>)\n","tensor(260158.2656, grad_fn=<MeanBackward0>)\n","tensor(23.6231, grad_fn=<MeanBackward0>)\n","tensor(242132.1719, grad_fn=<MeanBackward0>)\n","tensor(25.8150, grad_fn=<MeanBackward0>)\n","tensor(235010.7500, grad_fn=<MeanBackward0>)\n","[ 773/1000] train_loss: 18.47290 valid_loss: 10.35671\n","EarlyStopping counter: 1 out of 20\n","tensor(26.4626, grad_fn=<MeanBackward0>)\n","tensor(228985.0781, grad_fn=<MeanBackward0>)\n","tensor(25.3121, grad_fn=<MeanBackward0>)\n","tensor(235606.5156, grad_fn=<MeanBackward0>)\n","tensor(25.4593, grad_fn=<MeanBackward0>)\n","tensor(238517.2500, grad_fn=<MeanBackward0>)\n","[ 774/1000] train_loss: 18.37372 valid_loss: 10.37638\n","EarlyStopping counter: 2 out of 20\n","tensor(26.1272, grad_fn=<MeanBackward0>)\n","tensor(242376.9531, grad_fn=<MeanBackward0>)\n","tensor(28.1566, grad_fn=<MeanBackward0>)\n","tensor(227724.1875, grad_fn=<MeanBackward0>)\n","tensor(25.2438, grad_fn=<MeanBackward0>)\n","tensor(240342.5938, grad_fn=<MeanBackward0>)\n","[ 775/1000] train_loss: 18.30925 valid_loss: 10.37057\n","EarlyStopping counter: 3 out of 20\n","tensor(25.2000, grad_fn=<MeanBackward0>)\n","tensor(227011.3281, grad_fn=<MeanBackward0>)\n","tensor(26.1327, grad_fn=<MeanBackward0>)\n","tensor(244216.2500, grad_fn=<MeanBackward0>)\n","tensor(25.8792, grad_fn=<MeanBackward0>)\n","tensor(248367.5000, grad_fn=<MeanBackward0>)\n","[ 776/1000] train_loss: 18.56862 valid_loss: 10.44373\n","EarlyStopping counter: 4 out of 20\n","tensor(27.9349, grad_fn=<MeanBackward0>)\n","tensor(243684.1406, grad_fn=<MeanBackward0>)\n","tensor(26.5655, grad_fn=<MeanBackward0>)\n","tensor(239053.7500, grad_fn=<MeanBackward0>)\n","tensor(24.5129, grad_fn=<MeanBackward0>)\n","tensor(231930.3281, grad_fn=<MeanBackward0>)\n","[ 777/1000] train_loss: 18.76038 valid_loss: 10.36001\n","EarlyStopping counter: 5 out of 20\n","tensor(26.3125, grad_fn=<MeanBackward0>)\n","tensor(233270.5625, grad_fn=<MeanBackward0>)\n","tensor(27.2945, grad_fn=<MeanBackward0>)\n","tensor(233134.6719, grad_fn=<MeanBackward0>)\n","tensor(24.2689, grad_fn=<MeanBackward0>)\n","tensor(237648.2188, grad_fn=<MeanBackward0>)\n","[ 778/1000] train_loss: 18.38811 valid_loss: 10.34913\n","EarlyStopping counter: 6 out of 20\n","tensor(23.6508, grad_fn=<MeanBackward0>)\n","tensor(228422.0781, grad_fn=<MeanBackward0>)\n","tensor(25.1914, grad_fn=<MeanBackward0>)\n","tensor(235059.7969, grad_fn=<MeanBackward0>)\n","tensor(28.4559, grad_fn=<MeanBackward0>)\n","tensor(243944.4062, grad_fn=<MeanBackward0>)\n","[ 779/1000] train_loss: 18.40789 valid_loss: 10.34102\n","EarlyStopping counter: 7 out of 20\n","tensor(27.3389, grad_fn=<MeanBackward0>)\n","tensor(229928.1719, grad_fn=<MeanBackward0>)\n","tensor(24.3214, grad_fn=<MeanBackward0>)\n","tensor(222647.2656, grad_fn=<MeanBackward0>)\n","tensor(24.7230, grad_fn=<MeanBackward0>)\n","tensor(231433.6562, grad_fn=<MeanBackward0>)\n","[ 780/1000] train_loss: 18.37088 valid_loss: 10.29017\n","Validation loss decreased (10.325214 --> 10.290174).  Saving model ...\n","tensor(25.0877, grad_fn=<MeanBackward0>)\n","tensor(218306.6250, grad_fn=<MeanBackward0>)\n","tensor(25.8128, grad_fn=<MeanBackward0>)\n","tensor(227391.6094, grad_fn=<MeanBackward0>)\n","tensor(25.8171, grad_fn=<MeanBackward0>)\n","tensor(229186.0781, grad_fn=<MeanBackward0>)\n","[ 781/1000] train_loss: 18.50403 valid_loss: 10.28941\n","Validation loss decreased (10.290174 --> 10.289408).  Saving model ...\n","tensor(28.2254, grad_fn=<MeanBackward0>)\n","tensor(256639.2344, grad_fn=<MeanBackward0>)\n","tensor(24.2837, grad_fn=<MeanBackward0>)\n","tensor(228656.7656, grad_fn=<MeanBackward0>)\n","tensor(24.3158, grad_fn=<MeanBackward0>)\n","tensor(242781.9844, grad_fn=<MeanBackward0>)\n","[ 782/1000] train_loss: 18.47705 valid_loss: 10.28348\n","Validation loss decreased (10.289408 --> 10.283477).  Saving model ...\n","tensor(23.3963, grad_fn=<MeanBackward0>)\n","tensor(211273.2344, grad_fn=<MeanBackward0>)\n","tensor(23.1992, grad_fn=<MeanBackward0>)\n","tensor(239302.9219, grad_fn=<MeanBackward0>)\n","tensor(27.8484, grad_fn=<MeanBackward0>)\n","tensor(245970.5312, grad_fn=<MeanBackward0>)\n","[ 783/1000] train_loss: 18.30448 valid_loss: 10.26842\n","Validation loss decreased (10.283477 --> 10.268421).  Saving model ...\n","tensor(26.9314, grad_fn=<MeanBackward0>)\n","tensor(234176.6719, grad_fn=<MeanBackward0>)\n","tensor(24.0255, grad_fn=<MeanBackward0>)\n","tensor(222236.1406, grad_fn=<MeanBackward0>)\n","tensor(26.6219, grad_fn=<MeanBackward0>)\n","tensor(239142.2344, grad_fn=<MeanBackward0>)\n","[ 784/1000] train_loss: 18.64757 valid_loss: 10.28250\n","EarlyStopping counter: 1 out of 20\n","tensor(25.7149, grad_fn=<MeanBackward0>)\n","tensor(233794.6719, grad_fn=<MeanBackward0>)\n","tensor(24.9023, grad_fn=<MeanBackward0>)\n","tensor(234902.6719, grad_fn=<MeanBackward0>)\n","tensor(23.4557, grad_fn=<MeanBackward0>)\n","tensor(231569.7500, grad_fn=<MeanBackward0>)\n","[ 785/1000] train_loss: 18.40622 valid_loss: 10.30217\n","EarlyStopping counter: 2 out of 20\n","tensor(23.8959, grad_fn=<MeanBackward0>)\n","tensor(240611.3594, grad_fn=<MeanBackward0>)\n","tensor(27.2402, grad_fn=<MeanBackward0>)\n","tensor(231239.0469, grad_fn=<MeanBackward0>)\n","tensor(25.5082, grad_fn=<MeanBackward0>)\n","tensor(228095.5469, grad_fn=<MeanBackward0>)\n","[ 786/1000] train_loss: 18.58656 valid_loss: 10.33502\n","EarlyStopping counter: 3 out of 20\n","tensor(26.2468, grad_fn=<MeanBackward0>)\n","tensor(238188.7500, grad_fn=<MeanBackward0>)\n","tensor(26.3162, grad_fn=<MeanBackward0>)\n","tensor(225381.3594, grad_fn=<MeanBackward0>)\n","tensor(27.3122, grad_fn=<MeanBackward0>)\n","tensor(224655.9844, grad_fn=<MeanBackward0>)\n","[ 787/1000] train_loss: 18.40163 valid_loss: 10.33782\n","EarlyStopping counter: 4 out of 20\n","tensor(26.5468, grad_fn=<MeanBackward0>)\n","tensor(222787.0156, grad_fn=<MeanBackward0>)\n","tensor(26.4628, grad_fn=<MeanBackward0>)\n","tensor(224796.3750, grad_fn=<MeanBackward0>)\n","tensor(23.6758, grad_fn=<MeanBackward0>)\n","tensor(234254.9219, grad_fn=<MeanBackward0>)\n","[ 788/1000] train_loss: 18.24063 valid_loss: 10.26444\n","Validation loss decreased (10.268421 --> 10.264442).  Saving model ...\n","tensor(24.7590, grad_fn=<MeanBackward0>)\n","tensor(220122.3750, grad_fn=<MeanBackward0>)\n","tensor(24.0296, grad_fn=<MeanBackward0>)\n","tensor(231592.7500, grad_fn=<MeanBackward0>)\n","tensor(25.4299, grad_fn=<MeanBackward0>)\n","tensor(234017.6094, grad_fn=<MeanBackward0>)\n","[ 789/1000] train_loss: 18.39032 valid_loss: 10.27245\n","EarlyStopping counter: 1 out of 20\n","tensor(24.4556, grad_fn=<MeanBackward0>)\n","tensor(243250.0625, grad_fn=<MeanBackward0>)\n","tensor(25.5321, grad_fn=<MeanBackward0>)\n","tensor(237545.4375, grad_fn=<MeanBackward0>)\n","tensor(26.0864, grad_fn=<MeanBackward0>)\n","tensor(247964.5938, grad_fn=<MeanBackward0>)\n","[ 790/1000] train_loss: 18.45863 valid_loss: 10.29125\n","EarlyStopping counter: 2 out of 20\n","tensor(25.7043, grad_fn=<MeanBackward0>)\n","tensor(234470.6719, grad_fn=<MeanBackward0>)\n","tensor(24.5474, grad_fn=<MeanBackward0>)\n","tensor(236034.7031, grad_fn=<MeanBackward0>)\n","tensor(27.0946, grad_fn=<MeanBackward0>)\n","tensor(222317., grad_fn=<MeanBackward0>)\n","[ 791/1000] train_loss: 18.32860 valid_loss: 10.27206\n","EarlyStopping counter: 3 out of 20\n","tensor(23.8487, grad_fn=<MeanBackward0>)\n","tensor(239810.8750, grad_fn=<MeanBackward0>)\n","tensor(24.6911, grad_fn=<MeanBackward0>)\n","tensor(230360.2500, grad_fn=<MeanBackward0>)\n","tensor(27.0251, grad_fn=<MeanBackward0>)\n","tensor(231938.2344, grad_fn=<MeanBackward0>)\n","[ 792/1000] train_loss: 18.56872 valid_loss: 10.27515\n","EarlyStopping counter: 4 out of 20\n","tensor(26.7782, grad_fn=<MeanBackward0>)\n","tensor(216269.1719, grad_fn=<MeanBackward0>)\n","tensor(24.7088, grad_fn=<MeanBackward0>)\n","tensor(243738.1094, grad_fn=<MeanBackward0>)\n","tensor(27.0189, grad_fn=<MeanBackward0>)\n","tensor(233718.8594, grad_fn=<MeanBackward0>)\n","[ 793/1000] train_loss: 18.46017 valid_loss: 10.29476\n","EarlyStopping counter: 5 out of 20\n","tensor(26.0450, grad_fn=<MeanBackward0>)\n","tensor(235520.4219, grad_fn=<MeanBackward0>)\n","tensor(25.4371, grad_fn=<MeanBackward0>)\n","tensor(252095.5000, grad_fn=<MeanBackward0>)\n","tensor(23.0106, grad_fn=<MeanBackward0>)\n","tensor(213670.1406, grad_fn=<MeanBackward0>)\n","[ 794/1000] train_loss: 18.34263 valid_loss: 10.24039\n","Validation loss decreased (10.264442 --> 10.240392).  Saving model ...\n","tensor(23.5190, grad_fn=<MeanBackward0>)\n","tensor(235447.9219, grad_fn=<MeanBackward0>)\n","tensor(24.3442, grad_fn=<MeanBackward0>)\n","tensor(230402.0469, grad_fn=<MeanBackward0>)\n","tensor(27.7529, grad_fn=<MeanBackward0>)\n","tensor(228362.9375, grad_fn=<MeanBackward0>)\n","[ 795/1000] train_loss: 18.39735 valid_loss: 10.26142\n","EarlyStopping counter: 1 out of 20\n","tensor(24.7122, grad_fn=<MeanBackward0>)\n","tensor(230947.7969, grad_fn=<MeanBackward0>)\n","tensor(27.6065, grad_fn=<MeanBackward0>)\n","tensor(232661.5000, grad_fn=<MeanBackward0>)\n","tensor(26.1524, grad_fn=<MeanBackward0>)\n","tensor(235390.8281, grad_fn=<MeanBackward0>)\n","[ 796/1000] train_loss: 18.50813 valid_loss: 10.26385\n","EarlyStopping counter: 2 out of 20\n","tensor(24.9080, grad_fn=<MeanBackward0>)\n","tensor(232763.7656, grad_fn=<MeanBackward0>)\n","tensor(27.3454, grad_fn=<MeanBackward0>)\n","tensor(230332.8594, grad_fn=<MeanBackward0>)\n","tensor(24.7481, grad_fn=<MeanBackward0>)\n","tensor(213942.6719, grad_fn=<MeanBackward0>)\n","[ 797/1000] train_loss: 18.29826 valid_loss: 10.24144\n","EarlyStopping counter: 3 out of 20\n","tensor(28.6377, grad_fn=<MeanBackward0>)\n","tensor(209457., grad_fn=<MeanBackward0>)\n","tensor(23.9940, grad_fn=<MeanBackward0>)\n","tensor(236032.9219, grad_fn=<MeanBackward0>)\n","tensor(23.5791, grad_fn=<MeanBackward0>)\n","tensor(228108.1406, grad_fn=<MeanBackward0>)\n","[ 798/1000] train_loss: 18.25001 valid_loss: 10.26564\n","EarlyStopping counter: 4 out of 20\n","tensor(25.9369, grad_fn=<MeanBackward0>)\n","tensor(229999.7031, grad_fn=<MeanBackward0>)\n","tensor(24.7237, grad_fn=<MeanBackward0>)\n","tensor(221857.4375, grad_fn=<MeanBackward0>)\n","tensor(25.7629, grad_fn=<MeanBackward0>)\n","tensor(223611.6250, grad_fn=<MeanBackward0>)\n","[ 799/1000] train_loss: 18.29361 valid_loss: 10.23759\n","Validation loss decreased (10.240392 --> 10.237594).  Saving model ...\n","tensor(24.0917, grad_fn=<MeanBackward0>)\n","tensor(230155.0625, grad_fn=<MeanBackward0>)\n","tensor(25.5404, grad_fn=<MeanBackward0>)\n","tensor(220175.8281, grad_fn=<MeanBackward0>)\n","tensor(23.8183, grad_fn=<MeanBackward0>)\n","tensor(234222.8750, grad_fn=<MeanBackward0>)\n","[ 800/1000] train_loss: 18.41972 valid_loss: 10.27649\n","EarlyStopping counter: 1 out of 20\n","tensor(27.2202, grad_fn=<MeanBackward0>)\n","tensor(221829.9375, grad_fn=<MeanBackward0>)\n","tensor(23.5156, grad_fn=<MeanBackward0>)\n","tensor(217392.6250, grad_fn=<MeanBackward0>)\n","tensor(24.2742, grad_fn=<MeanBackward0>)\n","tensor(232487.9531, grad_fn=<MeanBackward0>)\n","[ 801/1000] train_loss: 18.30491 valid_loss: 10.25973\n","EarlyStopping counter: 2 out of 20\n","tensor(24.4696, grad_fn=<MeanBackward0>)\n","tensor(256582.9375, grad_fn=<MeanBackward0>)\n","tensor(23.1513, grad_fn=<MeanBackward0>)\n","tensor(200025.3906, grad_fn=<MeanBackward0>)\n","tensor(26.0680, grad_fn=<MeanBackward0>)\n","tensor(238940.0156, grad_fn=<MeanBackward0>)\n","[ 802/1000] train_loss: 18.18302 valid_loss: 10.25476\n","EarlyStopping counter: 3 out of 20\n","tensor(24.9250, grad_fn=<MeanBackward0>)\n","tensor(222318.3750, grad_fn=<MeanBackward0>)\n","tensor(24.5285, grad_fn=<MeanBackward0>)\n","tensor(229621.4375, grad_fn=<MeanBackward0>)\n","tensor(25.5918, grad_fn=<MeanBackward0>)\n","tensor(210582.8594, grad_fn=<MeanBackward0>)\n","[ 803/1000] train_loss: 18.28969 valid_loss: 10.26389\n","EarlyStopping counter: 4 out of 20\n","tensor(25.9820, grad_fn=<MeanBackward0>)\n","tensor(215685.1875, grad_fn=<MeanBackward0>)\n","tensor(26.6881, grad_fn=<MeanBackward0>)\n","tensor(221641.9531, grad_fn=<MeanBackward0>)\n","tensor(26.0796, grad_fn=<MeanBackward0>)\n","tensor(215904.9844, grad_fn=<MeanBackward0>)\n","[ 804/1000] train_loss: 18.26118 valid_loss: 10.29149\n","EarlyStopping counter: 5 out of 20\n","tensor(25.0826, grad_fn=<MeanBackward0>)\n","tensor(237820.9375, grad_fn=<MeanBackward0>)\n","tensor(23.9236, grad_fn=<MeanBackward0>)\n","tensor(220263.9531, grad_fn=<MeanBackward0>)\n","tensor(23.8490, grad_fn=<MeanBackward0>)\n","tensor(220750.7969, grad_fn=<MeanBackward0>)\n","[ 805/1000] train_loss: 18.18465 valid_loss: 10.24271\n","EarlyStopping counter: 6 out of 20\n","tensor(23.1815, grad_fn=<MeanBackward0>)\n","tensor(209398.9375, grad_fn=<MeanBackward0>)\n","tensor(23.3676, grad_fn=<MeanBackward0>)\n","tensor(226045.9531, grad_fn=<MeanBackward0>)\n","tensor(24.0351, grad_fn=<MeanBackward0>)\n","tensor(234596.8906, grad_fn=<MeanBackward0>)\n","[ 806/1000] train_loss: 18.26616 valid_loss: 10.27107\n","EarlyStopping counter: 7 out of 20\n","tensor(25.3402, grad_fn=<MeanBackward0>)\n","tensor(244240.2656, grad_fn=<MeanBackward0>)\n","tensor(25.2829, grad_fn=<MeanBackward0>)\n","tensor(230381.5000, grad_fn=<MeanBackward0>)\n","tensor(28.4406, grad_fn=<MeanBackward0>)\n","tensor(222904.0156, grad_fn=<MeanBackward0>)\n","[ 807/1000] train_loss: 18.25403 valid_loss: 10.23171\n","Validation loss decreased (10.237594 --> 10.231713).  Saving model ...\n","tensor(25.7246, grad_fn=<MeanBackward0>)\n","tensor(203340.6875, grad_fn=<MeanBackward0>)\n","tensor(24.5154, grad_fn=<MeanBackward0>)\n","tensor(211931.8906, grad_fn=<MeanBackward0>)\n","tensor(23.7236, grad_fn=<MeanBackward0>)\n","tensor(216562.1094, grad_fn=<MeanBackward0>)\n","[ 808/1000] train_loss: 18.13362 valid_loss: 10.19558\n","Validation loss decreased (10.231713 --> 10.195577).  Saving model ...\n","tensor(24.9047, grad_fn=<MeanBackward0>)\n","tensor(229783.6094, grad_fn=<MeanBackward0>)\n","tensor(24.2634, grad_fn=<MeanBackward0>)\n","tensor(201026.5000, grad_fn=<MeanBackward0>)\n","tensor(24.1821, grad_fn=<MeanBackward0>)\n","tensor(232879.9062, grad_fn=<MeanBackward0>)\n","[ 809/1000] train_loss: 18.31734 valid_loss: 10.20046\n","EarlyStopping counter: 1 out of 20\n","tensor(21.9132, grad_fn=<MeanBackward0>)\n","tensor(236180.1719, grad_fn=<MeanBackward0>)\n","tensor(24.3865, grad_fn=<MeanBackward0>)\n","tensor(218669.2500, grad_fn=<MeanBackward0>)\n","tensor(25.5085, grad_fn=<MeanBackward0>)\n","tensor(228981.3594, grad_fn=<MeanBackward0>)\n","[ 810/1000] train_loss: 18.04638 valid_loss: 10.18786\n","Validation loss decreased (10.195577 --> 10.187858).  Saving model ...\n","tensor(25.6664, grad_fn=<MeanBackward0>)\n","tensor(231229.3281, grad_fn=<MeanBackward0>)\n","tensor(22.0056, grad_fn=<MeanBackward0>)\n","tensor(224369.2969, grad_fn=<MeanBackward0>)\n","tensor(22.6781, grad_fn=<MeanBackward0>)\n","tensor(216734., grad_fn=<MeanBackward0>)\n","[ 811/1000] train_loss: 18.20444 valid_loss: 10.17149\n","Validation loss decreased (10.187858 --> 10.171489).  Saving model ...\n","tensor(26.7040, grad_fn=<MeanBackward0>)\n","tensor(231806.6875, grad_fn=<MeanBackward0>)\n","tensor(22.5682, grad_fn=<MeanBackward0>)\n","tensor(208207.2969, grad_fn=<MeanBackward0>)\n","tensor(25.3261, grad_fn=<MeanBackward0>)\n","tensor(220829.8438, grad_fn=<MeanBackward0>)\n","[ 812/1000] train_loss: 17.95699 valid_loss: 10.19654\n","EarlyStopping counter: 1 out of 20\n","tensor(26.3555, grad_fn=<MeanBackward0>)\n","tensor(220356.9219, grad_fn=<MeanBackward0>)\n","tensor(24.0218, grad_fn=<MeanBackward0>)\n","tensor(213976.6094, grad_fn=<MeanBackward0>)\n","tensor(23.8643, grad_fn=<MeanBackward0>)\n","tensor(221129.5625, grad_fn=<MeanBackward0>)\n","[ 813/1000] train_loss: 17.99421 valid_loss: 10.15928\n","Validation loss decreased (10.171489 --> 10.159284).  Saving model ...\n","tensor(27.6150, grad_fn=<MeanBackward0>)\n","tensor(237930.2656, grad_fn=<MeanBackward0>)\n","tensor(23.3915, grad_fn=<MeanBackward0>)\n","tensor(196300.8281, grad_fn=<MeanBackward0>)\n","tensor(26.4682, grad_fn=<MeanBackward0>)\n","tensor(213844.6562, grad_fn=<MeanBackward0>)\n","[ 814/1000] train_loss: 18.08122 valid_loss: 10.17140\n","EarlyStopping counter: 1 out of 20\n","tensor(24.6344, grad_fn=<MeanBackward0>)\n","tensor(202937.6250, grad_fn=<MeanBackward0>)\n","tensor(25.8628, grad_fn=<MeanBackward0>)\n","tensor(251606.5000, grad_fn=<MeanBackward0>)\n","tensor(26.9701, grad_fn=<MeanBackward0>)\n","tensor(226148.1406, grad_fn=<MeanBackward0>)\n","[ 815/1000] train_loss: 18.30085 valid_loss: 10.17973\n","EarlyStopping counter: 2 out of 20\n","tensor(25.8568, grad_fn=<MeanBackward0>)\n","tensor(215187.8125, grad_fn=<MeanBackward0>)\n","tensor(22.5881, grad_fn=<MeanBackward0>)\n","tensor(221665.9844, grad_fn=<MeanBackward0>)\n","tensor(24.5576, grad_fn=<MeanBackward0>)\n","tensor(218977.4844, grad_fn=<MeanBackward0>)\n","[ 816/1000] train_loss: 18.35598 valid_loss: 10.18825\n","EarlyStopping counter: 3 out of 20\n","tensor(24.0807, grad_fn=<MeanBackward0>)\n","tensor(211440.9375, grad_fn=<MeanBackward0>)\n","tensor(26.5572, grad_fn=<MeanBackward0>)\n","tensor(240787.3750, grad_fn=<MeanBackward0>)\n","tensor(23.0274, grad_fn=<MeanBackward0>)\n","tensor(204369.1875, grad_fn=<MeanBackward0>)\n","[ 817/1000] train_loss: 18.01491 valid_loss: 10.20019\n","EarlyStopping counter: 4 out of 20\n","tensor(24.2025, grad_fn=<MeanBackward0>)\n","tensor(225111.8281, grad_fn=<MeanBackward0>)\n","tensor(23.5656, grad_fn=<MeanBackward0>)\n","tensor(208729.8906, grad_fn=<MeanBackward0>)\n","tensor(23.6523, grad_fn=<MeanBackward0>)\n","tensor(227937.6875, grad_fn=<MeanBackward0>)\n","[ 818/1000] train_loss: 18.04859 valid_loss: 10.15853\n","Validation loss decreased (10.159284 --> 10.158530).  Saving model ...\n","tensor(24.1326, grad_fn=<MeanBackward0>)\n","tensor(233949.4531, grad_fn=<MeanBackward0>)\n","tensor(23.8500, grad_fn=<MeanBackward0>)\n","tensor(211370.8750, grad_fn=<MeanBackward0>)\n","tensor(23.8754, grad_fn=<MeanBackward0>)\n","tensor(218747.4688, grad_fn=<MeanBackward0>)\n","[ 819/1000] train_loss: 17.98422 valid_loss: 10.18482\n","EarlyStopping counter: 1 out of 20\n","tensor(24.1910, grad_fn=<MeanBackward0>)\n","tensor(208785.9375, grad_fn=<MeanBackward0>)\n","tensor(25.6741, grad_fn=<MeanBackward0>)\n","tensor(206690.4219, grad_fn=<MeanBackward0>)\n","tensor(24.4683, grad_fn=<MeanBackward0>)\n","tensor(243132.1250, grad_fn=<MeanBackward0>)\n","[ 820/1000] train_loss: 17.92619 valid_loss: 10.13789\n","Validation loss decreased (10.158530 --> 10.137893).  Saving model ...\n","tensor(25.2239, grad_fn=<MeanBackward0>)\n","tensor(227685., grad_fn=<MeanBackward0>)\n","tensor(25.2129, grad_fn=<MeanBackward0>)\n","tensor(200598.9375, grad_fn=<MeanBackward0>)\n","tensor(24.9374, grad_fn=<MeanBackward0>)\n","tensor(214365., grad_fn=<MeanBackward0>)\n","[ 821/1000] train_loss: 18.17380 valid_loss: 10.13123\n","Validation loss decreased (10.137893 --> 10.131232).  Saving model ...\n","tensor(25.6703, grad_fn=<MeanBackward0>)\n","tensor(220700.1875, grad_fn=<MeanBackward0>)\n","tensor(24.1268, grad_fn=<MeanBackward0>)\n","tensor(212832., grad_fn=<MeanBackward0>)\n","tensor(26.0277, grad_fn=<MeanBackward0>)\n","tensor(214385.1875, grad_fn=<MeanBackward0>)\n","[ 822/1000] train_loss: 17.97111 valid_loss: 10.19929\n","EarlyStopping counter: 1 out of 20\n","tensor(25.8627, grad_fn=<MeanBackward0>)\n","tensor(213428.5469, grad_fn=<MeanBackward0>)\n","tensor(25.2814, grad_fn=<MeanBackward0>)\n","tensor(226076.9219, grad_fn=<MeanBackward0>)\n","tensor(24.3759, grad_fn=<MeanBackward0>)\n","tensor(225740.1250, grad_fn=<MeanBackward0>)\n","[ 823/1000] train_loss: 18.06677 valid_loss: 10.17978\n","EarlyStopping counter: 2 out of 20\n","tensor(21.7666, grad_fn=<MeanBackward0>)\n","tensor(221726.1719, grad_fn=<MeanBackward0>)\n","tensor(22.1933, grad_fn=<MeanBackward0>)\n","tensor(227300.3594, grad_fn=<MeanBackward0>)\n","tensor(24.7969, grad_fn=<MeanBackward0>)\n","tensor(206286.4375, grad_fn=<MeanBackward0>)\n","[ 824/1000] train_loss: 17.98760 valid_loss: 10.15576\n","EarlyStopping counter: 3 out of 20\n","tensor(24.4553, grad_fn=<MeanBackward0>)\n","tensor(218426.1094, grad_fn=<MeanBackward0>)\n","tensor(23.1517, grad_fn=<MeanBackward0>)\n","tensor(229144.0156, grad_fn=<MeanBackward0>)\n","tensor(24.1773, grad_fn=<MeanBackward0>)\n","tensor(205844.4844, grad_fn=<MeanBackward0>)\n","[ 825/1000] train_loss: 18.09780 valid_loss: 10.23036\n","EarlyStopping counter: 4 out of 20\n","tensor(26.7775, grad_fn=<MeanBackward0>)\n","tensor(224620.9219, grad_fn=<MeanBackward0>)\n","tensor(24.3232, grad_fn=<MeanBackward0>)\n","tensor(219430.7500, grad_fn=<MeanBackward0>)\n","tensor(22.7630, grad_fn=<MeanBackward0>)\n","tensor(205918.5469, grad_fn=<MeanBackward0>)\n","[ 826/1000] train_loss: 17.93771 valid_loss: 10.15322\n","EarlyStopping counter: 5 out of 20\n","tensor(25.8723, grad_fn=<MeanBackward0>)\n","tensor(228350.8906, grad_fn=<MeanBackward0>)\n","tensor(22.5570, grad_fn=<MeanBackward0>)\n","tensor(211809.5781, grad_fn=<MeanBackward0>)\n","tensor(22.8401, grad_fn=<MeanBackward0>)\n","tensor(219012.2969, grad_fn=<MeanBackward0>)\n","[ 827/1000] train_loss: 18.28859 valid_loss: 10.17246\n","EarlyStopping counter: 6 out of 20\n","tensor(23.2317, grad_fn=<MeanBackward0>)\n","tensor(221472.3125, grad_fn=<MeanBackward0>)\n","tensor(25.1296, grad_fn=<MeanBackward0>)\n","tensor(217656., grad_fn=<MeanBackward0>)\n","tensor(24.9478, grad_fn=<MeanBackward0>)\n","tensor(224874.0781, grad_fn=<MeanBackward0>)\n","[ 828/1000] train_loss: 18.00639 valid_loss: 10.17139\n","EarlyStopping counter: 7 out of 20\n","tensor(25.6897, grad_fn=<MeanBackward0>)\n","tensor(227352.2344, grad_fn=<MeanBackward0>)\n","tensor(24.4080, grad_fn=<MeanBackward0>)\n","tensor(217211.1719, grad_fn=<MeanBackward0>)\n","tensor(22.9920, grad_fn=<MeanBackward0>)\n","tensor(212811.9375, grad_fn=<MeanBackward0>)\n","[ 829/1000] train_loss: 18.04932 valid_loss: 10.12120\n","Validation loss decreased (10.131232 --> 10.121202).  Saving model ...\n","tensor(25.6587, grad_fn=<MeanBackward0>)\n","tensor(221526.5000, grad_fn=<MeanBackward0>)\n","tensor(22.5998, grad_fn=<MeanBackward0>)\n","tensor(222210.5625, grad_fn=<MeanBackward0>)\n","tensor(23.0319, grad_fn=<MeanBackward0>)\n","tensor(206090.5469, grad_fn=<MeanBackward0>)\n","[ 830/1000] train_loss: 18.02100 valid_loss: 10.10697\n","Validation loss decreased (10.121202 --> 10.106974).  Saving model ...\n","tensor(24.6878, grad_fn=<MeanBackward0>)\n","tensor(208500.2031, grad_fn=<MeanBackward0>)\n","tensor(25.1959, grad_fn=<MeanBackward0>)\n","tensor(217651.4219, grad_fn=<MeanBackward0>)\n","tensor(23.1482, grad_fn=<MeanBackward0>)\n","tensor(216848.7344, grad_fn=<MeanBackward0>)\n","[ 831/1000] train_loss: 17.98972 valid_loss: 10.11414\n","EarlyStopping counter: 1 out of 20\n","tensor(23.1886, grad_fn=<MeanBackward0>)\n","tensor(214090.3750, grad_fn=<MeanBackward0>)\n","tensor(24.6599, grad_fn=<MeanBackward0>)\n","tensor(220738.4375, grad_fn=<MeanBackward0>)\n","tensor(23.3291, grad_fn=<MeanBackward0>)\n","tensor(215856.6250, grad_fn=<MeanBackward0>)\n","[ 832/1000] train_loss: 17.76353 valid_loss: 10.07937\n","Validation loss decreased (10.106974 --> 10.079370).  Saving model ...\n","tensor(23.3991, grad_fn=<MeanBackward0>)\n","tensor(218144.5000, grad_fn=<MeanBackward0>)\n","tensor(21.7320, grad_fn=<MeanBackward0>)\n","tensor(214980.2969, grad_fn=<MeanBackward0>)\n","tensor(23.8122, grad_fn=<MeanBackward0>)\n","tensor(209698.8906, grad_fn=<MeanBackward0>)\n","[ 833/1000] train_loss: 18.03904 valid_loss: 10.11512\n","EarlyStopping counter: 1 out of 20\n","tensor(25.9194, grad_fn=<MeanBackward0>)\n","tensor(216927.9219, grad_fn=<MeanBackward0>)\n","tensor(25.1484, grad_fn=<MeanBackward0>)\n","tensor(217676.0469, grad_fn=<MeanBackward0>)\n","tensor(22.2726, grad_fn=<MeanBackward0>)\n","tensor(212359.1719, grad_fn=<MeanBackward0>)\n","[ 834/1000] train_loss: 17.72858 valid_loss: 10.10283\n","EarlyStopping counter: 2 out of 20\n","tensor(25.1350, grad_fn=<MeanBackward0>)\n","tensor(222568.1094, grad_fn=<MeanBackward0>)\n","tensor(24.3976, grad_fn=<MeanBackward0>)\n","tensor(206457.2969, grad_fn=<MeanBackward0>)\n","tensor(24.9215, grad_fn=<MeanBackward0>)\n","tensor(208388.9062, grad_fn=<MeanBackward0>)\n","[ 835/1000] train_loss: 17.98613 valid_loss: 10.07347\n","Validation loss decreased (10.079370 --> 10.073466).  Saving model ...\n","tensor(20.8213, grad_fn=<MeanBackward0>)\n","tensor(213114.1406, grad_fn=<MeanBackward0>)\n","tensor(25.2618, grad_fn=<MeanBackward0>)\n","tensor(222085.2656, grad_fn=<MeanBackward0>)\n","tensor(22.6808, grad_fn=<MeanBackward0>)\n","tensor(208612.2188, grad_fn=<MeanBackward0>)\n","[ 836/1000] train_loss: 17.84510 valid_loss: 10.09564\n","EarlyStopping counter: 1 out of 20\n","tensor(24.0188, grad_fn=<MeanBackward0>)\n","tensor(226917.7031, grad_fn=<MeanBackward0>)\n","tensor(23.5840, grad_fn=<MeanBackward0>)\n","tensor(218305.4375, grad_fn=<MeanBackward0>)\n","tensor(22.0324, grad_fn=<MeanBackward0>)\n","tensor(205872.3438, grad_fn=<MeanBackward0>)\n","[ 837/1000] train_loss: 17.87393 valid_loss: 10.06857\n","Validation loss decreased (10.073466 --> 10.068567).  Saving model ...\n","tensor(21.6322, grad_fn=<MeanBackward0>)\n","tensor(196634.6094, grad_fn=<MeanBackward0>)\n","tensor(22.9408, grad_fn=<MeanBackward0>)\n","tensor(199306.8281, grad_fn=<MeanBackward0>)\n","tensor(24.8188, grad_fn=<MeanBackward0>)\n","tensor(231050.2812, grad_fn=<MeanBackward0>)\n","[ 838/1000] train_loss: 17.72789 valid_loss: 10.07467\n","EarlyStopping counter: 1 out of 20\n","tensor(22.6451, grad_fn=<MeanBackward0>)\n","tensor(201705.0781, grad_fn=<MeanBackward0>)\n","tensor(26.5627, grad_fn=<MeanBackward0>)\n","tensor(212248.6250, grad_fn=<MeanBackward0>)\n","tensor(22.8187, grad_fn=<MeanBackward0>)\n","tensor(216378.4375, grad_fn=<MeanBackward0>)\n","[ 839/1000] train_loss: 18.03729 valid_loss: 10.05685\n","Validation loss decreased (10.068567 --> 10.056846).  Saving model ...\n","tensor(23.8292, grad_fn=<MeanBackward0>)\n","tensor(193894.9219, grad_fn=<MeanBackward0>)\n","tensor(25.5510, grad_fn=<MeanBackward0>)\n","tensor(214886.6094, grad_fn=<MeanBackward0>)\n","tensor(22.1036, grad_fn=<MeanBackward0>)\n","tensor(209135.6562, grad_fn=<MeanBackward0>)\n","[ 840/1000] train_loss: 17.72923 valid_loss: 10.05719\n","EarlyStopping counter: 1 out of 20\n","tensor(23.7840, grad_fn=<MeanBackward0>)\n","tensor(211677.1719, grad_fn=<MeanBackward0>)\n","tensor(23.2328, grad_fn=<MeanBackward0>)\n","tensor(199985.2656, grad_fn=<MeanBackward0>)\n","tensor(24.2817, grad_fn=<MeanBackward0>)\n","tensor(214384.2188, grad_fn=<MeanBackward0>)\n","[ 841/1000] train_loss: 17.88513 valid_loss: 10.08400\n","EarlyStopping counter: 2 out of 20\n","tensor(23.8147, grad_fn=<MeanBackward0>)\n","tensor(197996.9844, grad_fn=<MeanBackward0>)\n","tensor(24.5657, grad_fn=<MeanBackward0>)\n","tensor(216178.6719, grad_fn=<MeanBackward0>)\n","tensor(24.0530, grad_fn=<MeanBackward0>)\n","tensor(209733.0469, grad_fn=<MeanBackward0>)\n","[ 842/1000] train_loss: 17.94514 valid_loss: 10.08823\n","EarlyStopping counter: 3 out of 20\n","tensor(23.9795, grad_fn=<MeanBackward0>)\n","tensor(202512., grad_fn=<MeanBackward0>)\n","tensor(24.8517, grad_fn=<MeanBackward0>)\n","tensor(191697.1250, grad_fn=<MeanBackward0>)\n","tensor(21.6888, grad_fn=<MeanBackward0>)\n","tensor(229378.5469, grad_fn=<MeanBackward0>)\n","[ 843/1000] train_loss: 18.02780 valid_loss: 10.04636\n","Validation loss decreased (10.056846 --> 10.046364).  Saving model ...\n","tensor(23.1674, grad_fn=<MeanBackward0>)\n","tensor(202678.2500, grad_fn=<MeanBackward0>)\n","tensor(22.6855, grad_fn=<MeanBackward0>)\n","tensor(214998.0625, grad_fn=<MeanBackward0>)\n","tensor(24.4762, grad_fn=<MeanBackward0>)\n","tensor(231236.7969, grad_fn=<MeanBackward0>)\n","[ 844/1000] train_loss: 17.92181 valid_loss: 10.06637\n","EarlyStopping counter: 1 out of 20\n","tensor(23.0240, grad_fn=<MeanBackward0>)\n","tensor(220613.1250, grad_fn=<MeanBackward0>)\n","tensor(25.8723, grad_fn=<MeanBackward0>)\n","tensor(215809.0781, grad_fn=<MeanBackward0>)\n","tensor(21.1320, grad_fn=<MeanBackward0>)\n","tensor(198512.8281, grad_fn=<MeanBackward0>)\n","[ 845/1000] train_loss: 17.76245 valid_loss: 10.04710\n","EarlyStopping counter: 2 out of 20\n","tensor(22.8567, grad_fn=<MeanBackward0>)\n","tensor(205876.8281, grad_fn=<MeanBackward0>)\n","tensor(22.9220, grad_fn=<MeanBackward0>)\n","tensor(208274.2969, grad_fn=<MeanBackward0>)\n","tensor(21.7682, grad_fn=<MeanBackward0>)\n","tensor(208415.1094, grad_fn=<MeanBackward0>)\n","[ 846/1000] train_loss: 17.78793 valid_loss: 10.03108\n","Validation loss decreased (10.046364 --> 10.031075).  Saving model ...\n","tensor(21.3124, grad_fn=<MeanBackward0>)\n","tensor(206572., grad_fn=<MeanBackward0>)\n","tensor(27.2637, grad_fn=<MeanBackward0>)\n","tensor(205395.3125, grad_fn=<MeanBackward0>)\n","tensor(24.2349, grad_fn=<MeanBackward0>)\n","tensor(211984.4062, grad_fn=<MeanBackward0>)\n","[ 847/1000] train_loss: 17.85170 valid_loss: 10.04817\n","EarlyStopping counter: 1 out of 20\n","tensor(24.8156, grad_fn=<MeanBackward0>)\n","tensor(235854.7656, grad_fn=<MeanBackward0>)\n","tensor(23.3893, grad_fn=<MeanBackward0>)\n","tensor(188707.7656, grad_fn=<MeanBackward0>)\n","tensor(23.1687, grad_fn=<MeanBackward0>)\n","tensor(201910.8281, grad_fn=<MeanBackward0>)\n","[ 848/1000] train_loss: 17.69480 valid_loss: 10.01777\n","Validation loss decreased (10.031075 --> 10.017769).  Saving model ...\n","tensor(20.0731, grad_fn=<MeanBackward0>)\n","tensor(219621.1875, grad_fn=<MeanBackward0>)\n","tensor(22.5661, grad_fn=<MeanBackward0>)\n","tensor(213165.4219, grad_fn=<MeanBackward0>)\n","tensor(23.1059, grad_fn=<MeanBackward0>)\n","tensor(199177.3594, grad_fn=<MeanBackward0>)\n","[ 849/1000] train_loss: 17.54756 valid_loss: 10.04399\n","EarlyStopping counter: 1 out of 20\n","tensor(21.6940, grad_fn=<MeanBackward0>)\n","tensor(212901.6875, grad_fn=<MeanBackward0>)\n","tensor(23.7774, grad_fn=<MeanBackward0>)\n","tensor(214168.5000, grad_fn=<MeanBackward0>)\n","tensor(24.1899, grad_fn=<MeanBackward0>)\n","tensor(216235.1875, grad_fn=<MeanBackward0>)\n","[ 850/1000] train_loss: 17.66711 valid_loss: 10.02296\n","EarlyStopping counter: 2 out of 20\n","tensor(22.3097, grad_fn=<MeanBackward0>)\n","tensor(192145.5000, grad_fn=<MeanBackward0>)\n","tensor(22.3708, grad_fn=<MeanBackward0>)\n","tensor(207545.2969, grad_fn=<MeanBackward0>)\n","tensor(23.6185, grad_fn=<MeanBackward0>)\n","tensor(217914.3750, grad_fn=<MeanBackward0>)\n","[ 851/1000] train_loss: 17.62772 valid_loss: 9.99785\n","Validation loss decreased (10.017769 --> 9.997854).  Saving model ...\n","tensor(23.3164, grad_fn=<MeanBackward0>)\n","tensor(201615.2969, grad_fn=<MeanBackward0>)\n","tensor(24.2501, grad_fn=<MeanBackward0>)\n","tensor(199077.8594, grad_fn=<MeanBackward0>)\n","tensor(24.8429, grad_fn=<MeanBackward0>)\n","tensor(218301.7188, grad_fn=<MeanBackward0>)\n","[ 852/1000] train_loss: 17.80981 valid_loss: 10.04518\n","EarlyStopping counter: 1 out of 20\n","tensor(24.1294, grad_fn=<MeanBackward0>)\n","tensor(202988., grad_fn=<MeanBackward0>)\n","tensor(25.8226, grad_fn=<MeanBackward0>)\n","tensor(202696.0469, grad_fn=<MeanBackward0>)\n","tensor(21.9534, grad_fn=<MeanBackward0>)\n","tensor(215777.5938, grad_fn=<MeanBackward0>)\n","[ 853/1000] train_loss: 17.58107 valid_loss: 10.02387\n","EarlyStopping counter: 2 out of 20\n","tensor(22.7188, grad_fn=<MeanBackward0>)\n","tensor(184506.2969, grad_fn=<MeanBackward0>)\n","tensor(23.3433, grad_fn=<MeanBackward0>)\n","tensor(228446.5156, grad_fn=<MeanBackward0>)\n","tensor(22.4637, grad_fn=<MeanBackward0>)\n","tensor(205399.3906, grad_fn=<MeanBackward0>)\n","[ 854/1000] train_loss: 17.74420 valid_loss: 10.01659\n","EarlyStopping counter: 3 out of 20\n","tensor(22.7320, grad_fn=<MeanBackward0>)\n","tensor(192473.9531, grad_fn=<MeanBackward0>)\n","tensor(22.6143, grad_fn=<MeanBackward0>)\n","tensor(211754.6406, grad_fn=<MeanBackward0>)\n","tensor(23.0737, grad_fn=<MeanBackward0>)\n","tensor(213689.9531, grad_fn=<MeanBackward0>)\n","[ 855/1000] train_loss: 17.78525 valid_loss: 10.02165\n","EarlyStopping counter: 4 out of 20\n","tensor(25.1961, grad_fn=<MeanBackward0>)\n","tensor(229908.6875, grad_fn=<MeanBackward0>)\n","tensor(24.0454, grad_fn=<MeanBackward0>)\n","tensor(204967.5781, grad_fn=<MeanBackward0>)\n","tensor(21.9516, grad_fn=<MeanBackward0>)\n","tensor(188221.0625, grad_fn=<MeanBackward0>)\n","[ 856/1000] train_loss: 17.71646 valid_loss: 10.01902\n","EarlyStopping counter: 5 out of 20\n","tensor(23.3608, grad_fn=<MeanBackward0>)\n","tensor(204471.9531, grad_fn=<MeanBackward0>)\n","tensor(23.1999, grad_fn=<MeanBackward0>)\n","tensor(225330.7344, grad_fn=<MeanBackward0>)\n","tensor(20.7517, grad_fn=<MeanBackward0>)\n","tensor(196115.1406, grad_fn=<MeanBackward0>)\n","[ 857/1000] train_loss: 17.53528 valid_loss: 10.01520\n","EarlyStopping counter: 6 out of 20\n","tensor(23.1370, grad_fn=<MeanBackward0>)\n","tensor(216537.6875, grad_fn=<MeanBackward0>)\n","tensor(21.1562, grad_fn=<MeanBackward0>)\n","tensor(191352.7969, grad_fn=<MeanBackward0>)\n","tensor(21.7828, grad_fn=<MeanBackward0>)\n","tensor(206419.6094, grad_fn=<MeanBackward0>)\n","[ 858/1000] train_loss: 17.73398 valid_loss: 9.99490\n","Validation loss decreased (9.997854 --> 9.994904).  Saving model ...\n","tensor(22.1142, grad_fn=<MeanBackward0>)\n","tensor(215085.7656, grad_fn=<MeanBackward0>)\n","tensor(23.9591, grad_fn=<MeanBackward0>)\n","tensor(192975.4375, grad_fn=<MeanBackward0>)\n","tensor(24.3426, grad_fn=<MeanBackward0>)\n","tensor(198632.1719, grad_fn=<MeanBackward0>)\n","[ 859/1000] train_loss: 17.49864 valid_loss: 9.98515\n","Validation loss decreased (9.994904 --> 9.985152).  Saving model ...\n","tensor(23.1823, grad_fn=<MeanBackward0>)\n","tensor(226777.9375, grad_fn=<MeanBackward0>)\n","tensor(23.3445, grad_fn=<MeanBackward0>)\n","tensor(191818.4531, grad_fn=<MeanBackward0>)\n","tensor(20.7937, grad_fn=<MeanBackward0>)\n","tensor(185828.4531, grad_fn=<MeanBackward0>)\n","[ 860/1000] train_loss: 17.55399 valid_loss: 9.97570\n","Validation loss decreased (9.985152 --> 9.975699).  Saving model ...\n","tensor(24.0240, grad_fn=<MeanBackward0>)\n","tensor(203173.5156, grad_fn=<MeanBackward0>)\n","tensor(24.0258, grad_fn=<MeanBackward0>)\n","tensor(197868.7969, grad_fn=<MeanBackward0>)\n","tensor(21.6049, grad_fn=<MeanBackward0>)\n","tensor(197837.1250, grad_fn=<MeanBackward0>)\n","[ 861/1000] train_loss: 17.75832 valid_loss: 10.01482\n","EarlyStopping counter: 1 out of 20\n","tensor(24.0031, grad_fn=<MeanBackward0>)\n","tensor(215338.7656, grad_fn=<MeanBackward0>)\n","tensor(24.0478, grad_fn=<MeanBackward0>)\n","tensor(190267.4375, grad_fn=<MeanBackward0>)\n","tensor(23.3914, grad_fn=<MeanBackward0>)\n","tensor(205320.7344, grad_fn=<MeanBackward0>)\n","[ 862/1000] train_loss: 17.81017 valid_loss: 9.99608\n","EarlyStopping counter: 2 out of 20\n","tensor(25.5532, grad_fn=<MeanBackward0>)\n","tensor(203606.3594, grad_fn=<MeanBackward0>)\n","tensor(23.2973, grad_fn=<MeanBackward0>)\n","tensor(197683.1094, grad_fn=<MeanBackward0>)\n","tensor(22.2666, grad_fn=<MeanBackward0>)\n","tensor(196501.0625, grad_fn=<MeanBackward0>)\n","[ 863/1000] train_loss: 17.67506 valid_loss: 9.99188\n","EarlyStopping counter: 3 out of 20\n","tensor(21.0569, grad_fn=<MeanBackward0>)\n","tensor(197283.1094, grad_fn=<MeanBackward0>)\n","tensor(22.8620, grad_fn=<MeanBackward0>)\n","tensor(198797.0469, grad_fn=<MeanBackward0>)\n","tensor(22.6565, grad_fn=<MeanBackward0>)\n","tensor(218819.7656, grad_fn=<MeanBackward0>)\n","[ 864/1000] train_loss: 17.59401 valid_loss: 9.99317\n","EarlyStopping counter: 4 out of 20\n","tensor(22.1756, grad_fn=<MeanBackward0>)\n","tensor(196745.7969, grad_fn=<MeanBackward0>)\n","tensor(21.6728, grad_fn=<MeanBackward0>)\n","tensor(205183.8906, grad_fn=<MeanBackward0>)\n","tensor(24.4005, grad_fn=<MeanBackward0>)\n","tensor(214645.3281, grad_fn=<MeanBackward0>)\n","[ 865/1000] train_loss: 17.65169 valid_loss: 9.96785\n","Validation loss decreased (9.975699 --> 9.967849).  Saving model ...\n","tensor(23.2017, grad_fn=<MeanBackward0>)\n","tensor(202015.4531, grad_fn=<MeanBackward0>)\n","tensor(22.4749, grad_fn=<MeanBackward0>)\n","tensor(209001.9219, grad_fn=<MeanBackward0>)\n","tensor(21.9986, grad_fn=<MeanBackward0>)\n","tensor(189414.6406, grad_fn=<MeanBackward0>)\n","[ 866/1000] train_loss: 17.41306 valid_loss: 9.97324\n","EarlyStopping counter: 1 out of 20\n","tensor(21.9110, grad_fn=<MeanBackward0>)\n","tensor(214994.9531, grad_fn=<MeanBackward0>)\n","tensor(24.4259, grad_fn=<MeanBackward0>)\n","tensor(189260.2969, grad_fn=<MeanBackward0>)\n","tensor(23.6302, grad_fn=<MeanBackward0>)\n","tensor(197618.5469, grad_fn=<MeanBackward0>)\n","[ 867/1000] train_loss: 17.76606 valid_loss: 10.01309\n","EarlyStopping counter: 2 out of 20\n","tensor(22.4397, grad_fn=<MeanBackward0>)\n","tensor(206512.3281, grad_fn=<MeanBackward0>)\n","tensor(22.9092, grad_fn=<MeanBackward0>)\n","tensor(206496.3281, grad_fn=<MeanBackward0>)\n","tensor(22.3820, grad_fn=<MeanBackward0>)\n","tensor(197077.4844, grad_fn=<MeanBackward0>)\n","[ 868/1000] train_loss: 17.48674 valid_loss: 9.96148\n","Validation loss decreased (9.967849 --> 9.961478).  Saving model ...\n","tensor(21.9164, grad_fn=<MeanBackward0>)\n","tensor(206234., grad_fn=<MeanBackward0>)\n","tensor(21.9994, grad_fn=<MeanBackward0>)\n","tensor(200782.5156, grad_fn=<MeanBackward0>)\n","tensor(23.0742, grad_fn=<MeanBackward0>)\n","tensor(208269.0625, grad_fn=<MeanBackward0>)\n","[ 869/1000] train_loss: 17.36707 valid_loss: 9.95155\n","Validation loss decreased (9.961478 --> 9.951549).  Saving model ...\n","tensor(22.7633, grad_fn=<MeanBackward0>)\n","tensor(203180.1406, grad_fn=<MeanBackward0>)\n","tensor(22.4442, grad_fn=<MeanBackward0>)\n","tensor(198304.3594, grad_fn=<MeanBackward0>)\n","tensor(24.2390, grad_fn=<MeanBackward0>)\n","tensor(204237.7812, grad_fn=<MeanBackward0>)\n","[ 870/1000] train_loss: 17.54218 valid_loss: 9.96159\n","EarlyStopping counter: 1 out of 20\n","tensor(23.2140, grad_fn=<MeanBackward0>)\n","tensor(210665.3281, grad_fn=<MeanBackward0>)\n","tensor(21.9030, grad_fn=<MeanBackward0>)\n","tensor(204131.1875, grad_fn=<MeanBackward0>)\n","tensor(21.7178, grad_fn=<MeanBackward0>)\n","tensor(183619.7656, grad_fn=<MeanBackward0>)\n","[ 871/1000] train_loss: 17.65206 valid_loss: 9.93134\n","Validation loss decreased (9.951549 --> 9.931337).  Saving model ...\n","tensor(24.9949, grad_fn=<MeanBackward0>)\n","tensor(210257.2969, grad_fn=<MeanBackward0>)\n","tensor(21.8689, grad_fn=<MeanBackward0>)\n","tensor(197957.6875, grad_fn=<MeanBackward0>)\n","tensor(21.5347, grad_fn=<MeanBackward0>)\n","tensor(194284.1406, grad_fn=<MeanBackward0>)\n","[ 872/1000] train_loss: 17.40573 valid_loss: 9.93978\n","EarlyStopping counter: 1 out of 20\n","tensor(21.8586, grad_fn=<MeanBackward0>)\n","tensor(188753.8906, grad_fn=<MeanBackward0>)\n","tensor(21.6587, grad_fn=<MeanBackward0>)\n","tensor(205865.0625, grad_fn=<MeanBackward0>)\n","tensor(22.9918, grad_fn=<MeanBackward0>)\n","tensor(208255.7344, grad_fn=<MeanBackward0>)\n","[ 873/1000] train_loss: 17.68586 valid_loss: 9.95204\n","EarlyStopping counter: 2 out of 20\n","tensor(23.0605, grad_fn=<MeanBackward0>)\n","tensor(215157., grad_fn=<MeanBackward0>)\n","tensor(22.1264, grad_fn=<MeanBackward0>)\n","tensor(202672.0625, grad_fn=<MeanBackward0>)\n","tensor(23.3505, grad_fn=<MeanBackward0>)\n","tensor(182040.9844, grad_fn=<MeanBackward0>)\n","[ 874/1000] train_loss: 17.51074 valid_loss: 9.96070\n","EarlyStopping counter: 3 out of 20\n","tensor(22.6462, grad_fn=<MeanBackward0>)\n","tensor(190536.5469, grad_fn=<MeanBackward0>)\n","tensor(23.6675, grad_fn=<MeanBackward0>)\n","tensor(198868.7031, grad_fn=<MeanBackward0>)\n","tensor(21.1023, grad_fn=<MeanBackward0>)\n","tensor(200058., grad_fn=<MeanBackward0>)\n","[ 875/1000] train_loss: 17.58838 valid_loss: 9.97952\n","EarlyStopping counter: 4 out of 20\n","tensor(22.4862, grad_fn=<MeanBackward0>)\n","tensor(196934.5625, grad_fn=<MeanBackward0>)\n","tensor(22.2493, grad_fn=<MeanBackward0>)\n","tensor(194551.5781, grad_fn=<MeanBackward0>)\n","tensor(20.9334, grad_fn=<MeanBackward0>)\n","tensor(213536.2656, grad_fn=<MeanBackward0>)\n","[ 876/1000] train_loss: 17.40397 valid_loss: 9.93468\n","EarlyStopping counter: 5 out of 20\n","tensor(20.9308, grad_fn=<MeanBackward0>)\n","tensor(215420.7344, grad_fn=<MeanBackward0>)\n","tensor(21.5549, grad_fn=<MeanBackward0>)\n","tensor(191670.4844, grad_fn=<MeanBackward0>)\n","tensor(21.7094, grad_fn=<MeanBackward0>)\n","tensor(189936.9375, grad_fn=<MeanBackward0>)\n","[ 877/1000] train_loss: 17.54322 valid_loss: 9.93274\n","EarlyStopping counter: 6 out of 20\n","tensor(23.1000, grad_fn=<MeanBackward0>)\n","tensor(200233.9375, grad_fn=<MeanBackward0>)\n","tensor(19.5346, grad_fn=<MeanBackward0>)\n","tensor(185343.1250, grad_fn=<MeanBackward0>)\n","tensor(25.4394, grad_fn=<MeanBackward0>)\n","tensor(212985.8125, grad_fn=<MeanBackward0>)\n","[ 878/1000] train_loss: 17.36819 valid_loss: 9.95994\n","EarlyStopping counter: 7 out of 20\n","tensor(21.9625, grad_fn=<MeanBackward0>)\n","tensor(189100.4375, grad_fn=<MeanBackward0>)\n","tensor(23.5009, grad_fn=<MeanBackward0>)\n","tensor(208997.8906, grad_fn=<MeanBackward0>)\n","tensor(21.4607, grad_fn=<MeanBackward0>)\n","tensor(189039.8594, grad_fn=<MeanBackward0>)\n","[ 879/1000] train_loss: 17.59761 valid_loss: 9.93335\n","EarlyStopping counter: 8 out of 20\n","tensor(19.8788, grad_fn=<MeanBackward0>)\n","tensor(189795.3750, grad_fn=<MeanBackward0>)\n","tensor(21.5962, grad_fn=<MeanBackward0>)\n","tensor(204690.9844, grad_fn=<MeanBackward0>)\n","tensor(21.9910, grad_fn=<MeanBackward0>)\n","tensor(193948.0156, grad_fn=<MeanBackward0>)\n","[ 880/1000] train_loss: 17.32232 valid_loss: 9.93214\n","EarlyStopping counter: 9 out of 20\n","tensor(22.8456, grad_fn=<MeanBackward0>)\n","tensor(187229.8906, grad_fn=<MeanBackward0>)\n","tensor(23.4569, grad_fn=<MeanBackward0>)\n","tensor(206183.3594, grad_fn=<MeanBackward0>)\n","tensor(23.1504, grad_fn=<MeanBackward0>)\n","tensor(192696.2188, grad_fn=<MeanBackward0>)\n","[ 881/1000] train_loss: 17.41795 valid_loss: 9.92455\n","Validation loss decreased (9.931337 --> 9.924546).  Saving model ...\n","tensor(22.9298, grad_fn=<MeanBackward0>)\n","tensor(197208.3594, grad_fn=<MeanBackward0>)\n","tensor(23.6646, grad_fn=<MeanBackward0>)\n","tensor(197667.6406, grad_fn=<MeanBackward0>)\n","tensor(20.5697, grad_fn=<MeanBackward0>)\n","tensor(190590.7656, grad_fn=<MeanBackward0>)\n","[ 882/1000] train_loss: 17.32898 valid_loss: 9.89917\n","Validation loss decreased (9.924546 --> 9.899175).  Saving model ...\n","tensor(22.2356, grad_fn=<MeanBackward0>)\n","tensor(205142.4375, grad_fn=<MeanBackward0>)\n","tensor(20.4096, grad_fn=<MeanBackward0>)\n","tensor(183235.5469, grad_fn=<MeanBackward0>)\n","tensor(24.9651, grad_fn=<MeanBackward0>)\n","tensor(204725.0938, grad_fn=<MeanBackward0>)\n","[ 883/1000] train_loss: 17.43762 valid_loss: 9.91777\n","EarlyStopping counter: 1 out of 20\n","tensor(24.0835, grad_fn=<MeanBackward0>)\n","tensor(194583.5156, grad_fn=<MeanBackward0>)\n","tensor(22.2433, grad_fn=<MeanBackward0>)\n","tensor(193999.5156, grad_fn=<MeanBackward0>)\n","tensor(22.9996, grad_fn=<MeanBackward0>)\n","tensor(194987.0312, grad_fn=<MeanBackward0>)\n","[ 884/1000] train_loss: 17.30368 valid_loss: 9.91837\n","EarlyStopping counter: 2 out of 20\n","tensor(22.1678, grad_fn=<MeanBackward0>)\n","tensor(201424.8750, grad_fn=<MeanBackward0>)\n","tensor(24.3188, grad_fn=<MeanBackward0>)\n","tensor(194462.5156, grad_fn=<MeanBackward0>)\n","tensor(20.7814, grad_fn=<MeanBackward0>)\n","tensor(196212.3906, grad_fn=<MeanBackward0>)\n","[ 885/1000] train_loss: 17.22758 valid_loss: 9.92645\n","EarlyStopping counter: 3 out of 20\n","tensor(23.0663, grad_fn=<MeanBackward0>)\n","tensor(189541.8750, grad_fn=<MeanBackward0>)\n","tensor(21.2450, grad_fn=<MeanBackward0>)\n","tensor(197530.9531, grad_fn=<MeanBackward0>)\n","tensor(20.7617, grad_fn=<MeanBackward0>)\n","tensor(193669.8906, grad_fn=<MeanBackward0>)\n","[ 886/1000] train_loss: 17.54203 valid_loss: 9.92967\n","EarlyStopping counter: 4 out of 20\n","tensor(21.6194, grad_fn=<MeanBackward0>)\n","tensor(199860.4219, grad_fn=<MeanBackward0>)\n","tensor(19.8843, grad_fn=<MeanBackward0>)\n","tensor(179072.9844, grad_fn=<MeanBackward0>)\n","tensor(23.3092, grad_fn=<MeanBackward0>)\n","tensor(190266.1562, grad_fn=<MeanBackward0>)\n","[ 887/1000] train_loss: 17.30021 valid_loss: 9.95349\n","EarlyStopping counter: 5 out of 20\n","tensor(23.0647, grad_fn=<MeanBackward0>)\n","tensor(184378.9219, grad_fn=<MeanBackward0>)\n","tensor(22.6522, grad_fn=<MeanBackward0>)\n","tensor(199215.5781, grad_fn=<MeanBackward0>)\n","tensor(19.3775, grad_fn=<MeanBackward0>)\n","tensor(202192.2656, grad_fn=<MeanBackward0>)\n","[ 888/1000] train_loss: 17.51545 valid_loss: 9.89997\n","EarlyStopping counter: 6 out of 20\n","tensor(22.7333, grad_fn=<MeanBackward0>)\n","tensor(196773.6406, grad_fn=<MeanBackward0>)\n","tensor(21.3299, grad_fn=<MeanBackward0>)\n","tensor(203456.5781, grad_fn=<MeanBackward0>)\n","tensor(21.6412, grad_fn=<MeanBackward0>)\n","tensor(198951.9375, grad_fn=<MeanBackward0>)\n","[ 889/1000] train_loss: 17.50646 valid_loss: 9.89883\n","Validation loss decreased (9.899175 --> 9.898833).  Saving model ...\n","tensor(23.1432, grad_fn=<MeanBackward0>)\n","tensor(198434.7656, grad_fn=<MeanBackward0>)\n","tensor(21.7110, grad_fn=<MeanBackward0>)\n","tensor(219751.9844, grad_fn=<MeanBackward0>)\n","tensor(21.7863, grad_fn=<MeanBackward0>)\n","tensor(185753.6875, grad_fn=<MeanBackward0>)\n","[ 890/1000] train_loss: 17.64174 valid_loss: 9.88333\n","Validation loss decreased (9.898833 --> 9.883327).  Saving model ...\n","tensor(23.9871, grad_fn=<MeanBackward0>)\n","tensor(189803.2500, grad_fn=<MeanBackward0>)\n","tensor(20.7773, grad_fn=<MeanBackward0>)\n","tensor(184803.4844, grad_fn=<MeanBackward0>)\n","tensor(25.8031, grad_fn=<MeanBackward0>)\n","tensor(191755.9688, grad_fn=<MeanBackward0>)\n","[ 891/1000] train_loss: 17.40198 valid_loss: 9.91002\n","EarlyStopping counter: 1 out of 20\n","tensor(23.4770, grad_fn=<MeanBackward0>)\n","tensor(191301.6094, grad_fn=<MeanBackward0>)\n","tensor(23.2529, grad_fn=<MeanBackward0>)\n","tensor(187418.2969, grad_fn=<MeanBackward0>)\n","tensor(22.0628, grad_fn=<MeanBackward0>)\n","tensor(201822.5625, grad_fn=<MeanBackward0>)\n","[ 892/1000] train_loss: 17.42747 valid_loss: 9.91402\n","EarlyStopping counter: 2 out of 20\n","tensor(22.0232, grad_fn=<MeanBackward0>)\n","tensor(201231.4219, grad_fn=<MeanBackward0>)\n","tensor(21.9267, grad_fn=<MeanBackward0>)\n","tensor(184919., grad_fn=<MeanBackward0>)\n","tensor(22.1240, grad_fn=<MeanBackward0>)\n","tensor(213388.0312, grad_fn=<MeanBackward0>)\n","[ 893/1000] train_loss: 17.39714 valid_loss: 9.90846\n","EarlyStopping counter: 3 out of 20\n","tensor(21.4963, grad_fn=<MeanBackward0>)\n","tensor(222056.6875, grad_fn=<MeanBackward0>)\n","tensor(21.6234, grad_fn=<MeanBackward0>)\n","tensor(199835.2656, grad_fn=<MeanBackward0>)\n","tensor(21.8403, grad_fn=<MeanBackward0>)\n","tensor(183135.5469, grad_fn=<MeanBackward0>)\n","[ 894/1000] train_loss: 17.45924 valid_loss: 9.87527\n","Validation loss decreased (9.883327 --> 9.875273).  Saving model ...\n","tensor(20.5689, grad_fn=<MeanBackward0>)\n","tensor(181135.6094, grad_fn=<MeanBackward0>)\n","tensor(21.1612, grad_fn=<MeanBackward0>)\n","tensor(181644.1719, grad_fn=<MeanBackward0>)\n","tensor(24.3222, grad_fn=<MeanBackward0>)\n","tensor(201719.7969, grad_fn=<MeanBackward0>)\n","[ 895/1000] train_loss: 17.34993 valid_loss: 9.87252\n","Validation loss decreased (9.875273 --> 9.872522).  Saving model ...\n","tensor(21.6728, grad_fn=<MeanBackward0>)\n","tensor(176453.8750, grad_fn=<MeanBackward0>)\n","tensor(23.5432, grad_fn=<MeanBackward0>)\n","tensor(210136.5000, grad_fn=<MeanBackward0>)\n","tensor(22.6044, grad_fn=<MeanBackward0>)\n","tensor(197482.6250, grad_fn=<MeanBackward0>)\n","[ 896/1000] train_loss: 17.34318 valid_loss: 9.84952\n","Validation loss decreased (9.872522 --> 9.849517).  Saving model ...\n","tensor(21.5435, grad_fn=<MeanBackward0>)\n","tensor(198817.4531, grad_fn=<MeanBackward0>)\n","tensor(21.2216, grad_fn=<MeanBackward0>)\n","tensor(184854.7500, grad_fn=<MeanBackward0>)\n","tensor(22.1292, grad_fn=<MeanBackward0>)\n","tensor(189059.3438, grad_fn=<MeanBackward0>)\n","[ 897/1000] train_loss: 17.42633 valid_loss: 9.86056\n","EarlyStopping counter: 1 out of 20\n","tensor(21.0109, grad_fn=<MeanBackward0>)\n","tensor(191263.8281, grad_fn=<MeanBackward0>)\n","tensor(22.9679, grad_fn=<MeanBackward0>)\n","tensor(193930.8281, grad_fn=<MeanBackward0>)\n","tensor(23.1554, grad_fn=<MeanBackward0>)\n","tensor(202110.5156, grad_fn=<MeanBackward0>)\n","[ 898/1000] train_loss: 17.36308 valid_loss: 9.87327\n","EarlyStopping counter: 2 out of 20\n","tensor(22.4087, grad_fn=<MeanBackward0>)\n","tensor(207440.9844, grad_fn=<MeanBackward0>)\n","tensor(21.3317, grad_fn=<MeanBackward0>)\n","tensor(194652.4219, grad_fn=<MeanBackward0>)\n","tensor(20.5237, grad_fn=<MeanBackward0>)\n","tensor(171400.5469, grad_fn=<MeanBackward0>)\n","[ 899/1000] train_loss: 17.13492 valid_loss: 9.91381\n","EarlyStopping counter: 3 out of 20\n","tensor(19.7091, grad_fn=<MeanBackward0>)\n","tensor(186644.0781, grad_fn=<MeanBackward0>)\n","tensor(23.1477, grad_fn=<MeanBackward0>)\n","tensor(214431.8750, grad_fn=<MeanBackward0>)\n","tensor(20.5432, grad_fn=<MeanBackward0>)\n","tensor(179446.1406, grad_fn=<MeanBackward0>)\n","[ 900/1000] train_loss: 17.26343 valid_loss: 9.86789\n","EarlyStopping counter: 4 out of 20\n","tensor(21.9238, grad_fn=<MeanBackward0>)\n","tensor(188057.1406, grad_fn=<MeanBackward0>)\n","tensor(23.3666, grad_fn=<MeanBackward0>)\n","tensor(190355.0156, grad_fn=<MeanBackward0>)\n","tensor(20.4664, grad_fn=<MeanBackward0>)\n","tensor(184468.3594, grad_fn=<MeanBackward0>)\n","[ 901/1000] train_loss: 17.27017 valid_loss: 9.86870\n","EarlyStopping counter: 5 out of 20\n","tensor(22.5739, grad_fn=<MeanBackward0>)\n","tensor(196303.5000, grad_fn=<MeanBackward0>)\n","tensor(21.0133, grad_fn=<MeanBackward0>)\n","tensor(173056.6875, grad_fn=<MeanBackward0>)\n","tensor(21.3575, grad_fn=<MeanBackward0>)\n","tensor(199806.8281, grad_fn=<MeanBackward0>)\n","[ 902/1000] train_loss: 17.01825 valid_loss: 9.86560\n","EarlyStopping counter: 6 out of 20\n","tensor(21.8284, grad_fn=<MeanBackward0>)\n","tensor(178965.9219, grad_fn=<MeanBackward0>)\n","tensor(20.5267, grad_fn=<MeanBackward0>)\n","tensor(179562.0625, grad_fn=<MeanBackward0>)\n","tensor(23.2219, grad_fn=<MeanBackward0>)\n","tensor(204464.7656, grad_fn=<MeanBackward0>)\n","[ 903/1000] train_loss: 17.40690 valid_loss: 9.91357\n","EarlyStopping counter: 7 out of 20\n","tensor(21.4645, grad_fn=<MeanBackward0>)\n","tensor(190767.7969, grad_fn=<MeanBackward0>)\n","tensor(23.4037, grad_fn=<MeanBackward0>)\n","tensor(217004.2344, grad_fn=<MeanBackward0>)\n","tensor(19.9990, grad_fn=<MeanBackward0>)\n","tensor(178852.3906, grad_fn=<MeanBackward0>)\n","[ 904/1000] train_loss: 17.30673 valid_loss: 9.88323\n","EarlyStopping counter: 8 out of 20\n","tensor(20.4781, grad_fn=<MeanBackward0>)\n","tensor(201483.9531, grad_fn=<MeanBackward0>)\n","tensor(20.8040, grad_fn=<MeanBackward0>)\n","tensor(185397.2031, grad_fn=<MeanBackward0>)\n","tensor(21.1404, grad_fn=<MeanBackward0>)\n","tensor(185359.8594, grad_fn=<MeanBackward0>)\n","[ 905/1000] train_loss: 17.24317 valid_loss: 9.87875\n","EarlyStopping counter: 9 out of 20\n","tensor(21.6190, grad_fn=<MeanBackward0>)\n","tensor(183425.4844, grad_fn=<MeanBackward0>)\n","tensor(23.5309, grad_fn=<MeanBackward0>)\n","tensor(193404.1875, grad_fn=<MeanBackward0>)\n","tensor(24.6644, grad_fn=<MeanBackward0>)\n","tensor(182698.8125, grad_fn=<MeanBackward0>)\n","[ 906/1000] train_loss: 17.41730 valid_loss: 9.86761\n","EarlyStopping counter: 10 out of 20\n","tensor(22.6417, grad_fn=<MeanBackward0>)\n","tensor(175680.5625, grad_fn=<MeanBackward0>)\n","tensor(23.0671, grad_fn=<MeanBackward0>)\n","tensor(185345.3125, grad_fn=<MeanBackward0>)\n","tensor(21.8935, grad_fn=<MeanBackward0>)\n","tensor(182035.5781, grad_fn=<MeanBackward0>)\n","[ 907/1000] train_loss: 17.07129 valid_loss: 9.84773\n","Validation loss decreased (9.849517 --> 9.847733).  Saving model ...\n","tensor(21.0724, grad_fn=<MeanBackward0>)\n","tensor(197269.9531, grad_fn=<MeanBackward0>)\n","tensor(22.1492, grad_fn=<MeanBackward0>)\n","tensor(185957.8125, grad_fn=<MeanBackward0>)\n","tensor(20.1730, grad_fn=<MeanBackward0>)\n","tensor(203690.2656, grad_fn=<MeanBackward0>)\n","[ 908/1000] train_loss: 17.36430 valid_loss: 9.85161\n","EarlyStopping counter: 1 out of 20\n","tensor(20.7161, grad_fn=<MeanBackward0>)\n","tensor(189376.1094, grad_fn=<MeanBackward0>)\n","tensor(22.4907, grad_fn=<MeanBackward0>)\n","tensor(202429.4844, grad_fn=<MeanBackward0>)\n","tensor(20.4146, grad_fn=<MeanBackward0>)\n","tensor(187314.3750, grad_fn=<MeanBackward0>)\n","[ 909/1000] train_loss: 17.16146 valid_loss: 9.84673\n","Validation loss decreased (9.847733 --> 9.846733).  Saving model ...\n","tensor(20.4896, grad_fn=<MeanBackward0>)\n","tensor(168921.4688, grad_fn=<MeanBackward0>)\n","tensor(21.4453, grad_fn=<MeanBackward0>)\n","tensor(202882.1875, grad_fn=<MeanBackward0>)\n","tensor(22.1027, grad_fn=<MeanBackward0>)\n","tensor(173343.1406, grad_fn=<MeanBackward0>)\n","[ 910/1000] train_loss: 16.98187 valid_loss: 9.84953\n","EarlyStopping counter: 1 out of 20\n","tensor(21.7423, grad_fn=<MeanBackward0>)\n","tensor(194421.5469, grad_fn=<MeanBackward0>)\n","tensor(20.6736, grad_fn=<MeanBackward0>)\n","tensor(175453.9844, grad_fn=<MeanBackward0>)\n","tensor(23.8509, grad_fn=<MeanBackward0>)\n","tensor(183586.3594, grad_fn=<MeanBackward0>)\n","[ 911/1000] train_loss: 17.37826 valid_loss: 9.85956\n","EarlyStopping counter: 2 out of 20\n","tensor(22.1072, grad_fn=<MeanBackward0>)\n","tensor(180928.3750, grad_fn=<MeanBackward0>)\n","tensor(23.3641, grad_fn=<MeanBackward0>)\n","tensor(188414.2500, grad_fn=<MeanBackward0>)\n","tensor(21.5682, grad_fn=<MeanBackward0>)\n","tensor(188285.1562, grad_fn=<MeanBackward0>)\n","[ 912/1000] train_loss: 17.27258 valid_loss: 9.81887\n","Validation loss decreased (9.846733 --> 9.818872).  Saving model ...\n","tensor(20.0466, grad_fn=<MeanBackward0>)\n","tensor(198163.2969, grad_fn=<MeanBackward0>)\n","tensor(23.7490, grad_fn=<MeanBackward0>)\n","tensor(200545.1719, grad_fn=<MeanBackward0>)\n","tensor(20.0478, grad_fn=<MeanBackward0>)\n","tensor(177472.5000, grad_fn=<MeanBackward0>)\n","[ 913/1000] train_loss: 17.24775 valid_loss: 9.85014\n","EarlyStopping counter: 1 out of 20\n","tensor(21.5528, grad_fn=<MeanBackward0>)\n","tensor(196648.8125, grad_fn=<MeanBackward0>)\n","tensor(19.3988, grad_fn=<MeanBackward0>)\n","tensor(182906.1875, grad_fn=<MeanBackward0>)\n","tensor(22.5326, grad_fn=<MeanBackward0>)\n","tensor(186991.9531, grad_fn=<MeanBackward0>)\n","[ 914/1000] train_loss: 17.22801 valid_loss: 9.85932\n","EarlyStopping counter: 2 out of 20\n","tensor(22.4618, grad_fn=<MeanBackward0>)\n","tensor(197314.6250, grad_fn=<MeanBackward0>)\n","tensor(21.6256, grad_fn=<MeanBackward0>)\n","tensor(177338.8750, grad_fn=<MeanBackward0>)\n","tensor(21.1351, grad_fn=<MeanBackward0>)\n","tensor(183169.2188, grad_fn=<MeanBackward0>)\n","[ 915/1000] train_loss: 17.14654 valid_loss: 9.88297\n","EarlyStopping counter: 3 out of 20\n","tensor(22.3877, grad_fn=<MeanBackward0>)\n","tensor(175752.1406, grad_fn=<MeanBackward0>)\n","tensor(21.3213, grad_fn=<MeanBackward0>)\n","tensor(180825.4375, grad_fn=<MeanBackward0>)\n","tensor(19.6704, grad_fn=<MeanBackward0>)\n","tensor(190034.5781, grad_fn=<MeanBackward0>)\n","[ 916/1000] train_loss: 17.26615 valid_loss: 9.88249\n","EarlyStopping counter: 4 out of 20\n","tensor(22.5268, grad_fn=<MeanBackward0>)\n","tensor(194169.3906, grad_fn=<MeanBackward0>)\n","tensor(20.7052, grad_fn=<MeanBackward0>)\n","tensor(190174.2656, grad_fn=<MeanBackward0>)\n","tensor(19.4982, grad_fn=<MeanBackward0>)\n","tensor(185712.0938, grad_fn=<MeanBackward0>)\n","[ 917/1000] train_loss: 17.25978 valid_loss: 9.81159\n","Validation loss decreased (9.818872 --> 9.811591).  Saving model ...\n","tensor(21.7319, grad_fn=<MeanBackward0>)\n","tensor(198645.7344, grad_fn=<MeanBackward0>)\n","tensor(21.9542, grad_fn=<MeanBackward0>)\n","tensor(178523.3281, grad_fn=<MeanBackward0>)\n","tensor(20.7630, grad_fn=<MeanBackward0>)\n","tensor(184313.1719, grad_fn=<MeanBackward0>)\n","[ 918/1000] train_loss: 17.08588 valid_loss: 9.79246\n","Validation loss decreased (9.811591 --> 9.792459).  Saving model ...\n","tensor(22.0123, grad_fn=<MeanBackward0>)\n","tensor(162019.3281, grad_fn=<MeanBackward0>)\n","tensor(23.0506, grad_fn=<MeanBackward0>)\n","tensor(181371.3125, grad_fn=<MeanBackward0>)\n","tensor(23.3193, grad_fn=<MeanBackward0>)\n","tensor(181297.7969, grad_fn=<MeanBackward0>)\n","[ 919/1000] train_loss: 17.23308 valid_loss: 9.80302\n","EarlyStopping counter: 1 out of 20\n","tensor(23.1305, grad_fn=<MeanBackward0>)\n","tensor(168217.1406, grad_fn=<MeanBackward0>)\n","tensor(22.4886, grad_fn=<MeanBackward0>)\n","tensor(191383.1719, grad_fn=<MeanBackward0>)\n","tensor(22.8374, grad_fn=<MeanBackward0>)\n","tensor(188570.1562, grad_fn=<MeanBackward0>)\n","[ 920/1000] train_loss: 17.17016 valid_loss: 9.81335\n","EarlyStopping counter: 2 out of 20\n","tensor(21.6949, grad_fn=<MeanBackward0>)\n","tensor(191285.6406, grad_fn=<MeanBackward0>)\n","tensor(20.4382, grad_fn=<MeanBackward0>)\n","tensor(193187.6250, grad_fn=<MeanBackward0>)\n","tensor(21.6463, grad_fn=<MeanBackward0>)\n","tensor(181033.0156, grad_fn=<MeanBackward0>)\n","[ 921/1000] train_loss: 17.36746 valid_loss: 9.80123\n","EarlyStopping counter: 3 out of 20\n","tensor(20.5831, grad_fn=<MeanBackward0>)\n","tensor(197796.7969, grad_fn=<MeanBackward0>)\n","tensor(21.5319, grad_fn=<MeanBackward0>)\n","tensor(181706.0781, grad_fn=<MeanBackward0>)\n","tensor(21.6584, grad_fn=<MeanBackward0>)\n","tensor(179808.5156, grad_fn=<MeanBackward0>)\n","[ 922/1000] train_loss: 16.94964 valid_loss: 9.79287\n","EarlyStopping counter: 4 out of 20\n","tensor(20.7593, grad_fn=<MeanBackward0>)\n","tensor(207585.5781, grad_fn=<MeanBackward0>)\n","tensor(19.8979, grad_fn=<MeanBackward0>)\n","tensor(192687.0781, grad_fn=<MeanBackward0>)\n","tensor(20.4991, grad_fn=<MeanBackward0>)\n","tensor(166153.4062, grad_fn=<MeanBackward0>)\n","[ 923/1000] train_loss: 17.12845 valid_loss: 9.79635\n","EarlyStopping counter: 5 out of 20\n","tensor(20.6794, grad_fn=<MeanBackward0>)\n","tensor(170834.4531, grad_fn=<MeanBackward0>)\n","tensor(21.5565, grad_fn=<MeanBackward0>)\n","tensor(194258.0156, grad_fn=<MeanBackward0>)\n","tensor(20.4568, grad_fn=<MeanBackward0>)\n","tensor(181810.7969, grad_fn=<MeanBackward0>)\n","[ 924/1000] train_loss: 16.99136 valid_loss: 9.83892\n","EarlyStopping counter: 6 out of 20\n","tensor(21.6312, grad_fn=<MeanBackward0>)\n","tensor(204417.0625, grad_fn=<MeanBackward0>)\n","tensor(20.8841, grad_fn=<MeanBackward0>)\n","tensor(178630.9375, grad_fn=<MeanBackward0>)\n","tensor(21.1083, grad_fn=<MeanBackward0>)\n","tensor(185257.9531, grad_fn=<MeanBackward0>)\n","[ 925/1000] train_loss: 16.87052 valid_loss: 9.81116\n","EarlyStopping counter: 7 out of 20\n","tensor(22.4245, grad_fn=<MeanBackward0>)\n","tensor(190802.3281, grad_fn=<MeanBackward0>)\n","tensor(20.8252, grad_fn=<MeanBackward0>)\n","tensor(169344.0312, grad_fn=<MeanBackward0>)\n","tensor(20.5738, grad_fn=<MeanBackward0>)\n","tensor(174841.7031, grad_fn=<MeanBackward0>)\n","[ 926/1000] train_loss: 16.91933 valid_loss: 9.79144\n","Validation loss decreased (9.792459 --> 9.791436).  Saving model ...\n","tensor(22.2090, grad_fn=<MeanBackward0>)\n","tensor(176876.8125, grad_fn=<MeanBackward0>)\n","tensor(22.1623, grad_fn=<MeanBackward0>)\n","tensor(182111.2344, grad_fn=<MeanBackward0>)\n","tensor(22.7461, grad_fn=<MeanBackward0>)\n","tensor(184469.7656, grad_fn=<MeanBackward0>)\n","[ 927/1000] train_loss: 16.94851 valid_loss: 9.75049\n","Validation loss decreased (9.791436 --> 9.750495).  Saving model ...\n","tensor(19.9330, grad_fn=<MeanBackward0>)\n","tensor(179988.5000, grad_fn=<MeanBackward0>)\n","tensor(21.6785, grad_fn=<MeanBackward0>)\n","tensor(186849.8906, grad_fn=<MeanBackward0>)\n","tensor(21.7870, grad_fn=<MeanBackward0>)\n","tensor(193651.7656, grad_fn=<MeanBackward0>)\n","[ 928/1000] train_loss: 17.03537 valid_loss: 9.75850\n","EarlyStopping counter: 1 out of 20\n","tensor(21.8793, grad_fn=<MeanBackward0>)\n","tensor(180752.5469, grad_fn=<MeanBackward0>)\n","tensor(20.9349, grad_fn=<MeanBackward0>)\n","tensor(188893.2656, grad_fn=<MeanBackward0>)\n","tensor(20.8847, grad_fn=<MeanBackward0>)\n","tensor(182415.9062, grad_fn=<MeanBackward0>)\n","[ 929/1000] train_loss: 17.03748 valid_loss: 9.76336\n","EarlyStopping counter: 2 out of 20\n","tensor(20.0789, grad_fn=<MeanBackward0>)\n","tensor(183934.7656, grad_fn=<MeanBackward0>)\n","tensor(21.8075, grad_fn=<MeanBackward0>)\n","tensor(175530.0625, grad_fn=<MeanBackward0>)\n","tensor(21.4945, grad_fn=<MeanBackward0>)\n","tensor(204255.3750, grad_fn=<MeanBackward0>)\n","[ 930/1000] train_loss: 16.93515 valid_loss: 9.76619\n","EarlyStopping counter: 3 out of 20\n","tensor(21.9526, grad_fn=<MeanBackward0>)\n","tensor(208674.8906, grad_fn=<MeanBackward0>)\n","tensor(20.9197, grad_fn=<MeanBackward0>)\n","tensor(177787.8594, grad_fn=<MeanBackward0>)\n","tensor(18.6756, grad_fn=<MeanBackward0>)\n","tensor(170710.2031, grad_fn=<MeanBackward0>)\n","[ 931/1000] train_loss: 17.05604 valid_loss: 9.75935\n","EarlyStopping counter: 4 out of 20\n","tensor(22.6380, grad_fn=<MeanBackward0>)\n","tensor(181961.5156, grad_fn=<MeanBackward0>)\n","tensor(21.5355, grad_fn=<MeanBackward0>)\n","tensor(173269.2031, grad_fn=<MeanBackward0>)\n","tensor(20.6947, grad_fn=<MeanBackward0>)\n","tensor(195263.4375, grad_fn=<MeanBackward0>)\n","[ 932/1000] train_loss: 17.21091 valid_loss: 9.76237\n","EarlyStopping counter: 5 out of 20\n","tensor(20.2940, grad_fn=<MeanBackward0>)\n","tensor(196886.0781, grad_fn=<MeanBackward0>)\n","tensor(22.1009, grad_fn=<MeanBackward0>)\n","tensor(175452.6406, grad_fn=<MeanBackward0>)\n","tensor(23.6030, grad_fn=<MeanBackward0>)\n","tensor(184368.9375, grad_fn=<MeanBackward0>)\n","[ 933/1000] train_loss: 16.90903 valid_loss: 9.73997\n","Validation loss decreased (9.750495 --> 9.739968).  Saving model ...\n","tensor(20.9115, grad_fn=<MeanBackward0>)\n","tensor(185007.2656, grad_fn=<MeanBackward0>)\n","tensor(20.1840, grad_fn=<MeanBackward0>)\n","tensor(173602.7656, grad_fn=<MeanBackward0>)\n","tensor(20.3517, grad_fn=<MeanBackward0>)\n","tensor(186707.2031, grad_fn=<MeanBackward0>)\n","[ 934/1000] train_loss: 16.94409 valid_loss: 9.73232\n","Validation loss decreased (9.739968 --> 9.732322).  Saving model ...\n","tensor(20.4568, grad_fn=<MeanBackward0>)\n","tensor(181775.7656, grad_fn=<MeanBackward0>)\n","tensor(20.7576, grad_fn=<MeanBackward0>)\n","tensor(176763.1094, grad_fn=<MeanBackward0>)\n","tensor(20.7722, grad_fn=<MeanBackward0>)\n","tensor(179600.9062, grad_fn=<MeanBackward0>)\n","[ 935/1000] train_loss: 16.88839 valid_loss: 9.72209\n","Validation loss decreased (9.732322 --> 9.722091).  Saving model ...\n","tensor(20.9414, grad_fn=<MeanBackward0>)\n","tensor(185374.8750, grad_fn=<MeanBackward0>)\n","tensor(19.9166, grad_fn=<MeanBackward0>)\n","tensor(167850.8594, grad_fn=<MeanBackward0>)\n","tensor(19.9278, grad_fn=<MeanBackward0>)\n","tensor(177939.9219, grad_fn=<MeanBackward0>)\n","[ 936/1000] train_loss: 16.96998 valid_loss: 9.73899\n","EarlyStopping counter: 1 out of 20\n","tensor(22.4761, grad_fn=<MeanBackward0>)\n","tensor(174509.5781, grad_fn=<MeanBackward0>)\n","tensor(21.4482, grad_fn=<MeanBackward0>)\n","tensor(186769.3906, grad_fn=<MeanBackward0>)\n","tensor(20.8407, grad_fn=<MeanBackward0>)\n","tensor(180041.2656, grad_fn=<MeanBackward0>)\n","[ 937/1000] train_loss: 16.92633 valid_loss: 9.76287\n","EarlyStopping counter: 2 out of 20\n","tensor(19.7939, grad_fn=<MeanBackward0>)\n","tensor(172835.9531, grad_fn=<MeanBackward0>)\n","tensor(20.7505, grad_fn=<MeanBackward0>)\n","tensor(178343.4219, grad_fn=<MeanBackward0>)\n","tensor(19.3370, grad_fn=<MeanBackward0>)\n","tensor(193092.7031, grad_fn=<MeanBackward0>)\n","[ 938/1000] train_loss: 16.86396 valid_loss: 9.70411\n","Validation loss decreased (9.722091 --> 9.704109).  Saving model ...\n","tensor(20.4613, grad_fn=<MeanBackward0>)\n","tensor(191144.0469, grad_fn=<MeanBackward0>)\n","tensor(21.2949, grad_fn=<MeanBackward0>)\n","tensor(183902.3281, grad_fn=<MeanBackward0>)\n","tensor(20.5113, grad_fn=<MeanBackward0>)\n","tensor(174953.5625, grad_fn=<MeanBackward0>)\n","[ 939/1000] train_loss: 17.15121 valid_loss: 9.71037\n","EarlyStopping counter: 1 out of 20\n","tensor(19.9493, grad_fn=<MeanBackward0>)\n","tensor(171401.7656, grad_fn=<MeanBackward0>)\n","tensor(20.4851, grad_fn=<MeanBackward0>)\n","tensor(168716.6719, grad_fn=<MeanBackward0>)\n","tensor(22.8520, grad_fn=<MeanBackward0>)\n","tensor(188302.7969, grad_fn=<MeanBackward0>)\n","[ 940/1000] train_loss: 16.76116 valid_loss: 9.71714\n","EarlyStopping counter: 2 out of 20\n","tensor(23.9815, grad_fn=<MeanBackward0>)\n","tensor(181874.5000, grad_fn=<MeanBackward0>)\n","tensor(19.0623, grad_fn=<MeanBackward0>)\n","tensor(168352.9531, grad_fn=<MeanBackward0>)\n","tensor(22.1094, grad_fn=<MeanBackward0>)\n","tensor(176372.4219, grad_fn=<MeanBackward0>)\n","[ 941/1000] train_loss: 16.96805 valid_loss: 9.69955\n","Validation loss decreased (9.704109 --> 9.699553).  Saving model ...\n","tensor(19.8797, grad_fn=<MeanBackward0>)\n","tensor(174989.6094, grad_fn=<MeanBackward0>)\n","tensor(21.7550, grad_fn=<MeanBackward0>)\n","tensor(177910.5469, grad_fn=<MeanBackward0>)\n","tensor(22.4115, grad_fn=<MeanBackward0>)\n","tensor(184714.2656, grad_fn=<MeanBackward0>)\n","[ 942/1000] train_loss: 16.99450 valid_loss: 9.72835\n","EarlyStopping counter: 1 out of 20\n","tensor(21.8526, grad_fn=<MeanBackward0>)\n","tensor(188160.6875, grad_fn=<MeanBackward0>)\n","tensor(20.8364, grad_fn=<MeanBackward0>)\n","tensor(175394.0781, grad_fn=<MeanBackward0>)\n","tensor(22.4571, grad_fn=<MeanBackward0>)\n","tensor(171576.5625, grad_fn=<MeanBackward0>)\n","[ 943/1000] train_loss: 16.91000 valid_loss: 9.71870\n","EarlyStopping counter: 2 out of 20\n","tensor(20.2389, grad_fn=<MeanBackward0>)\n","tensor(188162.5000, grad_fn=<MeanBackward0>)\n","tensor(20.9627, grad_fn=<MeanBackward0>)\n","tensor(162807.6094, grad_fn=<MeanBackward0>)\n","tensor(20.5680, grad_fn=<MeanBackward0>)\n","tensor(197466.1250, grad_fn=<MeanBackward0>)\n","[ 944/1000] train_loss: 17.21315 valid_loss: 9.72577\n","EarlyStopping counter: 3 out of 20\n","tensor(20.0934, grad_fn=<MeanBackward0>)\n","tensor(173259.7812, grad_fn=<MeanBackward0>)\n","tensor(20.7174, grad_fn=<MeanBackward0>)\n","tensor(188662.0625, grad_fn=<MeanBackward0>)\n","tensor(20.0970, grad_fn=<MeanBackward0>)\n","tensor(186126.1406, grad_fn=<MeanBackward0>)\n","[ 945/1000] train_loss: 16.86247 valid_loss: 9.74612\n","EarlyStopping counter: 4 out of 20\n","tensor(20.7809, grad_fn=<MeanBackward0>)\n","tensor(183054.9219, grad_fn=<MeanBackward0>)\n","tensor(21.1635, grad_fn=<MeanBackward0>)\n","tensor(190646.3594, grad_fn=<MeanBackward0>)\n","tensor(20.5845, grad_fn=<MeanBackward0>)\n","tensor(171673.5156, grad_fn=<MeanBackward0>)\n","[ 946/1000] train_loss: 16.65719 valid_loss: 9.72359\n","EarlyStopping counter: 5 out of 20\n","tensor(19.7829, grad_fn=<MeanBackward0>)\n","tensor(185356.3125, grad_fn=<MeanBackward0>)\n","tensor(20.9677, grad_fn=<MeanBackward0>)\n","tensor(191122.6875, grad_fn=<MeanBackward0>)\n","tensor(18.7947, grad_fn=<MeanBackward0>)\n","tensor(181366.9062, grad_fn=<MeanBackward0>)\n","[ 947/1000] train_loss: 17.03701 valid_loss: 9.70930\n","EarlyStopping counter: 6 out of 20\n","tensor(19.8485, grad_fn=<MeanBackward0>)\n","tensor(191591.7969, grad_fn=<MeanBackward0>)\n","tensor(20.4507, grad_fn=<MeanBackward0>)\n","tensor(184081.4531, grad_fn=<MeanBackward0>)\n","tensor(20.7232, grad_fn=<MeanBackward0>)\n","tensor(178326.4531, grad_fn=<MeanBackward0>)\n","[ 948/1000] train_loss: 16.81544 valid_loss: 9.73844\n","EarlyStopping counter: 7 out of 20\n","tensor(22.2576, grad_fn=<MeanBackward0>)\n","tensor(178402.7031, grad_fn=<MeanBackward0>)\n","tensor(21.2957, grad_fn=<MeanBackward0>)\n","tensor(184503.4219, grad_fn=<MeanBackward0>)\n","tensor(21.2508, grad_fn=<MeanBackward0>)\n","tensor(169027.3125, grad_fn=<MeanBackward0>)\n","[ 949/1000] train_loss: 17.00119 valid_loss: 9.69716\n","Validation loss decreased (9.699553 --> 9.697159).  Saving model ...\n","tensor(19.2251, grad_fn=<MeanBackward0>)\n","tensor(172598.9688, grad_fn=<MeanBackward0>)\n","tensor(21.2009, grad_fn=<MeanBackward0>)\n","tensor(185272.2500, grad_fn=<MeanBackward0>)\n","tensor(21.3807, grad_fn=<MeanBackward0>)\n","tensor(178454.6406, grad_fn=<MeanBackward0>)\n","[ 950/1000] train_loss: 16.85774 valid_loss: 9.73668\n","EarlyStopping counter: 1 out of 20\n","tensor(21.7555, grad_fn=<MeanBackward0>)\n","tensor(192228.3750, grad_fn=<MeanBackward0>)\n","tensor(19.9220, grad_fn=<MeanBackward0>)\n","tensor(172880.7656, grad_fn=<MeanBackward0>)\n","tensor(20.4813, grad_fn=<MeanBackward0>)\n","tensor(178320.2188, grad_fn=<MeanBackward0>)\n","[ 951/1000] train_loss: 17.01183 valid_loss: 9.72276\n","EarlyStopping counter: 2 out of 20\n","tensor(20.3045, grad_fn=<MeanBackward0>)\n","tensor(180854.3125, grad_fn=<MeanBackward0>)\n","tensor(19.9523, grad_fn=<MeanBackward0>)\n","tensor(174669.8125, grad_fn=<MeanBackward0>)\n","tensor(20.0598, grad_fn=<MeanBackward0>)\n","tensor(179106.5781, grad_fn=<MeanBackward0>)\n","[ 952/1000] train_loss: 16.82012 valid_loss: 9.72002\n","EarlyStopping counter: 3 out of 20\n","tensor(21.7112, grad_fn=<MeanBackward0>)\n","tensor(170812.4219, grad_fn=<MeanBackward0>)\n","tensor(21.0479, grad_fn=<MeanBackward0>)\n","tensor(181611.0625, grad_fn=<MeanBackward0>)\n","tensor(20.1347, grad_fn=<MeanBackward0>)\n","tensor(181063.1562, grad_fn=<MeanBackward0>)\n","[ 953/1000] train_loss: 16.97904 valid_loss: 9.71080\n","EarlyStopping counter: 4 out of 20\n","tensor(19.8858, grad_fn=<MeanBackward0>)\n","tensor(169307.0781, grad_fn=<MeanBackward0>)\n","tensor(20.7735, grad_fn=<MeanBackward0>)\n","tensor(185456.2031, grad_fn=<MeanBackward0>)\n","tensor(20.8352, grad_fn=<MeanBackward0>)\n","tensor(184876.5938, grad_fn=<MeanBackward0>)\n","[ 954/1000] train_loss: 16.80667 valid_loss: 9.72031\n","EarlyStopping counter: 5 out of 20\n","tensor(19.3770, grad_fn=<MeanBackward0>)\n","tensor(179243.6875, grad_fn=<MeanBackward0>)\n","tensor(22.1310, grad_fn=<MeanBackward0>)\n","tensor(174169.5156, grad_fn=<MeanBackward0>)\n","tensor(18.6449, grad_fn=<MeanBackward0>)\n","tensor(162707.9688, grad_fn=<MeanBackward0>)\n","[ 955/1000] train_loss: 16.72873 valid_loss: 9.69568\n","Validation loss decreased (9.697159 --> 9.695683).  Saving model ...\n","tensor(19.7573, grad_fn=<MeanBackward0>)\n","tensor(171383.3906, grad_fn=<MeanBackward0>)\n","tensor(19.6416, grad_fn=<MeanBackward0>)\n","tensor(162365.9375, grad_fn=<MeanBackward0>)\n","tensor(20.5633, grad_fn=<MeanBackward0>)\n","tensor(183754.8281, grad_fn=<MeanBackward0>)\n","[ 956/1000] train_loss: 16.71410 valid_loss: 9.69810\n","EarlyStopping counter: 1 out of 20\n","tensor(19.5170, grad_fn=<MeanBackward0>)\n","tensor(195560.0469, grad_fn=<MeanBackward0>)\n","tensor(20.0635, grad_fn=<MeanBackward0>)\n","tensor(185852.2031, grad_fn=<MeanBackward0>)\n","tensor(20.5139, grad_fn=<MeanBackward0>)\n","tensor(174101.6562, grad_fn=<MeanBackward0>)\n","[ 957/1000] train_loss: 16.83737 valid_loss: 9.67622\n","Validation loss decreased (9.695683 --> 9.676221).  Saving model ...\n","tensor(21.9089, grad_fn=<MeanBackward0>)\n","tensor(192475.4531, grad_fn=<MeanBackward0>)\n","tensor(20.0888, grad_fn=<MeanBackward0>)\n","tensor(159215.7344, grad_fn=<MeanBackward0>)\n","tensor(21.0794, grad_fn=<MeanBackward0>)\n","tensor(174517.5312, grad_fn=<MeanBackward0>)\n","[ 958/1000] train_loss: 16.86486 valid_loss: 9.71135\n","EarlyStopping counter: 1 out of 20\n","tensor(21.1836, grad_fn=<MeanBackward0>)\n","tensor(176989.1094, grad_fn=<MeanBackward0>)\n","tensor(21.2750, grad_fn=<MeanBackward0>)\n","tensor(183677.8750, grad_fn=<MeanBackward0>)\n","tensor(19.4566, grad_fn=<MeanBackward0>)\n","tensor(178780.0938, grad_fn=<MeanBackward0>)\n","[ 959/1000] train_loss: 16.70331 valid_loss: 9.70474\n","EarlyStopping counter: 2 out of 20\n","tensor(18.6764, grad_fn=<MeanBackward0>)\n","tensor(179178., grad_fn=<MeanBackward0>)\n","tensor(19.3873, grad_fn=<MeanBackward0>)\n","tensor(186610.0156, grad_fn=<MeanBackward0>)\n","tensor(18.9847, grad_fn=<MeanBackward0>)\n","tensor(176874.1250, grad_fn=<MeanBackward0>)\n","[ 960/1000] train_loss: 16.87831 valid_loss: 9.69489\n","EarlyStopping counter: 3 out of 20\n","tensor(19.7396, grad_fn=<MeanBackward0>)\n","tensor(182731.4375, grad_fn=<MeanBackward0>)\n","tensor(20.0296, grad_fn=<MeanBackward0>)\n","tensor(172147.8906, grad_fn=<MeanBackward0>)\n","tensor(21.3483, grad_fn=<MeanBackward0>)\n","tensor(176959.4219, grad_fn=<MeanBackward0>)\n","[ 961/1000] train_loss: 16.72759 valid_loss: 9.70941\n","EarlyStopping counter: 4 out of 20\n","tensor(19.3949, grad_fn=<MeanBackward0>)\n","tensor(163893.3438, grad_fn=<MeanBackward0>)\n","tensor(19.9378, grad_fn=<MeanBackward0>)\n","tensor(177075.5781, grad_fn=<MeanBackward0>)\n","tensor(21.1202, grad_fn=<MeanBackward0>)\n","tensor(180639.7188, grad_fn=<MeanBackward0>)\n","[ 962/1000] train_loss: 16.76709 valid_loss: 9.69460\n","EarlyStopping counter: 5 out of 20\n","tensor(20.6605, grad_fn=<MeanBackward0>)\n","tensor(179499.2500, grad_fn=<MeanBackward0>)\n","tensor(19.8130, grad_fn=<MeanBackward0>)\n","tensor(192469.2656, grad_fn=<MeanBackward0>)\n","tensor(19.6426, grad_fn=<MeanBackward0>)\n","tensor(157352.1406, grad_fn=<MeanBackward0>)\n","[ 963/1000] train_loss: 16.77395 valid_loss: 9.64769\n","Validation loss decreased (9.676221 --> 9.647686).  Saving model ...\n","tensor(20.6016, grad_fn=<MeanBackward0>)\n","tensor(175761.7656, grad_fn=<MeanBackward0>)\n","tensor(20.0023, grad_fn=<MeanBackward0>)\n","tensor(173845.6875, grad_fn=<MeanBackward0>)\n","tensor(22.0035, grad_fn=<MeanBackward0>)\n","tensor(170858.3594, grad_fn=<MeanBackward0>)\n","[ 964/1000] train_loss: 16.83555 valid_loss: 9.66352\n","EarlyStopping counter: 1 out of 20\n","tensor(20.4049, grad_fn=<MeanBackward0>)\n","tensor(181975.2344, grad_fn=<MeanBackward0>)\n","tensor(21.8825, grad_fn=<MeanBackward0>)\n","tensor(184962.3750, grad_fn=<MeanBackward0>)\n","tensor(21.6026, grad_fn=<MeanBackward0>)\n","tensor(170935.1562, grad_fn=<MeanBackward0>)\n","[ 965/1000] train_loss: 16.93528 valid_loss: 9.69484\n","EarlyStopping counter: 2 out of 20\n","tensor(20.9477, grad_fn=<MeanBackward0>)\n","tensor(179021.4844, grad_fn=<MeanBackward0>)\n","tensor(21.1556, grad_fn=<MeanBackward0>)\n","tensor(166877.8594, grad_fn=<MeanBackward0>)\n","tensor(20.4828, grad_fn=<MeanBackward0>)\n","tensor(175680.3594, grad_fn=<MeanBackward0>)\n","[ 966/1000] train_loss: 16.64308 valid_loss: 9.66785\n","EarlyStopping counter: 3 out of 20\n","tensor(20.8305, grad_fn=<MeanBackward0>)\n","tensor(183228., grad_fn=<MeanBackward0>)\n","tensor(20.2250, grad_fn=<MeanBackward0>)\n","tensor(161910.0781, grad_fn=<MeanBackward0>)\n","tensor(20.7461, grad_fn=<MeanBackward0>)\n","tensor(182025.1719, grad_fn=<MeanBackward0>)\n","[ 967/1000] train_loss: 16.80530 valid_loss: 9.63786\n","Validation loss decreased (9.647686 --> 9.637857).  Saving model ...\n","tensor(21.6342, grad_fn=<MeanBackward0>)\n","tensor(175503., grad_fn=<MeanBackward0>)\n","tensor(21.1157, grad_fn=<MeanBackward0>)\n","tensor(173992.3594, grad_fn=<MeanBackward0>)\n","tensor(19.4754, grad_fn=<MeanBackward0>)\n","tensor(179914.4375, grad_fn=<MeanBackward0>)\n","[ 968/1000] train_loss: 16.67008 valid_loss: 9.64019\n","EarlyStopping counter: 1 out of 20\n","tensor(18.9521, grad_fn=<MeanBackward0>)\n","tensor(172753.9531, grad_fn=<MeanBackward0>)\n","tensor(19.7232, grad_fn=<MeanBackward0>)\n","tensor(186968.8750, grad_fn=<MeanBackward0>)\n","tensor(18.4140, grad_fn=<MeanBackward0>)\n","tensor(172859.1406, grad_fn=<MeanBackward0>)\n","[ 969/1000] train_loss: 16.67349 valid_loss: 9.62789\n","Validation loss decreased (9.637857 --> 9.627888).  Saving model ...\n","tensor(20.2748, grad_fn=<MeanBackward0>)\n","tensor(173656.7969, grad_fn=<MeanBackward0>)\n","tensor(18.8519, grad_fn=<MeanBackward0>)\n","tensor(175994.7500, grad_fn=<MeanBackward0>)\n","tensor(19.3683, grad_fn=<MeanBackward0>)\n","tensor(169103.7500, grad_fn=<MeanBackward0>)\n","[ 970/1000] train_loss: 16.61859 valid_loss: 9.63311\n","EarlyStopping counter: 1 out of 20\n","tensor(21.4980, grad_fn=<MeanBackward0>)\n","tensor(180599.1094, grad_fn=<MeanBackward0>)\n","tensor(21.0304, grad_fn=<MeanBackward0>)\n","tensor(184209.2656, grad_fn=<MeanBackward0>)\n","tensor(20.3382, grad_fn=<MeanBackward0>)\n","tensor(172943.2344, grad_fn=<MeanBackward0>)\n","[ 971/1000] train_loss: 16.75597 valid_loss: 9.60825\n","Validation loss decreased (9.627888 --> 9.608250).  Saving model ...\n","tensor(18.4181, grad_fn=<MeanBackward0>)\n","tensor(168397.8438, grad_fn=<MeanBackward0>)\n","tensor(19.8116, grad_fn=<MeanBackward0>)\n","tensor(175526.0781, grad_fn=<MeanBackward0>)\n","tensor(19.4303, grad_fn=<MeanBackward0>)\n","tensor(169586.4219, grad_fn=<MeanBackward0>)\n","[ 972/1000] train_loss: 16.58029 valid_loss: 9.61147\n","EarlyStopping counter: 1 out of 20\n","tensor(21.8113, grad_fn=<MeanBackward0>)\n","tensor(172450.1250, grad_fn=<MeanBackward0>)\n","tensor(20.5609, grad_fn=<MeanBackward0>)\n","tensor(167851.8906, grad_fn=<MeanBackward0>)\n","tensor(20.1163, grad_fn=<MeanBackward0>)\n","tensor(172664.3750, grad_fn=<MeanBackward0>)\n","[ 973/1000] train_loss: 16.56177 valid_loss: 9.61483\n","EarlyStopping counter: 2 out of 20\n","tensor(21.3881, grad_fn=<MeanBackward0>)\n","tensor(200184.4844, grad_fn=<MeanBackward0>)\n","tensor(19.6864, grad_fn=<MeanBackward0>)\n","tensor(162796.5469, grad_fn=<MeanBackward0>)\n","tensor(19.4738, grad_fn=<MeanBackward0>)\n","tensor(168010.4375, grad_fn=<MeanBackward0>)\n","[ 974/1000] train_loss: 16.56040 valid_loss: 9.62873\n","EarlyStopping counter: 3 out of 20\n","tensor(19.4193, grad_fn=<MeanBackward0>)\n","tensor(183969.2969, grad_fn=<MeanBackward0>)\n","tensor(21.8897, grad_fn=<MeanBackward0>)\n","tensor(184628.3125, grad_fn=<MeanBackward0>)\n","tensor(19.2882, grad_fn=<MeanBackward0>)\n","tensor(158424.8438, grad_fn=<MeanBackward0>)\n","[ 975/1000] train_loss: 16.58947 valid_loss: 9.59100\n","Validation loss decreased (9.608250 --> 9.591002).  Saving model ...\n","tensor(19.8983, grad_fn=<MeanBackward0>)\n","tensor(166285.9688, grad_fn=<MeanBackward0>)\n","tensor(21.8894, grad_fn=<MeanBackward0>)\n","tensor(183366.7969, grad_fn=<MeanBackward0>)\n","tensor(22.1033, grad_fn=<MeanBackward0>)\n","tensor(168725.4688, grad_fn=<MeanBackward0>)\n","[ 976/1000] train_loss: 16.69307 valid_loss: 9.59469\n","EarlyStopping counter: 1 out of 20\n","tensor(19.0477, grad_fn=<MeanBackward0>)\n","tensor(163275.1094, grad_fn=<MeanBackward0>)\n","tensor(21.0392, grad_fn=<MeanBackward0>)\n","tensor(186618.4375, grad_fn=<MeanBackward0>)\n","tensor(19.6341, grad_fn=<MeanBackward0>)\n","tensor(159976.7656, grad_fn=<MeanBackward0>)\n","[ 977/1000] train_loss: 16.79949 valid_loss: 9.64157\n","EarlyStopping counter: 2 out of 20\n","tensor(19.5639, grad_fn=<MeanBackward0>)\n","tensor(183245.7969, grad_fn=<MeanBackward0>)\n","tensor(20.6110, grad_fn=<MeanBackward0>)\n","tensor(176115., grad_fn=<MeanBackward0>)\n","tensor(20.2589, grad_fn=<MeanBackward0>)\n","tensor(186013.9219, grad_fn=<MeanBackward0>)\n","[ 978/1000] train_loss: 16.62189 valid_loss: 9.64116\n","EarlyStopping counter: 3 out of 20\n","tensor(19.7641, grad_fn=<MeanBackward0>)\n","tensor(168139.0156, grad_fn=<MeanBackward0>)\n","tensor(20.4175, grad_fn=<MeanBackward0>)\n","tensor(190114.7344, grad_fn=<MeanBackward0>)\n","tensor(19.0664, grad_fn=<MeanBackward0>)\n","tensor(159841.6875, grad_fn=<MeanBackward0>)\n","[ 979/1000] train_loss: 16.62462 valid_loss: 9.64506\n","EarlyStopping counter: 4 out of 20\n","tensor(17.8858, grad_fn=<MeanBackward0>)\n","tensor(178925.0625, grad_fn=<MeanBackward0>)\n","tensor(19.2168, grad_fn=<MeanBackward0>)\n","tensor(182410.3281, grad_fn=<MeanBackward0>)\n","tensor(19.7162, grad_fn=<MeanBackward0>)\n","tensor(168979.3594, grad_fn=<MeanBackward0>)\n","[ 980/1000] train_loss: 16.57160 valid_loss: 9.60607\n","EarlyStopping counter: 5 out of 20\n","tensor(19.2835, grad_fn=<MeanBackward0>)\n","tensor(171385.4844, grad_fn=<MeanBackward0>)\n","tensor(20.1617, grad_fn=<MeanBackward0>)\n","tensor(158486.6094, grad_fn=<MeanBackward0>)\n","tensor(19.2482, grad_fn=<MeanBackward0>)\n","tensor(169464.8125, grad_fn=<MeanBackward0>)\n","[ 981/1000] train_loss: 16.46684 valid_loss: 9.58275\n","Validation loss decreased (9.591002 --> 9.582750).  Saving model ...\n","tensor(19.3038, grad_fn=<MeanBackward0>)\n","tensor(158058.3281, grad_fn=<MeanBackward0>)\n","tensor(20.0272, grad_fn=<MeanBackward0>)\n","tensor(185446.5469, grad_fn=<MeanBackward0>)\n","tensor(21.0212, grad_fn=<MeanBackward0>)\n","tensor(173688., grad_fn=<MeanBackward0>)\n","[ 982/1000] train_loss: 16.54098 valid_loss: 9.56677\n","Validation loss decreased (9.582750 --> 9.566769).  Saving model ...\n","tensor(21.0905, grad_fn=<MeanBackward0>)\n","tensor(158825.3906, grad_fn=<MeanBackward0>)\n","tensor(21.5708, grad_fn=<MeanBackward0>)\n","tensor(164085.7812, grad_fn=<MeanBackward0>)\n","tensor(20.7640, grad_fn=<MeanBackward0>)\n","tensor(169432.5781, grad_fn=<MeanBackward0>)\n","[ 983/1000] train_loss: 16.56368 valid_loss: 9.64994\n","EarlyStopping counter: 1 out of 20\n","tensor(20.7079, grad_fn=<MeanBackward0>)\n","tensor(167176.0312, grad_fn=<MeanBackward0>)\n","tensor(20.5518, grad_fn=<MeanBackward0>)\n","tensor(178215.0469, grad_fn=<MeanBackward0>)\n","tensor(19.4823, grad_fn=<MeanBackward0>)\n","tensor(182751.6562, grad_fn=<MeanBackward0>)\n","[ 984/1000] train_loss: 16.60355 valid_loss: 9.62878\n","EarlyStopping counter: 2 out of 20\n","tensor(18.9939, grad_fn=<MeanBackward0>)\n","tensor(164878.5156, grad_fn=<MeanBackward0>)\n","tensor(20.3317, grad_fn=<MeanBackward0>)\n","tensor(197844.5156, grad_fn=<MeanBackward0>)\n","tensor(20.7641, grad_fn=<MeanBackward0>)\n","tensor(157925.9375, grad_fn=<MeanBackward0>)\n","[ 985/1000] train_loss: 16.44382 valid_loss: 9.63562\n","EarlyStopping counter: 3 out of 20\n","tensor(18.5166, grad_fn=<MeanBackward0>)\n","tensor(169923.5156, grad_fn=<MeanBackward0>)\n","tensor(19.5134, grad_fn=<MeanBackward0>)\n","tensor(169765.8750, grad_fn=<MeanBackward0>)\n","tensor(20.1217, grad_fn=<MeanBackward0>)\n","tensor(167014.4375, grad_fn=<MeanBackward0>)\n","[ 986/1000] train_loss: 16.52044 valid_loss: 9.67347\n","EarlyStopping counter: 4 out of 20\n","tensor(21.5943, grad_fn=<MeanBackward0>)\n","tensor(174710.9219, grad_fn=<MeanBackward0>)\n","tensor(19.5187, grad_fn=<MeanBackward0>)\n","tensor(172762.1094, grad_fn=<MeanBackward0>)\n","tensor(18.8606, grad_fn=<MeanBackward0>)\n","tensor(163478.5469, grad_fn=<MeanBackward0>)\n","[ 987/1000] train_loss: 16.57456 valid_loss: 9.63897\n","EarlyStopping counter: 5 out of 20\n","tensor(17.9796, grad_fn=<MeanBackward0>)\n","tensor(161364.4375, grad_fn=<MeanBackward0>)\n","tensor(20.9362, grad_fn=<MeanBackward0>)\n","tensor(178689.3906, grad_fn=<MeanBackward0>)\n","tensor(20.2025, grad_fn=<MeanBackward0>)\n","tensor(166652.4844, grad_fn=<MeanBackward0>)\n","[ 988/1000] train_loss: 16.58986 valid_loss: 9.62689\n","EarlyStopping counter: 6 out of 20\n","tensor(19.5249, grad_fn=<MeanBackward0>)\n","tensor(174145.6875, grad_fn=<MeanBackward0>)\n","tensor(19.2605, grad_fn=<MeanBackward0>)\n","tensor(169571., grad_fn=<MeanBackward0>)\n","tensor(20.0547, grad_fn=<MeanBackward0>)\n","tensor(170270.8750, grad_fn=<MeanBackward0>)\n","[ 989/1000] train_loss: 16.44913 valid_loss: 9.59832\n","EarlyStopping counter: 7 out of 20\n","tensor(21.0394, grad_fn=<MeanBackward0>)\n","tensor(172675.6562, grad_fn=<MeanBackward0>)\n","tensor(20.6141, grad_fn=<MeanBackward0>)\n","tensor(166363.4844, grad_fn=<MeanBackward0>)\n","tensor(19.6510, grad_fn=<MeanBackward0>)\n","tensor(178803.5781, grad_fn=<MeanBackward0>)\n","[ 990/1000] train_loss: 16.72764 valid_loss: 9.58328\n","EarlyStopping counter: 8 out of 20\n","tensor(20.2674, grad_fn=<MeanBackward0>)\n","tensor(166932.9531, grad_fn=<MeanBackward0>)\n","tensor(20.5160, grad_fn=<MeanBackward0>)\n","tensor(162265.1719, grad_fn=<MeanBackward0>)\n","tensor(21.8933, grad_fn=<MeanBackward0>)\n","tensor(183477.1406, grad_fn=<MeanBackward0>)\n","[ 991/1000] train_loss: 16.46161 valid_loss: 9.58338\n","EarlyStopping counter: 9 out of 20\n","tensor(19.8216, grad_fn=<MeanBackward0>)\n","tensor(174791.1406, grad_fn=<MeanBackward0>)\n","tensor(21.0548, grad_fn=<MeanBackward0>)\n","tensor(187918.4375, grad_fn=<MeanBackward0>)\n","tensor(18.0309, grad_fn=<MeanBackward0>)\n","tensor(161477.3594, grad_fn=<MeanBackward0>)\n","[ 992/1000] train_loss: 16.43062 valid_loss: 9.56683\n","EarlyStopping counter: 10 out of 20\n","tensor(19.0872, grad_fn=<MeanBackward0>)\n","tensor(169673.2500, grad_fn=<MeanBackward0>)\n","tensor(19.6220, grad_fn=<MeanBackward0>)\n","tensor(173444.1406, grad_fn=<MeanBackward0>)\n","tensor(20.5393, grad_fn=<MeanBackward0>)\n","tensor(166353.5156, grad_fn=<MeanBackward0>)\n","[ 993/1000] train_loss: 16.61121 valid_loss: 9.56284\n","Validation loss decreased (9.566769 --> 9.562842).  Saving model ...\n","tensor(19.3696, grad_fn=<MeanBackward0>)\n","tensor(165587.1406, grad_fn=<MeanBackward0>)\n","tensor(20.8014, grad_fn=<MeanBackward0>)\n","tensor(164556.1875, grad_fn=<MeanBackward0>)\n","tensor(19.9475, grad_fn=<MeanBackward0>)\n","tensor(170402.8281, grad_fn=<MeanBackward0>)\n","[ 994/1000] train_loss: 16.45564 valid_loss: 9.56310\n","EarlyStopping counter: 1 out of 20\n","tensor(20.5257, grad_fn=<MeanBackward0>)\n","tensor(170776.2812, grad_fn=<MeanBackward0>)\n","tensor(20.6538, grad_fn=<MeanBackward0>)\n","tensor(177359.5000, grad_fn=<MeanBackward0>)\n","tensor(18.3266, grad_fn=<MeanBackward0>)\n","tensor(166709.2812, grad_fn=<MeanBackward0>)\n","[ 995/1000] train_loss: 16.57959 valid_loss: 9.58932\n","EarlyStopping counter: 2 out of 20\n","tensor(19.0360, grad_fn=<MeanBackward0>)\n","tensor(164766.2969, grad_fn=<MeanBackward0>)\n","tensor(19.1978, grad_fn=<MeanBackward0>)\n","tensor(177652.5000, grad_fn=<MeanBackward0>)\n","tensor(18.6262, grad_fn=<MeanBackward0>)\n","tensor(177270.5781, grad_fn=<MeanBackward0>)\n","[ 996/1000] train_loss: 16.46126 valid_loss: 9.57183\n","EarlyStopping counter: 3 out of 20\n","tensor(20.9875, grad_fn=<MeanBackward0>)\n","tensor(168201.5781, grad_fn=<MeanBackward0>)\n","tensor(20.8316, grad_fn=<MeanBackward0>)\n","tensor(177487.1094, grad_fn=<MeanBackward0>)\n","tensor(18.1042, grad_fn=<MeanBackward0>)\n","tensor(169296.1719, grad_fn=<MeanBackward0>)\n","[ 997/1000] train_loss: 16.57257 valid_loss: 9.56031\n","Validation loss decreased (9.562842 --> 9.560312).  Saving model ...\n","tensor(18.5968, grad_fn=<MeanBackward0>)\n","tensor(166758.9062, grad_fn=<MeanBackward0>)\n","tensor(18.6716, grad_fn=<MeanBackward0>)\n","tensor(157512.6094, grad_fn=<MeanBackward0>)\n","tensor(22.1744, grad_fn=<MeanBackward0>)\n","tensor(170620.0156, grad_fn=<MeanBackward0>)\n","[ 998/1000] train_loss: 16.41186 valid_loss: 9.57980\n","EarlyStopping counter: 1 out of 20\n","tensor(19.5028, grad_fn=<MeanBackward0>)\n","tensor(166030.8125, grad_fn=<MeanBackward0>)\n","tensor(22.2164, grad_fn=<MeanBackward0>)\n","tensor(167120.8281, grad_fn=<MeanBackward0>)\n","tensor(21.9319, grad_fn=<MeanBackward0>)\n","tensor(167919.7031, grad_fn=<MeanBackward0>)\n","[ 999/1000] train_loss: 16.62719 valid_loss: 9.59655\n","EarlyStopping counter: 2 out of 20\n","tensor(22.3741, grad_fn=<MeanBackward0>)\n","tensor(175296.8750, grad_fn=<MeanBackward0>)\n","tensor(17.3031, grad_fn=<MeanBackward0>)\n","tensor(179385.4844, grad_fn=<MeanBackward0>)\n","tensor(18.3890, grad_fn=<MeanBackward0>)\n","tensor(165395.0312, grad_fn=<MeanBackward0>)\n","[1000/1000] train_loss: 16.33679 valid_loss: 9.57618\n","EarlyStopping counter: 3 out of 20\n"]}],"source":["# define the structure of the Recurrent Neural Network model\n","\n","model_PINN = RNN(4, 2, 32, 3)\n","model_PINN.to(device)\n","\n","print(model_PINN)\n","\n","optimizer = torch.optim.Adam(model_PINN.parameters(),lr=1e-3)\n","\n","std_physics = torch.from_numpy(np.array([std_CA_input, std_T_input])).float()\n","mean_physics = torch.from_numpy(np.array([mean_CA_input, mean_T_input])).float()\n","\n","n_epochs = 1000 #1500\n","\n","# early stopping patience; how long to wait after last time validation loss improved.\n","patience = 20\n","\n","model, train_loss, valid_loss = train_model(model_PINN, patience, n_epochs)"]},{"cell_type":"markdown","id":"945bec05","metadata":{"id":"945bec05"},"source":["# Save model"]},{"cell_type":"code","execution_count":null,"id":"cc0c530c","metadata":{"id":"cc0c530c","outputId":"d448e74c-7c33-4f29-9c2a-935bd8141892"},"outputs":[{"name":"stdout","output_type":"stream","text":["1 out of 560\n","2 out of 560\n","3 out of 560\n","4 out of 560\n","5 out of 560\n","6 out of 560\n","7 out of 560\n","8 out of 560\n","9 out of 560\n","10 out of 560\n","11 out of 560\n","12 out of 560\n","13 out of 560\n","14 out of 560\n","15 out of 560\n","16 out of 560\n","17 out of 560\n","18 out of 560\n","19 out of 560\n","20 out of 560\n","21 out of 560\n","22 out of 560\n","23 out of 560\n","24 out of 560\n","25 out of 560\n","26 out of 560\n","27 out of 560\n","28 out of 560\n","29 out of 560\n","30 out of 560\n","31 out of 560\n","32 out of 560\n","33 out of 560\n","34 out of 560\n","35 out of 560\n","36 out of 560\n","37 out of 560\n","38 out of 560\n","39 out of 560\n","40 out of 560\n","41 out of 560\n","42 out of 560\n","43 out of 560\n","44 out of 560\n","45 out of 560\n","46 out of 560\n","47 out of 560\n","48 out of 560\n","49 out of 560\n","50 out of 560\n","51 out of 560\n","52 out of 560\n","53 out of 560\n","54 out of 560\n","55 out of 560\n","56 out of 560\n","57 out of 560\n","58 out of 560\n","59 out of 560\n","60 out of 560\n","61 out of 560\n","62 out of 560\n","63 out of 560\n","64 out of 560\n","65 out of 560\n","66 out of 560\n","67 out of 560\n","68 out of 560\n","69 out of 560\n","70 out of 560\n","71 out of 560\n","72 out of 560\n","73 out of 560\n","74 out of 560\n","75 out of 560\n","76 out of 560\n","77 out of 560\n","78 out of 560\n","79 out of 560\n","80 out of 560\n","81 out of 560\n","82 out of 560\n","83 out of 560\n","84 out of 560\n","85 out of 560\n","86 out of 560\n","87 out of 560\n","88 out of 560\n","89 out of 560\n","90 out of 560\n","91 out of 560\n","92 out of 560\n","93 out of 560\n","94 out of 560\n","95 out of 560\n","96 out of 560\n","97 out of 560\n","98 out of 560\n","99 out of 560\n","100 out of 560\n","101 out of 560\n","102 out of 560\n","103 out of 560\n","104 out of 560\n","105 out of 560\n","106 out of 560\n","107 out of 560\n","108 out of 560\n","109 out of 560\n","110 out of 560\n","111 out of 560\n","112 out of 560\n","113 out of 560\n","114 out of 560\n","115 out of 560\n","116 out of 560\n","117 out of 560\n","118 out of 560\n","119 out of 560\n","120 out of 560\n","121 out of 560\n","122 out of 560\n","123 out of 560\n","124 out of 560\n","125 out of 560\n","126 out of 560\n","127 out of 560\n","128 out of 560\n","129 out of 560\n","130 out of 560\n","131 out of 560\n","132 out of 560\n","133 out of 560\n","134 out of 560\n","135 out of 560\n","136 out of 560\n","137 out of 560\n","138 out of 560\n","139 out of 560\n","140 out of 560\n","141 out of 560\n","142 out of 560\n","143 out of 560\n","144 out of 560\n","145 out of 560\n","146 out of 560\n","147 out of 560\n","148 out of 560\n","149 out of 560\n","150 out of 560\n","151 out of 560\n","152 out of 560\n","153 out of 560\n","154 out of 560\n","155 out of 560\n","156 out of 560\n","157 out of 560\n","158 out of 560\n","159 out of 560\n","160 out of 560\n","161 out of 560\n","162 out of 560\n","163 out of 560\n","164 out of 560\n","165 out of 560\n","166 out of 560\n","167 out of 560\n","168 out of 560\n","169 out of 560\n","170 out of 560\n","171 out of 560\n","172 out of 560\n","173 out of 560\n","174 out of 560\n","175 out of 560\n","176 out of 560\n","177 out of 560\n","178 out of 560\n","179 out of 560\n","180 out of 560\n","181 out of 560\n","182 out of 560\n","183 out of 560\n","184 out of 560\n","185 out of 560\n","186 out of 560\n","187 out of 560\n","188 out of 560\n","189 out of 560\n","190 out of 560\n","191 out of 560\n","192 out of 560\n","193 out of 560\n","194 out of 560\n","195 out of 560\n","196 out of 560\n","197 out of 560\n","198 out of 560\n","199 out of 560\n","200 out of 560\n","201 out of 560\n","202 out of 560\n","203 out of 560\n","204 out of 560\n","205 out of 560\n","206 out of 560\n","207 out of 560\n","208 out of 560\n","209 out of 560\n","210 out of 560\n","211 out of 560\n","212 out of 560\n","213 out of 560\n","214 out of 560\n","215 out of 560\n","216 out of 560\n","217 out of 560\n","218 out of 560\n","219 out of 560\n","220 out of 560\n","221 out of 560\n","222 out of 560\n","223 out of 560\n","224 out of 560\n","225 out of 560\n","226 out of 560\n","227 out of 560\n","228 out of 560\n","229 out of 560\n","230 out of 560\n","231 out of 560\n","232 out of 560\n","233 out of 560\n","234 out of 560\n","235 out of 560\n","236 out of 560\n","237 out of 560\n","238 out of 560\n","239 out of 560\n","240 out of 560\n","241 out of 560\n","242 out of 560\n","243 out of 560\n","244 out of 560\n","245 out of 560\n","246 out of 560\n","247 out of 560\n","248 out of 560\n","249 out of 560\n","250 out of 560\n","251 out of 560\n","252 out of 560\n","253 out of 560\n","254 out of 560\n","255 out of 560\n","256 out of 560\n","257 out of 560\n","258 out of 560\n","259 out of 560\n","260 out of 560\n","261 out of 560\n","262 out of 560\n","263 out of 560\n","264 out of 560\n","265 out of 560\n","266 out of 560\n","267 out of 560\n","268 out of 560\n","269 out of 560\n","270 out of 560\n","271 out of 560\n","272 out of 560\n","273 out of 560\n","274 out of 560\n","275 out of 560\n","276 out of 560\n","277 out of 560\n","278 out of 560\n","279 out of 560\n","280 out of 560\n","281 out of 560\n","282 out of 560\n","283 out of 560\n","284 out of 560\n","285 out of 560\n","286 out of 560\n","287 out of 560\n","288 out of 560\n","289 out of 560\n","290 out of 560\n","291 out of 560\n","292 out of 560\n","293 out of 560\n","294 out of 560\n","295 out of 560\n","296 out of 560\n","297 out of 560\n","298 out of 560\n","299 out of 560\n","300 out of 560\n","301 out of 560\n","302 out of 560\n","303 out of 560\n","304 out of 560\n","305 out of 560\n","306 out of 560\n","307 out of 560\n","308 out of 560\n","309 out of 560\n","310 out of 560\n","311 out of 560\n","312 out of 560\n","313 out of 560\n","314 out of 560\n","315 out of 560\n","316 out of 560\n","317 out of 560\n","318 out of 560\n","319 out of 560\n","320 out of 560\n","321 out of 560\n","322 out of 560\n","323 out of 560\n","324 out of 560\n","325 out of 560\n","326 out of 560\n","327 out of 560\n","328 out of 560\n","329 out of 560\n","330 out of 560\n","331 out of 560\n","332 out of 560\n","333 out of 560\n","334 out of 560\n","335 out of 560\n","336 out of 560\n","337 out of 560\n","338 out of 560\n","339 out of 560\n","340 out of 560\n","341 out of 560\n","342 out of 560\n","343 out of 560\n","344 out of 560\n","345 out of 560\n","346 out of 560\n","347 out of 560\n","348 out of 560\n","349 out of 560\n","350 out of 560\n","351 out of 560\n","352 out of 560\n","353 out of 560\n","354 out of 560\n","355 out of 560\n","356 out of 560\n","357 out of 560\n","358 out of 560\n","359 out of 560\n","360 out of 560\n","361 out of 560\n","362 out of 560\n","363 out of 560\n","364 out of 560\n","365 out of 560\n","366 out of 560\n","367 out of 560\n","368 out of 560\n","369 out of 560\n","370 out of 560\n","371 out of 560\n","372 out of 560\n","373 out of 560\n","374 out of 560\n","375 out of 560\n","376 out of 560\n","377 out of 560\n","378 out of 560\n","379 out of 560\n","380 out of 560\n","381 out of 560\n","382 out of 560\n","383 out of 560\n","384 out of 560\n","385 out of 560\n","386 out of 560\n","387 out of 560\n","388 out of 560\n","389 out of 560\n","390 out of 560\n","391 out of 560\n","392 out of 560\n","393 out of 560\n","394 out of 560\n","395 out of 560\n","396 out of 560\n","397 out of 560\n","398 out of 560\n","399 out of 560\n","400 out of 560\n","401 out of 560\n","402 out of 560\n","403 out of 560\n","404 out of 560\n","405 out of 560\n","406 out of 560\n","407 out of 560\n","408 out of 560\n","409 out of 560\n","410 out of 560\n","411 out of 560\n","412 out of 560\n","413 out of 560\n","414 out of 560\n","415 out of 560\n","416 out of 560\n","417 out of 560\n","418 out of 560\n","419 out of 560\n","420 out of 560\n","421 out of 560\n","422 out of 560\n","423 out of 560\n","424 out of 560\n","425 out of 560\n","426 out of 560\n","427 out of 560\n","428 out of 560\n","429 out of 560\n","430 out of 560\n","431 out of 560\n","432 out of 560\n","433 out of 560\n","434 out of 560\n","435 out of 560\n","436 out of 560\n","437 out of 560\n","438 out of 560\n","439 out of 560\n","440 out of 560\n","441 out of 560\n","442 out of 560\n","443 out of 560\n","444 out of 560\n","445 out of 560\n","446 out of 560\n","447 out of 560\n","448 out of 560\n","449 out of 560\n","450 out of 560\n","451 out of 560\n","452 out of 560\n","453 out of 560\n","454 out of 560\n","455 out of 560\n","456 out of 560\n","457 out of 560\n","458 out of 560\n","459 out of 560\n","460 out of 560\n","461 out of 560\n","462 out of 560\n","463 out of 560\n","464 out of 560\n","465 out of 560\n","466 out of 560\n","467 out of 560\n","468 out of 560\n","469 out of 560\n","470 out of 560\n","471 out of 560\n","472 out of 560\n","473 out of 560\n","474 out of 560\n","475 out of 560\n","476 out of 560\n","477 out of 560\n","478 out of 560\n","479 out of 560\n","480 out of 560\n","481 out of 560\n","482 out of 560\n","483 out of 560\n","484 out of 560\n","485 out of 560\n","486 out of 560\n","487 out of 560\n","488 out of 560\n","489 out of 560\n","490 out of 560\n","491 out of 560\n","492 out of 560\n","493 out of 560\n","494 out of 560\n","495 out of 560\n","496 out of 560\n","497 out of 560\n","498 out of 560\n","499 out of 560\n","500 out of 560\n","501 out of 560\n","502 out of 560\n","503 out of 560\n","504 out of 560\n","505 out of 560\n","506 out of 560\n","507 out of 560\n","508 out of 560\n","509 out of 560\n","510 out of 560\n","511 out of 560\n","512 out of 560\n","513 out of 560\n","514 out of 560\n","515 out of 560\n","516 out of 560\n","517 out of 560\n","518 out of 560\n","519 out of 560\n","520 out of 560\n","521 out of 560\n","522 out of 560\n","523 out of 560\n","524 out of 560\n","525 out of 560\n","526 out of 560\n","527 out of 560\n","528 out of 560\n","529 out of 560\n","530 out of 560\n","531 out of 560\n","532 out of 560\n","533 out of 560\n","534 out of 560\n","535 out of 560\n","536 out of 560\n","537 out of 560\n","538 out of 560\n","539 out of 560\n","540 out of 560\n","541 out of 560\n","542 out of 560\n","543 out of 560\n","544 out of 560\n","545 out of 560\n","546 out of 560\n","547 out of 560\n","548 out of 560\n","549 out of 560\n","550 out of 560\n","551 out of 560\n","552 out of 560\n","553 out of 560\n","554 out of 560\n","555 out of 560\n","556 out of 560\n","557 out of 560\n","558 out of 560\n","559 out of 560\n","560 out of 560\n"]}],"source":["y_test_error = list()\n","total_batch_num = y_test.shape[0]\n","\n","for batch_num, x_batch_test in enumerate(dataloader_physics_test, 1):\n","    print(f\"{batch_num} out of {total_batch_num}\")\n","    model.eval()\n","    model.to(\"cpu\")\n","\n","    # forward pass: compute predicted outputs by passing inputs to the model\n","    x_batch_test = x_batch_test[0]\n","    NN_output = model(x_batch_test)\n","\n","    loss1 = torch.mean((NN_output[:, 0, :] - x_batch_test[:, 0, -2:])**2)  # use mean squared error\n","\n","    # compute the \"physics loss\"\n","    C_A0 = x_batch_test[:, :, 0] * std_CA0 + mean_CA0 + C_A0s\n","    Q = x_batch_test[:, :, 1] * std_Q + mean_Q + Q_s\n","\n","    NN_output = NN_output * std_y.to('cpu') + mean_y.to('cpu') + torch.from_numpy(np.array([C_As, T_s])).float().to('cpu')\n","\n","    dCA_first = (NN_output[:, 1:2, 0] - NN_output[:, 0:1, 0]) / (t_step)\n","    dT_first = (NN_output[:, 1:2, 1] - NN_output[:, 0:1, 1]) / (t_step)\n","\n","    dCA_center = (NN_output[:, 2:, 0] - NN_output[:, :-2, 0]) / (2 * t_step)\n","    dT_center = (NN_output[:, 2:, 1] - NN_output[:, :-2, 1]) / (2 * t_step)\n","\n","    dCA_last = (NN_output[:, -1:, 0] - NN_output[:, -2:-1, 0]) / (t_step)\n","    dT_last = (NN_output[:, -1:, 1] - NN_output[:, -2:-1, 1]) / (t_step)\n","\n","\n","    dCA = torch.cat((dCA_first, dCA_center, dCA_last), 1)\n","    dT = torch.cat((dT_first, dT_center, dT_last), 1)\n","\n","\n","    # Physics-based Concentration loss\n","    loss3 = dCA - F / V * (C_A0 - NN_output[:, :, 0]) + k_0 * torch.exp(-E / (R * NN_output[:, :, 1])) * NN_output[:, :, 0]**2\n","    loss3 = torch.mean(loss3**2)\n","\n","    # Physics-based Temperature loss\n","    loss4 = dT - F / V * (T_0 - NN_output[:, :, 1]) + delta_H / (rho_L * C_p) * k_0 * torch.exp(-E / (R * NN_output[:, :, 1])) * NN_output[:, :, 0]**2 - Q / (rho_L * C_p * V)\n","    loss4 = torch.mean(loss4**2)\n","\n","    # backpropagate joint loss using appropriate scaling factor\n","    loss = 1e3 * loss1 + 1e-1 * loss3 + 1e-5 * loss4 # add all loss terms together\n","\n","    # record validation loss\n","    y_test_error.append(loss.item())"]},{"cell_type":"code","execution_count":null,"id":"4f2cad3e","metadata":{"id":"4f2cad3e","outputId":"077b93ba-fa4f-4037-c36e-10f4077bbc9d"},"outputs":[{"name":"stdout","output_type":"stream","text":["mean error is 1.709591373920973, std is 2.684643091688111\n"]}],"source":["# Evaluation of the Test dataset\n","\n","print(f\"mean error is {np.mean(y_test_error)}, std is {np.std(y_test_error)}\")"]},{"cell_type":"code","execution_count":null,"id":"9d7d8bda","metadata":{"id":"9d7d8bda","outputId":"60cb4a7c-91e1-48e3-f6cd-47aea3d9e3b6"},"outputs":[{"data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7fbe1a707a00>,\n"," <matplotlib.lines.Line2D at 0x7fbe1a7079d0>,\n"," <matplotlib.lines.Line2D at 0x7fbe1a7078b0>,\n"," <matplotlib.lines.Line2D at 0x7fbe1a707790>,\n"," <matplotlib.lines.Line2D at 0x7fbe1a707670>,\n"," <matplotlib.lines.Line2D at 0x7fbe1a707550>]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# Data visualization between Test and Predicted data for the time-series data of a few sample datapoints\n","\n","y_pred1 = model(X_physics_test)\n","\n","\n","# Reversing standardization\n","y_pred1 = y_pred1 * std_y.to('cpu') + mean_y.to('cpu')\n","\n","y_pred1 = y_pred1.detach().numpy()\n","\n","plt.plot(y_pred1[0:50:5, :, 0], y_pred1[0:50:5, :, 1], color='blue', ls='--')\n","plt.plot(y_test[0:50:5, :, 0], y_test[0:50:5, :, 1], color='cyan')"]},{"cell_type":"code","execution_count":null,"id":"42fcd1a3","metadata":{"id":"42fcd1a3"},"outputs":[],"source":["model_PINN.eval()\n","model_PINN.to('cpu')\n","y_predict_test = model_PINN(X_physics_test[:1000, :, :]).detach().numpy()\n","y_predict_test = y_predict_test * (std_y).detach().numpy() + (mean_y).detach().numpy()\n","y_test = y_physics_test[:1000, :, :] * (std_y).detach().numpy() + (mean_y).detach().numpy()"]},{"cell_type":"code","execution_count":null,"id":"d04fc967","metadata":{"id":"d04fc967","outputId":"b6ec3756-32ff-47b8-9d8b-abafe5a97451"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 864x576 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# Data visualization between Test and Predicted data for the time-series data of the first 10 sample datapoints\n","\n","y_test = y_physics_test[:1000, :, :]\n","\n","plt.figure(figsize=(12, 8))\n","for i in range(10):\n","    if i == 0:  # only add label to 1 data point\n","        plt.plot(y_test[i, :, 0], y_test[i, :, 1], color='cyan', lw=2, label='Test')\n","        plt.plot(y_predict_test[i, :, 0], y_predict_test[i, :, 1], color='black', lw=2, ls=':', label='Predicted')\n","    else:\n","        plt.plot(y_test[i, :, 0], y_test[i, :, 1], color='cyan', lw=2)\n","        plt.plot(y_predict_test[i, :, 0], y_predict_test[i, :, 1], color='black', lw=2, ls=':')\n","\n","\n","plt.xlabel(\"C_A\")\n","plt.ylabel(\"T\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"8c036b31","metadata":{"id":"8c036b31"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}
